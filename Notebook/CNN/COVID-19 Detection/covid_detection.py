# -*- coding: utf-8 -*-
"""COVID Detection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1piN4VenUgpfu09a_hiH5UFr4N3AJtJxu

#**COVID Detection with X-Rays**

importing the libraries
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from matplotlib.image import imread
import seaborn as sns
import os
import cv2

from google.colab import drive
drive.mount('/content/drive')

import zipfile
zip_ref = zipfile.ZipFile('/content/drive/MyDrive/covid X ray.zip')
zip_ref.extractall('/tmp')
zip_ref.close()

os.listdir('/tmp/COVID-19_Radiography_Dataset')

len(os.listdir('/tmp/COVID-19_Radiography_Dataset/COVID/images/'))

len(os.listdir('/tmp/COVID-19_Radiography_Dataset/Normal/images'))

"""***We can clearly see that our dataset is inbalanced by the looking at the number of 2 different classes.***"""

root_dir = '/tmp/COVID-19_Radiography_Dataset'
number_of_img = {}

for dir in os.listdir(root_dir):
  number_of_img[dir] = len(os.listdir(os.path.join(root_dir,dir+"/images/")))

number_of_img

"""We shall split the dataset into:-
* 70% training data
* 15% testing data
* 15% validation data
"""

import math
import shutil

"""creating the directories - train, test, val"""

def datafolder(path, split):
  if not os.path.exists("./"+path):
    os.mkdir("./"+path)     # root ---> train(path)

    for dir in os.listdir(root_dir):
      os.makedirs("./"+path+"/"+dir)     # root --> train ---> COVID/normal
      for img in np.random.choice(a=os.listdir(os.path.join(root_dir,dir + "/images/")),
                                  size=(math.floor(split*number_of_img[dir])),
                                  replace=False):
        O = os.path.join(root_dir, dir+ "/images/", img)  # origin
        D = os.path.join("./"+path,dir)       # destination root --> train ---> covid ---> imgfile
        shutil.copy(O,D)
        os.remove(O)
  else:
    print("Path already exists")

datafolder('train', 0.7)

train_n_img = {}
for dir in os.listdir("./train/"):
  train_n_img[dir] = len(os.listdir(os.path.join("./train/",dir)))

train_n_img

datafolder('test',0.15)

datafolder('val',0.15)

"""***Data visualization***"""

os.listdir('train/Normal/')[:3]

os.listdir('train/COVID/')[:3]

fig, axes = plt.subplots(1,2)
axes[0].imshow(imread('train'+'/Normal/Normal-6391.png'), cmap='binary')
axes[0].title.set_text("NORMAL X_RAY IMAGE")

axes[1].imshow(imread('train'+'/COVID/COVID-2079.png'), cmap='binary')
axes[1].title.set_text("COVID INFECTED X_RAY IMAGE")

plt.tight_layout()
plt.autoscale(enable=True, axis='both')

imread('train'+'/COVID/COVID-2079.png').shape

"""## Building Deep Learning model"""

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Dropout

model = Sequential()
model.add(Conv2D(filters=32, kernel_size=(3,3), input_shape=(150,150,1), activation='relu'))
model.add(MaxPool2D(pool_size=(2,2)))

model.add(Conv2D(filters=64, kernel_size=(3,3), activation='relu'))
model.add(MaxPool2D(pool_size=(2,2)))

model.add(Conv2D(filters=128, kernel_size=(3,3), activation='relu'))
model.add(MaxPool2D(pool_size=(2,2)))

model.add(Dropout(0.2))

model.add(Flatten())

model.add(Dense(units=128, activation='relu'))
model.add(Dropout(0.2))
model.add(Dense(units=1, activation='sigmoid'))

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

model.summary()

"""## Data pre-processing"""

from tensorflow.keras.preprocessing.image import ImageDataGenerator

def preprocessing(path):
  image_data = ImageDataGenerator(width_shift_range=0.1,
                                  shear_range=0.2,
                                  horizontal_flip=True,
                                  zoom_range=0.1)
  image = image_data.flow_from_directory(directory=path, target_size=(150,150),
                                         color_mode='grayscale',
                                         batch_size=32,
                                         class_mode='binary')
  return image

train_data = preprocessing('/content/train')

def preprocessing2(path):
  image_data = ImageDataGenerator()
  image = image_data.flow_from_directory(directory=path, target_size=(150,150),
                                         color_mode='grayscale',
                                         batch_size=32,
                                         class_mode='binary',
                                         shuffle=False)
  return image

test_data = preprocessing2('/content/test')
val_data = preprocessing2('/content/val')

from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
early_stop = EarlyStopping(monitor='val_loss', patience=2)
mc = ModelCheckpoint(monitor='val_loss', filepath='./bestmodel.h5', 
                     save_best_only=True,
                     mode='auto')

cb = [early_stop, mc]

from gc import callbacks
model.fit(train_data, epochs=50, validation_data=val_data, callbacks=cb)

df = pd.DataFrame(model.history.history)
df

df[['loss','val_loss']].plot()

df[['accuracy','val_accuracy']].plot()

from tensorflow.keras.models import load_model
best_model = load_model('/content/bestmodel.h5')

"""Model Evaluation"""

print("The accuracy of the model: ", best_model.evaluate(test_data)[1])

"""Predictions"""

from tensorflow.keras.preprocessing import image
img = image.load_img('/content/test/COVID/COVID-1001.png',
                       target_size=(150,150),
                      color_mode='grayscale')
img_arr = image.img_to_array(img)
img_arr = np.expand_dims(img_arr, axis=0)

plt.imshow(imread('/content/test/COVID/COVID-1001.png'), cmap='binary')
plt.title("To be predicted")

pred = best_model.predict(img_arr)
pred_classes = (pred > 0.5).astype('int32')
pred_classes

test_data.class_indices

if pred_classes == 0:
  print("COVID infected - tested positive!!!")
elif pred_classes == 1:
  print("NORMAL - tested negative")
else:
  print("Not known!!!")

pred_total = best_model.predict(test_data)
pred_classes_total = (pred_total > 0.5).astype("int32")

from sklearn.metrics import confusion_matrix, classification_report
print(confusion_matrix(test_data.classes, pred_classes_total))
print(classification_report(test_data.classes, pred_classes_total))

"""***We achieved 93% accuracy using the custom CNN model***

## Transfer Learning Techniques
"""

from tensorflow.keras.models import Model, load_model
from tensorflow.keras.layers import Dense, Flatten
from tensorflow.keras.applications.mobilenet import MobileNet, preprocess_input

def preprocessing(path):
  image_data = ImageDataGenerator(
                                   width_shift_range=0.1,
                                   zoom_range=0.1,
                                   preprocessing_function=preprocess_input,
                                   shear_range=0.2,
                                   horizontal_flip=True)
  image = image_data.flow_from_directory(directory=path, target_size=(150,150),
                                         color_mode='grayscale',
                                         batch_size=16, class_mode='binary')
  return image

def preprocessing2(path):
  image_data = ImageDataGenerator(
                                   preprocessing_function=preprocess_input)
  image = image_data.flow_from_directory(directory=path, target_size=(150,150),
                                         color_mode='grayscale', shuffle=False,
                                         batch_size=16, class_mode='binary')
  return image

train__data = preprocessing('/content/train')

test__data = preprocessing2('/content/test')
val__data = preprocessing2('/content/val')

base_model = MobileNet(input_shape=(150,150,3),
                   include_top = False)

# to make sure we won't re-train the model again
for layer in base_model.layers:
  layer.trainable = False

base_model.summary()

# club the pre-trained model with our custom model
X =Flatten()(base_model.output)  # last layer in base_model
X = Dense(units=1, activation='sigmoid')(X)

tf_model = Model(base_model.input, X)

tf_model.summary()

tf_model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])

early_stop = EarlyStopping(monitor='val_loss', patience=5)
mc = ModelCheckpoint(monitor='val_loss', filepath='./bestmodel2.h5',save_best_only=True, mode='auto')

cb = [early_stop,mc]

result_tf = tf_model.fit(train__data, 
                         epochs=30, 
                         validation_data=val__data, 
                         callbacks=cb)

