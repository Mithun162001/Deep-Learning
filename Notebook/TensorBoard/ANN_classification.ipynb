{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>benign_0__mal_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                 0.07871  ...          17.33           184.60      2019.0   \n",
       "1                 0.05667  ...          23.41           158.80      1956.0   \n",
       "2                 0.05999  ...          25.53           152.50      1709.0   \n",
       "3                 0.09744  ...          26.50            98.87       567.7   \n",
       "4                 0.05883  ...          16.67           152.20      1575.0   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  benign_0__mal_1  \n",
       "0          0.4601                  0.11890                0  \n",
       "1          0.2750                  0.08902                0  \n",
       "2          0.3613                  0.08758                0  \n",
       "3          0.6638                  0.17300                0  \n",
       "4          0.2364                  0.07678                0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('cancer_classification.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Basic EDA</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 31 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   mean radius              569 non-null    float64\n",
      " 1   mean texture             569 non-null    float64\n",
      " 2   mean perimeter           569 non-null    float64\n",
      " 3   mean area                569 non-null    float64\n",
      " 4   mean smoothness          569 non-null    float64\n",
      " 5   mean compactness         569 non-null    float64\n",
      " 6   mean concavity           569 non-null    float64\n",
      " 7   mean concave points      569 non-null    float64\n",
      " 8   mean symmetry            569 non-null    float64\n",
      " 9   mean fractal dimension   569 non-null    float64\n",
      " 10  radius error             569 non-null    float64\n",
      " 11  texture error            569 non-null    float64\n",
      " 12  perimeter error          569 non-null    float64\n",
      " 13  area error               569 non-null    float64\n",
      " 14  smoothness error         569 non-null    float64\n",
      " 15  compactness error        569 non-null    float64\n",
      " 16  concavity error          569 non-null    float64\n",
      " 17  concave points error     569 non-null    float64\n",
      " 18  symmetry error           569 non-null    float64\n",
      " 19  fractal dimension error  569 non-null    float64\n",
      " 20  worst radius             569 non-null    float64\n",
      " 21  worst texture            569 non-null    float64\n",
      " 22  worst perimeter          569 non-null    float64\n",
      " 23  worst area               569 non-null    float64\n",
      " 24  worst smoothness         569 non-null    float64\n",
      " 25  worst compactness        569 non-null    float64\n",
      " 26  worst concavity          569 non-null    float64\n",
      " 27  worst concave points     569 non-null    float64\n",
      " 28  worst symmetry           569 non-null    float64\n",
      " 29  worst fractal dimension  569 non-null    float64\n",
      " 30  benign_0__mal_1          569 non-null    int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 137.9 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean radius</th>\n",
       "      <td>569.0</td>\n",
       "      <td>14.127292</td>\n",
       "      <td>3.524049</td>\n",
       "      <td>6.981000</td>\n",
       "      <td>11.700000</td>\n",
       "      <td>13.370000</td>\n",
       "      <td>15.780000</td>\n",
       "      <td>28.11000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean texture</th>\n",
       "      <td>569.0</td>\n",
       "      <td>19.289649</td>\n",
       "      <td>4.301036</td>\n",
       "      <td>9.710000</td>\n",
       "      <td>16.170000</td>\n",
       "      <td>18.840000</td>\n",
       "      <td>21.800000</td>\n",
       "      <td>39.28000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean perimeter</th>\n",
       "      <td>569.0</td>\n",
       "      <td>91.969033</td>\n",
       "      <td>24.298981</td>\n",
       "      <td>43.790000</td>\n",
       "      <td>75.170000</td>\n",
       "      <td>86.240000</td>\n",
       "      <td>104.100000</td>\n",
       "      <td>188.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean area</th>\n",
       "      <td>569.0</td>\n",
       "      <td>654.889104</td>\n",
       "      <td>351.914129</td>\n",
       "      <td>143.500000</td>\n",
       "      <td>420.300000</td>\n",
       "      <td>551.100000</td>\n",
       "      <td>782.700000</td>\n",
       "      <td>2501.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean smoothness</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.096360</td>\n",
       "      <td>0.014064</td>\n",
       "      <td>0.052630</td>\n",
       "      <td>0.086370</td>\n",
       "      <td>0.095870</td>\n",
       "      <td>0.105300</td>\n",
       "      <td>0.16340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean compactness</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.104341</td>\n",
       "      <td>0.052813</td>\n",
       "      <td>0.019380</td>\n",
       "      <td>0.064920</td>\n",
       "      <td>0.092630</td>\n",
       "      <td>0.130400</td>\n",
       "      <td>0.34540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean concavity</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.088799</td>\n",
       "      <td>0.079720</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029560</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>0.130700</td>\n",
       "      <td>0.42680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean concave points</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.048919</td>\n",
       "      <td>0.038803</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020310</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>0.20120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean symmetry</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.181162</td>\n",
       "      <td>0.027414</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>0.161900</td>\n",
       "      <td>0.179200</td>\n",
       "      <td>0.195700</td>\n",
       "      <td>0.30400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.062798</td>\n",
       "      <td>0.007060</td>\n",
       "      <td>0.049960</td>\n",
       "      <td>0.057700</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>0.066120</td>\n",
       "      <td>0.09744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>radius error</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.405172</td>\n",
       "      <td>0.277313</td>\n",
       "      <td>0.111500</td>\n",
       "      <td>0.232400</td>\n",
       "      <td>0.324200</td>\n",
       "      <td>0.478900</td>\n",
       "      <td>2.87300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>texture error</th>\n",
       "      <td>569.0</td>\n",
       "      <td>1.216853</td>\n",
       "      <td>0.551648</td>\n",
       "      <td>0.360200</td>\n",
       "      <td>0.833900</td>\n",
       "      <td>1.108000</td>\n",
       "      <td>1.474000</td>\n",
       "      <td>4.88500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perimeter error</th>\n",
       "      <td>569.0</td>\n",
       "      <td>2.866059</td>\n",
       "      <td>2.021855</td>\n",
       "      <td>0.757000</td>\n",
       "      <td>1.606000</td>\n",
       "      <td>2.287000</td>\n",
       "      <td>3.357000</td>\n",
       "      <td>21.98000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>area error</th>\n",
       "      <td>569.0</td>\n",
       "      <td>40.337079</td>\n",
       "      <td>45.491006</td>\n",
       "      <td>6.802000</td>\n",
       "      <td>17.850000</td>\n",
       "      <td>24.530000</td>\n",
       "      <td>45.190000</td>\n",
       "      <td>542.20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smoothness error</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.007041</td>\n",
       "      <td>0.003003</td>\n",
       "      <td>0.001713</td>\n",
       "      <td>0.005169</td>\n",
       "      <td>0.006380</td>\n",
       "      <td>0.008146</td>\n",
       "      <td>0.03113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compactness error</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.025478</td>\n",
       "      <td>0.017908</td>\n",
       "      <td>0.002252</td>\n",
       "      <td>0.013080</td>\n",
       "      <td>0.020450</td>\n",
       "      <td>0.032450</td>\n",
       "      <td>0.13540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concavity error</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.031894</td>\n",
       "      <td>0.030186</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015090</td>\n",
       "      <td>0.025890</td>\n",
       "      <td>0.042050</td>\n",
       "      <td>0.39600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concave points error</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.011796</td>\n",
       "      <td>0.006170</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007638</td>\n",
       "      <td>0.010930</td>\n",
       "      <td>0.014710</td>\n",
       "      <td>0.05279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>symmetry error</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.020542</td>\n",
       "      <td>0.008266</td>\n",
       "      <td>0.007882</td>\n",
       "      <td>0.015160</td>\n",
       "      <td>0.018730</td>\n",
       "      <td>0.023480</td>\n",
       "      <td>0.07895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fractal dimension error</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.003795</td>\n",
       "      <td>0.002646</td>\n",
       "      <td>0.000895</td>\n",
       "      <td>0.002248</td>\n",
       "      <td>0.003187</td>\n",
       "      <td>0.004558</td>\n",
       "      <td>0.02984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worst radius</th>\n",
       "      <td>569.0</td>\n",
       "      <td>16.269190</td>\n",
       "      <td>4.833242</td>\n",
       "      <td>7.930000</td>\n",
       "      <td>13.010000</td>\n",
       "      <td>14.970000</td>\n",
       "      <td>18.790000</td>\n",
       "      <td>36.04000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worst texture</th>\n",
       "      <td>569.0</td>\n",
       "      <td>25.677223</td>\n",
       "      <td>6.146258</td>\n",
       "      <td>12.020000</td>\n",
       "      <td>21.080000</td>\n",
       "      <td>25.410000</td>\n",
       "      <td>29.720000</td>\n",
       "      <td>49.54000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worst perimeter</th>\n",
       "      <td>569.0</td>\n",
       "      <td>107.261213</td>\n",
       "      <td>33.602542</td>\n",
       "      <td>50.410000</td>\n",
       "      <td>84.110000</td>\n",
       "      <td>97.660000</td>\n",
       "      <td>125.400000</td>\n",
       "      <td>251.20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worst area</th>\n",
       "      <td>569.0</td>\n",
       "      <td>880.583128</td>\n",
       "      <td>569.356993</td>\n",
       "      <td>185.200000</td>\n",
       "      <td>515.300000</td>\n",
       "      <td>686.500000</td>\n",
       "      <td>1084.000000</td>\n",
       "      <td>4254.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worst smoothness</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.132369</td>\n",
       "      <td>0.022832</td>\n",
       "      <td>0.071170</td>\n",
       "      <td>0.116600</td>\n",
       "      <td>0.131300</td>\n",
       "      <td>0.146000</td>\n",
       "      <td>0.22260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worst compactness</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.254265</td>\n",
       "      <td>0.157336</td>\n",
       "      <td>0.027290</td>\n",
       "      <td>0.147200</td>\n",
       "      <td>0.211900</td>\n",
       "      <td>0.339100</td>\n",
       "      <td>1.05800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worst concavity</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.272188</td>\n",
       "      <td>0.208624</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.114500</td>\n",
       "      <td>0.226700</td>\n",
       "      <td>0.382900</td>\n",
       "      <td>1.25200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worst concave points</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.114606</td>\n",
       "      <td>0.065732</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.064930</td>\n",
       "      <td>0.099930</td>\n",
       "      <td>0.161400</td>\n",
       "      <td>0.29100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worst symmetry</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.290076</td>\n",
       "      <td>0.061867</td>\n",
       "      <td>0.156500</td>\n",
       "      <td>0.250400</td>\n",
       "      <td>0.282200</td>\n",
       "      <td>0.317900</td>\n",
       "      <td>0.66380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.083946</td>\n",
       "      <td>0.018061</td>\n",
       "      <td>0.055040</td>\n",
       "      <td>0.071460</td>\n",
       "      <td>0.080040</td>\n",
       "      <td>0.092080</td>\n",
       "      <td>0.20750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>benign_0__mal_1</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.627417</td>\n",
       "      <td>0.483918</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         count        mean         std         min  \\\n",
       "mean radius              569.0   14.127292    3.524049    6.981000   \n",
       "mean texture             569.0   19.289649    4.301036    9.710000   \n",
       "mean perimeter           569.0   91.969033   24.298981   43.790000   \n",
       "mean area                569.0  654.889104  351.914129  143.500000   \n",
       "mean smoothness          569.0    0.096360    0.014064    0.052630   \n",
       "mean compactness         569.0    0.104341    0.052813    0.019380   \n",
       "mean concavity           569.0    0.088799    0.079720    0.000000   \n",
       "mean concave points      569.0    0.048919    0.038803    0.000000   \n",
       "mean symmetry            569.0    0.181162    0.027414    0.106000   \n",
       "mean fractal dimension   569.0    0.062798    0.007060    0.049960   \n",
       "radius error             569.0    0.405172    0.277313    0.111500   \n",
       "texture error            569.0    1.216853    0.551648    0.360200   \n",
       "perimeter error          569.0    2.866059    2.021855    0.757000   \n",
       "area error               569.0   40.337079   45.491006    6.802000   \n",
       "smoothness error         569.0    0.007041    0.003003    0.001713   \n",
       "compactness error        569.0    0.025478    0.017908    0.002252   \n",
       "concavity error          569.0    0.031894    0.030186    0.000000   \n",
       "concave points error     569.0    0.011796    0.006170    0.000000   \n",
       "symmetry error           569.0    0.020542    0.008266    0.007882   \n",
       "fractal dimension error  569.0    0.003795    0.002646    0.000895   \n",
       "worst radius             569.0   16.269190    4.833242    7.930000   \n",
       "worst texture            569.0   25.677223    6.146258   12.020000   \n",
       "worst perimeter          569.0  107.261213   33.602542   50.410000   \n",
       "worst area               569.0  880.583128  569.356993  185.200000   \n",
       "worst smoothness         569.0    0.132369    0.022832    0.071170   \n",
       "worst compactness        569.0    0.254265    0.157336    0.027290   \n",
       "worst concavity          569.0    0.272188    0.208624    0.000000   \n",
       "worst concave points     569.0    0.114606    0.065732    0.000000   \n",
       "worst symmetry           569.0    0.290076    0.061867    0.156500   \n",
       "worst fractal dimension  569.0    0.083946    0.018061    0.055040   \n",
       "benign_0__mal_1          569.0    0.627417    0.483918    0.000000   \n",
       "\n",
       "                                25%         50%          75%         max  \n",
       "mean radius               11.700000   13.370000    15.780000    28.11000  \n",
       "mean texture              16.170000   18.840000    21.800000    39.28000  \n",
       "mean perimeter            75.170000   86.240000   104.100000   188.50000  \n",
       "mean area                420.300000  551.100000   782.700000  2501.00000  \n",
       "mean smoothness            0.086370    0.095870     0.105300     0.16340  \n",
       "mean compactness           0.064920    0.092630     0.130400     0.34540  \n",
       "mean concavity             0.029560    0.061540     0.130700     0.42680  \n",
       "mean concave points        0.020310    0.033500     0.074000     0.20120  \n",
       "mean symmetry              0.161900    0.179200     0.195700     0.30400  \n",
       "mean fractal dimension     0.057700    0.061540     0.066120     0.09744  \n",
       "radius error               0.232400    0.324200     0.478900     2.87300  \n",
       "texture error              0.833900    1.108000     1.474000     4.88500  \n",
       "perimeter error            1.606000    2.287000     3.357000    21.98000  \n",
       "area error                17.850000   24.530000    45.190000   542.20000  \n",
       "smoothness error           0.005169    0.006380     0.008146     0.03113  \n",
       "compactness error          0.013080    0.020450     0.032450     0.13540  \n",
       "concavity error            0.015090    0.025890     0.042050     0.39600  \n",
       "concave points error       0.007638    0.010930     0.014710     0.05279  \n",
       "symmetry error             0.015160    0.018730     0.023480     0.07895  \n",
       "fractal dimension error    0.002248    0.003187     0.004558     0.02984  \n",
       "worst radius              13.010000   14.970000    18.790000    36.04000  \n",
       "worst texture             21.080000   25.410000    29.720000    49.54000  \n",
       "worst perimeter           84.110000   97.660000   125.400000   251.20000  \n",
       "worst area               515.300000  686.500000  1084.000000  4254.00000  \n",
       "worst smoothness           0.116600    0.131300     0.146000     0.22260  \n",
       "worst compactness          0.147200    0.211900     0.339100     1.05800  \n",
       "worst concavity            0.114500    0.226700     0.382900     1.25200  \n",
       "worst concave points       0.064930    0.099930     0.161400     0.29100  \n",
       "worst symmetry             0.250400    0.282200     0.317900     0.66380  \n",
       "worst fractal dimension    0.071460    0.080040     0.092080     0.20750  \n",
       "benign_0__mal_1            0.000000    1.000000     1.000000     1.00000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='benign_0__mal_1', ylabel='count'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='benign_0__mal_1',data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "df.corr()['benign_0__mal_1'][:-1].sort_values().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('benign_0__mal_1',axis=1).values\n",
    "y = df['benign_0__mal_1'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(398, 30)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-16 18:59:15.906558: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-03-16 18:59:15.906598: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-03-16 18:59:15.906623: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (default): /proc/driver/nvidia/version does not exist\n",
      "2022-03-16 18:59:15.910318: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(30, activation='relu'))     # hidden layer 1\n",
    "model.add(Dense(15, activation='relu'))     # hidden layer 2\n",
    "model.add(Dense(1,activation = 'sigmoid'))  # output layer, sigmoidal because it's an binary classifcation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "13/13 [==============================] - 1s 16ms/step - loss: 0.8474 - val_loss: 0.6478\n",
      "Epoch 2/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5804 - val_loss: 0.4844\n",
      "Epoch 3/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4459 - val_loss: 0.3819\n",
      "Epoch 4/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.3542 - val_loss: 0.3048\n",
      "Epoch 5/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2860 - val_loss: 0.2475\n",
      "Epoch 6/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.2378 - val_loss: 0.2063\n",
      "Epoch 7/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.2038 - val_loss: 0.1773\n",
      "Epoch 8/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1793 - val_loss: 0.1549\n",
      "Epoch 9/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1610 - val_loss: 0.1364\n",
      "Epoch 10/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1457 - val_loss: 0.1216\n",
      "Epoch 11/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1324 - val_loss: 0.1098\n",
      "Epoch 12/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1208 - val_loss: 0.1004\n",
      "Epoch 13/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1117 - val_loss: 0.0931\n",
      "Epoch 14/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1040 - val_loss: 0.0868\n",
      "Epoch 15/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0972 - val_loss: 0.0816\n",
      "Epoch 16/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0914 - val_loss: 0.0770\n",
      "Epoch 17/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0866 - val_loss: 0.0731\n",
      "Epoch 18/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0820 - val_loss: 0.0706\n",
      "Epoch 19/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0777 - val_loss: 0.0680\n",
      "Epoch 20/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0745 - val_loss: 0.0663\n",
      "Epoch 21/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0707 - val_loss: 0.0642\n",
      "Epoch 22/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0678 - val_loss: 0.0627\n",
      "Epoch 23/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0653 - val_loss: 0.0612\n",
      "Epoch 24/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0625 - val_loss: 0.0596\n",
      "Epoch 25/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0604 - val_loss: 0.0585\n",
      "Epoch 26/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0581 - val_loss: 0.0576\n",
      "Epoch 27/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0560 - val_loss: 0.0575\n",
      "Epoch 28/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0541 - val_loss: 0.0562\n",
      "Epoch 29/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0521 - val_loss: 0.0558\n",
      "Epoch 30/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0501 - val_loss: 0.0553\n",
      "Epoch 31/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0485 - val_loss: 0.0541\n",
      "Epoch 32/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0470 - val_loss: 0.0533\n",
      "Epoch 33/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0453 - val_loss: 0.0531\n",
      "Epoch 34/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0437 - val_loss: 0.0533\n",
      "Epoch 35/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0425 - val_loss: 0.0530\n",
      "Epoch 36/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0410 - val_loss: 0.0521\n",
      "Epoch 37/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0397 - val_loss: 0.0519\n",
      "Epoch 38/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0385 - val_loss: 0.0511\n",
      "Epoch 39/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0374 - val_loss: 0.0514\n",
      "Epoch 40/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0364 - val_loss: 0.0515\n",
      "Epoch 41/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0353 - val_loss: 0.0503\n",
      "Epoch 42/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0339 - val_loss: 0.0507\n",
      "Epoch 43/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0328 - val_loss: 0.0504\n",
      "Epoch 44/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0318 - val_loss: 0.0507\n",
      "Epoch 45/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0306 - val_loss: 0.0504\n",
      "Epoch 46/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0294 - val_loss: 0.0499\n",
      "Epoch 47/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0284 - val_loss: 0.0505\n",
      "Epoch 48/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0274 - val_loss: 0.0507\n",
      "Epoch 49/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0261 - val_loss: 0.0503\n",
      "Epoch 50/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0253 - val_loss: 0.0504\n",
      "Epoch 51/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0244 - val_loss: 0.0504\n",
      "Epoch 52/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0237 - val_loss: 0.0498\n",
      "Epoch 53/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0233 - val_loss: 0.0518\n",
      "Epoch 54/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0220 - val_loss: 0.0506\n",
      "Epoch 55/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0211 - val_loss: 0.0509\n",
      "Epoch 56/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0202 - val_loss: 0.0502\n",
      "Epoch 57/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0197 - val_loss: 0.0495\n",
      "Epoch 58/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0191 - val_loss: 0.0493\n",
      "Epoch 59/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0185 - val_loss: 0.0504\n",
      "Epoch 60/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0175 - val_loss: 0.0516\n",
      "Epoch 61/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0172 - val_loss: 0.0516\n",
      "Epoch 62/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0169 - val_loss: 0.0499\n",
      "Epoch 63/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0159 - val_loss: 0.0502\n",
      "Epoch 64/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0153 - val_loss: 0.0503\n",
      "Epoch 65/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0151 - val_loss: 0.0520\n",
      "Epoch 66/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - val_loss: 0.0515\n",
      "Epoch 67/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0135 - val_loss: 0.0513\n",
      "Epoch 68/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0131 - val_loss: 0.0508\n",
      "Epoch 69/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0126 - val_loss: 0.0512\n",
      "Epoch 70/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0122 - val_loss: 0.0515\n",
      "Epoch 71/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0117 - val_loss: 0.0520\n",
      "Epoch 72/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0112 - val_loss: 0.0516\n",
      "Epoch 73/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0113 - val_loss: 0.0533\n",
      "Epoch 74/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0107 - val_loss: 0.0521\n",
      "Epoch 75/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0103 - val_loss: 0.0525\n",
      "Epoch 76/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0099 - val_loss: 0.0523\n",
      "Epoch 77/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0096 - val_loss: 0.0524\n",
      "Epoch 78/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0092 - val_loss: 0.0522\n",
      "Epoch 79/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0089 - val_loss: 0.0523\n",
      "Epoch 80/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0086 - val_loss: 0.0526\n",
      "Epoch 81/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0084 - val_loss: 0.0525\n",
      "Epoch 82/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0082 - val_loss: 0.0533\n",
      "Epoch 83/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0080 - val_loss: 0.0535\n",
      "Epoch 84/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0077 - val_loss: 0.0535\n",
      "Epoch 85/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0074 - val_loss: 0.0543\n",
      "Epoch 86/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0073 - val_loss: 0.0543\n",
      "Epoch 87/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0069 - val_loss: 0.0546\n",
      "Epoch 88/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0067 - val_loss: 0.0543\n",
      "Epoch 89/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0065 - val_loss: 0.0548\n",
      "Epoch 90/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0064 - val_loss: 0.0550\n",
      "Epoch 91/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0061 - val_loss: 0.0545\n",
      "Epoch 92/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0060 - val_loss: 0.0549\n",
      "Epoch 93/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0058 - val_loss: 0.0554\n",
      "Epoch 94/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0056 - val_loss: 0.0554\n",
      "Epoch 95/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0053 - val_loss: 0.0549\n",
      "Epoch 96/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0551\n",
      "Epoch 97/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0050 - val_loss: 0.0553\n",
      "Epoch 98/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.0561\n",
      "Epoch 99/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.0558\n",
      "Epoch 100/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0048 - val_loss: 0.0560\n",
      "Epoch 101/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0045 - val_loss: 0.0573\n",
      "Epoch 102/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0044 - val_loss: 0.0569\n",
      "Epoch 103/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0042 - val_loss: 0.0565\n",
      "Epoch 104/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0041 - val_loss: 0.0566\n",
      "Epoch 105/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0040 - val_loss: 0.0571\n",
      "Epoch 106/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0038 - val_loss: 0.0568\n",
      "Epoch 107/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0038 - val_loss: 0.0571\n",
      "Epoch 108/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0037 - val_loss: 0.0576\n",
      "Epoch 109/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0036 - val_loss: 0.0572\n",
      "Epoch 110/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0036 - val_loss: 0.0570\n",
      "Epoch 111/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0033 - val_loss: 0.0577\n",
      "Epoch 112/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0033 - val_loss: 0.0580\n",
      "Epoch 113/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0033 - val_loss: 0.0578\n",
      "Epoch 114/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0031 - val_loss: 0.0579\n",
      "Epoch 115/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0030 - val_loss: 0.0596\n",
      "Epoch 116/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0031 - val_loss: 0.0591\n",
      "Epoch 117/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0028 - val_loss: 0.0589\n",
      "Epoch 118/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0028 - val_loss: 0.0589\n",
      "Epoch 119/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0028 - val_loss: 0.0593\n",
      "Epoch 120/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0027 - val_loss: 0.0588\n",
      "Epoch 121/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0026 - val_loss: 0.0590\n",
      "Epoch 122/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0026 - val_loss: 0.0598\n",
      "Epoch 123/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0025 - val_loss: 0.0595\n",
      "Epoch 124/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0024 - val_loss: 0.0599\n",
      "Epoch 125/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0024 - val_loss: 0.0600\n",
      "Epoch 126/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0023 - val_loss: 0.0602\n",
      "Epoch 127/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0022 - val_loss: 0.0605\n",
      "Epoch 128/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0022 - val_loss: 0.0606\n",
      "Epoch 129/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0021 - val_loss: 0.0610\n",
      "Epoch 130/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0021 - val_loss: 0.0610\n",
      "Epoch 131/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0020 - val_loss: 0.0608\n",
      "Epoch 132/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0020 - val_loss: 0.0614\n",
      "Epoch 133/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0020 - val_loss: 0.0615\n",
      "Epoch 134/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0019 - val_loss: 0.0615\n",
      "Epoch 135/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0019 - val_loss: 0.0617\n",
      "Epoch 136/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 0.0621\n",
      "Epoch 137/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 0.0623\n",
      "Epoch 138/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 0.0625\n",
      "Epoch 139/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 0.0630\n",
      "Epoch 140/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 0.0630\n",
      "Epoch 141/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 0.0632\n",
      "Epoch 142/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0016 - val_loss: 0.0634\n",
      "Epoch 143/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0016 - val_loss: 0.0633\n",
      "Epoch 144/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0016 - val_loss: 0.0639\n",
      "Epoch 145/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0015 - val_loss: 0.0638\n",
      "Epoch 146/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0015 - val_loss: 0.0646\n",
      "Epoch 147/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0015 - val_loss: 0.0645\n",
      "Epoch 148/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0014 - val_loss: 0.0651\n",
      "Epoch 149/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0014 - val_loss: 0.0651\n",
      "Epoch 150/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0014 - val_loss: 0.0648\n",
      "Epoch 151/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0013 - val_loss: 0.0653\n",
      "Epoch 152/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0013 - val_loss: 0.0654\n",
      "Epoch 153/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0013 - val_loss: 0.0654\n",
      "Epoch 154/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0013 - val_loss: 0.0657\n",
      "Epoch 155/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0012 - val_loss: 0.0661\n",
      "Epoch 156/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0012 - val_loss: 0.0662\n",
      "Epoch 157/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0012 - val_loss: 0.0663\n",
      "Epoch 158/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0012 - val_loss: 0.0664\n",
      "Epoch 159/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 0.0665\n",
      "Epoch 160/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 0.0669\n",
      "Epoch 161/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0012 - val_loss: 0.0669\n",
      "Epoch 162/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 0.0674\n",
      "Epoch 163/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 0.0676\n",
      "Epoch 164/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 0.0677\n",
      "Epoch 165/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 0.0676\n",
      "Epoch 166/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 0.0686\n",
      "Epoch 167/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 0.0685\n",
      "Epoch 168/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 9.7595e-04 - val_loss: 0.0686\n",
      "Epoch 169/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 9.5132e-04 - val_loss: 0.0687\n",
      "Epoch 170/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 9.2464e-04 - val_loss: 0.0689\n",
      "Epoch 171/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 9.0811e-04 - val_loss: 0.0689\n",
      "Epoch 172/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 8.8963e-04 - val_loss: 0.0691\n",
      "Epoch 173/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 8.8851e-04 - val_loss: 0.0694\n",
      "Epoch 174/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 8.6951e-04 - val_loss: 0.0695\n",
      "Epoch 175/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 8.5373e-04 - val_loss: 0.0698\n",
      "Epoch 176/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 8.3558e-04 - val_loss: 0.0697\n",
      "Epoch 177/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 8.4443e-04 - val_loss: 0.0700\n",
      "Epoch 178/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 8.1209e-04 - val_loss: 0.0705\n",
      "Epoch 179/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 8.0000e-04 - val_loss: 0.0707\n",
      "Epoch 180/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 8.0963e-04 - val_loss: 0.0706\n",
      "Epoch 181/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 7.7532e-04 - val_loss: 0.0711\n",
      "Epoch 182/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 7.5125e-04 - val_loss: 0.0713\n",
      "Epoch 183/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 7.4419e-04 - val_loss: 0.0714\n",
      "Epoch 184/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 7.2671e-04 - val_loss: 0.0716\n",
      "Epoch 185/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 7.1853e-04 - val_loss: 0.0717\n",
      "Epoch 186/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 6.9839e-04 - val_loss: 0.0719\n",
      "Epoch 187/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 6.9048e-04 - val_loss: 0.0719\n",
      "Epoch 188/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 6.9716e-04 - val_loss: 0.0723\n",
      "Epoch 189/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 6.7381e-04 - val_loss: 0.0723\n",
      "Epoch 190/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 6.5373e-04 - val_loss: 0.0726\n",
      "Epoch 191/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 6.4465e-04 - val_loss: 0.0729\n",
      "Epoch 192/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 6.3236e-04 - val_loss: 0.0730\n",
      "Epoch 193/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 6.2459e-04 - val_loss: 0.0731\n",
      "Epoch 194/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 6.1821e-04 - val_loss: 0.0733\n",
      "Epoch 195/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 6.0448e-04 - val_loss: 0.0735\n",
      "Epoch 196/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 5.9534e-04 - val_loss: 0.0737\n",
      "Epoch 197/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 5.9351e-04 - val_loss: 0.0739\n",
      "Epoch 198/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 5.8006e-04 - val_loss: 0.0740\n",
      "Epoch 199/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 5.7160e-04 - val_loss: 0.0742\n",
      "Epoch 200/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 5.6488e-04 - val_loss: 0.0744\n",
      "Epoch 201/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 5.5181e-04 - val_loss: 0.0746\n",
      "Epoch 202/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 5.5154e-04 - val_loss: 0.0748\n",
      "Epoch 203/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 5.3672e-04 - val_loss: 0.0749\n",
      "Epoch 204/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 5.2708e-04 - val_loss: 0.0751\n",
      "Epoch 205/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 5.2770e-04 - val_loss: 0.0753\n",
      "Epoch 206/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 5.1841e-04 - val_loss: 0.0756\n",
      "Epoch 207/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 5.1467e-04 - val_loss: 0.0757\n",
      "Epoch 208/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 5.0336e-04 - val_loss: 0.0759\n",
      "Epoch 209/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 4.8913e-04 - val_loss: 0.0761\n",
      "Epoch 210/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 4.8058e-04 - val_loss: 0.0763\n",
      "Epoch 211/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 4.7346e-04 - val_loss: 0.0764\n",
      "Epoch 212/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 4.6668e-04 - val_loss: 0.0765\n",
      "Epoch 213/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 4.6580e-04 - val_loss: 0.0767\n",
      "Epoch 214/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 4.5217e-04 - val_loss: 0.0769\n",
      "Epoch 215/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 4.4442e-04 - val_loss: 0.0771\n",
      "Epoch 216/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 4.4167e-04 - val_loss: 0.0773\n",
      "Epoch 217/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 4.3890e-04 - val_loss: 0.0774\n",
      "Epoch 218/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 4.2692e-04 - val_loss: 0.0776\n",
      "Epoch 219/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 4.2098e-04 - val_loss: 0.0778\n",
      "Epoch 220/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 4.1364e-04 - val_loss: 0.0780\n",
      "Epoch 221/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 4.1330e-04 - val_loss: 0.0783\n",
      "Epoch 222/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 4.0198e-04 - val_loss: 0.0784\n",
      "Epoch 223/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 4.0450e-04 - val_loss: 0.0785\n",
      "Epoch 224/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 3.9372e-04 - val_loss: 0.0788\n",
      "Epoch 225/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 3.8913e-04 - val_loss: 0.0788\n",
      "Epoch 226/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 3.8263e-04 - val_loss: 0.0790\n",
      "Epoch 227/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 3.7586e-04 - val_loss: 0.0791\n",
      "Epoch 228/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 3.6945e-04 - val_loss: 0.0794\n",
      "Epoch 229/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 3.6555e-04 - val_loss: 0.0796\n",
      "Epoch 230/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 3.6315e-04 - val_loss: 0.0797\n",
      "Epoch 231/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 3.5668e-04 - val_loss: 0.0799\n",
      "Epoch 232/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 3.5029e-04 - val_loss: 0.0800\n",
      "Epoch 233/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 3.4842e-04 - val_loss: 0.0802\n",
      "Epoch 234/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 3.4629e-04 - val_loss: 0.0803\n",
      "Epoch 235/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 3.3876e-04 - val_loss: 0.0805\n",
      "Epoch 236/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 3.3617e-04 - val_loss: 0.0806\n",
      "Epoch 237/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 3.3174e-04 - val_loss: 0.0808\n",
      "Epoch 238/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 3.2355e-04 - val_loss: 0.0811\n",
      "Epoch 239/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 3.1734e-04 - val_loss: 0.0812\n",
      "Epoch 240/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 3.2468e-04 - val_loss: 0.0813\n",
      "Epoch 241/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 3.1329e-04 - val_loss: 0.0816\n",
      "Epoch 242/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 3.0690e-04 - val_loss: 0.0818\n",
      "Epoch 243/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 3.0308e-04 - val_loss: 0.0818\n",
      "Epoch 244/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 2.9862e-04 - val_loss: 0.0820\n",
      "Epoch 245/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 2.9358e-04 - val_loss: 0.0822\n",
      "Epoch 246/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 2.8949e-04 - val_loss: 0.0823\n",
      "Epoch 247/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 2.8626e-04 - val_loss: 0.0826\n",
      "Epoch 248/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 2.8590e-04 - val_loss: 0.0828\n",
      "Epoch 249/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 2.7662e-04 - val_loss: 0.0829\n",
      "Epoch 250/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 2.7301e-04 - val_loss: 0.0830\n",
      "Epoch 251/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 2.7290e-04 - val_loss: 0.0832\n",
      "Epoch 252/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 2.6962e-04 - val_loss: 0.0836\n",
      "Epoch 253/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 2.6719e-04 - val_loss: 0.0838\n",
      "Epoch 254/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 2.6075e-04 - val_loss: 0.0839\n",
      "Epoch 255/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 2.5720e-04 - val_loss: 0.0839\n",
      "Epoch 256/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 2.5572e-04 - val_loss: 0.0840\n",
      "Epoch 257/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 2.5062e-04 - val_loss: 0.0842\n",
      "Epoch 258/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 2.4764e-04 - val_loss: 0.0844\n",
      "Epoch 259/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 2.4306e-04 - val_loss: 0.0845\n",
      "Epoch 260/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 2.4478e-04 - val_loss: 0.0846\n",
      "Epoch 261/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 2.4178e-04 - val_loss: 0.0850\n",
      "Epoch 262/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 2.4220e-04 - val_loss: 0.0851\n",
      "Epoch 263/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 2.3315e-04 - val_loss: 0.0852\n",
      "Epoch 264/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 2.3031e-04 - val_loss: 0.0854\n",
      "Epoch 265/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 2.2848e-04 - val_loss: 0.0855\n",
      "Epoch 266/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 2.2092e-04 - val_loss: 0.0857\n",
      "Epoch 267/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 2.1966e-04 - val_loss: 0.0858\n",
      "Epoch 268/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 2.1768e-04 - val_loss: 0.0860\n",
      "Epoch 269/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 2.1368e-04 - val_loss: 0.0861\n",
      "Epoch 270/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 2.1755e-04 - val_loss: 0.0863\n",
      "Epoch 271/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 2.0895e-04 - val_loss: 0.0865\n",
      "Epoch 272/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 2.0862e-04 - val_loss: 0.0866\n",
      "Epoch 273/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 2.0458e-04 - val_loss: 0.0868\n",
      "Epoch 274/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 2.0166e-04 - val_loss: 0.0869\n",
      "Epoch 275/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 2.0216e-04 - val_loss: 0.0871\n",
      "Epoch 276/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 2.0237e-04 - val_loss: 0.0872\n",
      "Epoch 277/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.9469e-04 - val_loss: 0.0873\n",
      "Epoch 278/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.9514e-04 - val_loss: 0.0875\n",
      "Epoch 279/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.8973e-04 - val_loss: 0.0877\n",
      "Epoch 280/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.8837e-04 - val_loss: 0.0878\n",
      "Epoch 281/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.8446e-04 - val_loss: 0.0880\n",
      "Epoch 282/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.8242e-04 - val_loss: 0.0881\n",
      "Epoch 283/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.8007e-04 - val_loss: 0.0882\n",
      "Epoch 284/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.8014e-04 - val_loss: 0.0883\n",
      "Epoch 285/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.7708e-04 - val_loss: 0.0885\n",
      "Epoch 286/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.7384e-04 - val_loss: 0.0887\n",
      "Epoch 287/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.7200e-04 - val_loss: 0.0889\n",
      "Epoch 288/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.6950e-04 - val_loss: 0.0890\n",
      "Epoch 289/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.6730e-04 - val_loss: 0.0891\n",
      "Epoch 290/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.6711e-04 - val_loss: 0.0893\n",
      "Epoch 291/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.6346e-04 - val_loss: 0.0894\n",
      "Epoch 292/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.6403e-04 - val_loss: 0.0896\n",
      "Epoch 293/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.5886e-04 - val_loss: 0.0897\n",
      "Epoch 294/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.6019e-04 - val_loss: 0.0899\n",
      "Epoch 295/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.5642e-04 - val_loss: 0.0900\n",
      "Epoch 296/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.5440e-04 - val_loss: 0.0902\n",
      "Epoch 297/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.5224e-04 - val_loss: 0.0904\n",
      "Epoch 298/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.5082e-04 - val_loss: 0.0905\n",
      "Epoch 299/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.4932e-04 - val_loss: 0.0907\n",
      "Epoch 300/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.4793e-04 - val_loss: 0.0908\n",
      "Epoch 301/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.4754e-04 - val_loss: 0.0910\n",
      "Epoch 302/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.4807e-04 - val_loss: 0.0912\n",
      "Epoch 303/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.4356e-04 - val_loss: 0.0914\n",
      "Epoch 304/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.4098e-04 - val_loss: 0.0915\n",
      "Epoch 305/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.3977e-04 - val_loss: 0.0916\n",
      "Epoch 306/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.3721e-04 - val_loss: 0.0917\n",
      "Epoch 307/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.3588e-04 - val_loss: 0.0919\n",
      "Epoch 308/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.3482e-04 - val_loss: 0.0920\n",
      "Epoch 309/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.3295e-04 - val_loss: 0.0922\n",
      "Epoch 310/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.3197e-04 - val_loss: 0.0924\n",
      "Epoch 311/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.3064e-04 - val_loss: 0.0924\n",
      "Epoch 312/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.2914e-04 - val_loss: 0.0926\n",
      "Epoch 313/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.2910e-04 - val_loss: 0.0929\n",
      "Epoch 314/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.2685e-04 - val_loss: 0.0930\n",
      "Epoch 315/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.2560e-04 - val_loss: 0.0931\n",
      "Epoch 316/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.2227e-04 - val_loss: 0.0933\n",
      "Epoch 317/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.2179e-04 - val_loss: 0.0934\n",
      "Epoch 318/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.1984e-04 - val_loss: 0.0935\n",
      "Epoch 319/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.2040e-04 - val_loss: 0.0937\n",
      "Epoch 320/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.1914e-04 - val_loss: 0.0937\n",
      "Epoch 321/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.1700e-04 - val_loss: 0.0939\n",
      "Epoch 322/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.1717e-04 - val_loss: 0.0941\n",
      "Epoch 323/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.1431e-04 - val_loss: 0.0943\n",
      "Epoch 324/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.1226e-04 - val_loss: 0.0944\n",
      "Epoch 325/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.1178e-04 - val_loss: 0.0945\n",
      "Epoch 326/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.0971e-04 - val_loss: 0.0946\n",
      "Epoch 327/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.0858e-04 - val_loss: 0.0949\n",
      "Epoch 328/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.0838e-04 - val_loss: 0.0950\n",
      "Epoch 329/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.0624e-04 - val_loss: 0.0951\n",
      "Epoch 330/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.0671e-04 - val_loss: 0.0953\n",
      "Epoch 331/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.0428e-04 - val_loss: 0.0954\n",
      "Epoch 332/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.0284e-04 - val_loss: 0.0956\n",
      "Epoch 333/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.0217e-04 - val_loss: 0.0957\n",
      "Epoch 334/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.0113e-04 - val_loss: 0.0958\n",
      "Epoch 335/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.0018e-04 - val_loss: 0.0959\n",
      "Epoch 336/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 9.8828e-05 - val_loss: 0.0961\n",
      "Epoch 337/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 9.8762e-05 - val_loss: 0.0963\n",
      "Epoch 338/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 9.6504e-05 - val_loss: 0.0964\n",
      "Epoch 339/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 9.5953e-05 - val_loss: 0.0965\n",
      "Epoch 340/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 9.4925e-05 - val_loss: 0.0967\n",
      "Epoch 341/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 9.3923e-05 - val_loss: 0.0969\n",
      "Epoch 342/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 9.3211e-05 - val_loss: 0.0970\n",
      "Epoch 343/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 9.1740e-05 - val_loss: 0.0971\n",
      "Epoch 344/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 9.2465e-05 - val_loss: 0.0973\n",
      "Epoch 345/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 8.9777e-05 - val_loss: 0.0974\n",
      "Epoch 346/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 8.9923e-05 - val_loss: 0.0975\n",
      "Epoch 347/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 8.8651e-05 - val_loss: 0.0977\n",
      "Epoch 348/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 8.6652e-05 - val_loss: 0.0978\n",
      "Epoch 349/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 8.6391e-05 - val_loss: 0.0979\n",
      "Epoch 350/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 8.5181e-05 - val_loss: 0.0981\n",
      "Epoch 351/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 8.4251e-05 - val_loss: 0.0983\n",
      "Epoch 352/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 8.3552e-05 - val_loss: 0.0984\n",
      "Epoch 353/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 8.2468e-05 - val_loss: 0.0985\n",
      "Epoch 354/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 8.1524e-05 - val_loss: 0.0987\n",
      "Epoch 355/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 8.0909e-05 - val_loss: 0.0989\n",
      "Epoch 356/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 7.9723e-05 - val_loss: 0.0989\n",
      "Epoch 357/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 7.8556e-05 - val_loss: 0.0991\n",
      "Epoch 358/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 7.8393e-05 - val_loss: 0.0992\n",
      "Epoch 359/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 7.7497e-05 - val_loss: 0.0994\n",
      "Epoch 360/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 7.6397e-05 - val_loss: 0.0995\n",
      "Epoch 361/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 7.6731e-05 - val_loss: 0.0997\n",
      "Epoch 362/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 7.5458e-05 - val_loss: 0.0998\n",
      "Epoch 363/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 7.5239e-05 - val_loss: 0.1000\n",
      "Epoch 364/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 7.4923e-05 - val_loss: 0.1001\n",
      "Epoch 365/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 7.4231e-05 - val_loss: 0.1003\n",
      "Epoch 366/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 7.2325e-05 - val_loss: 0.1004\n",
      "Epoch 367/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 7.1468e-05 - val_loss: 0.1006\n",
      "Epoch 368/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 7.0894e-05 - val_loss: 0.1007\n",
      "Epoch 369/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 7.0396e-05 - val_loss: 0.1009\n",
      "Epoch 370/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 7.0382e-05 - val_loss: 0.1010\n",
      "Epoch 371/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 6.8611e-05 - val_loss: 0.1011\n",
      "Epoch 372/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 6.7529e-05 - val_loss: 0.1012\n",
      "Epoch 373/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 6.7062e-05 - val_loss: 0.1014\n",
      "Epoch 374/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 6.6094e-05 - val_loss: 0.1016\n",
      "Epoch 375/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 6.6047e-05 - val_loss: 0.1017\n",
      "Epoch 376/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 6.6857e-05 - val_loss: 0.1018\n",
      "Epoch 377/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 6.4683e-05 - val_loss: 0.1020\n",
      "Epoch 378/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 6.3607e-05 - val_loss: 0.1021\n",
      "Epoch 379/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 6.3168e-05 - val_loss: 0.1023\n",
      "Epoch 380/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 6.2124e-05 - val_loss: 0.1024\n",
      "Epoch 381/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 6.1571e-05 - val_loss: 0.1026\n",
      "Epoch 382/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 6.0979e-05 - val_loss: 0.1026\n",
      "Epoch 383/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 6.0278e-05 - val_loss: 0.1028\n",
      "Epoch 384/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 6.0412e-05 - val_loss: 0.1030\n",
      "Epoch 385/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 5.9789e-05 - val_loss: 0.1031\n",
      "Epoch 386/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 5.9226e-05 - val_loss: 0.1032\n",
      "Epoch 387/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 5.7897e-05 - val_loss: 0.1033\n",
      "Epoch 388/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 5.7252e-05 - val_loss: 0.1035\n",
      "Epoch 389/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 5.7207e-05 - val_loss: 0.1035\n",
      "Epoch 390/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 5.7392e-05 - val_loss: 0.1037\n",
      "Epoch 391/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 5.5690e-05 - val_loss: 0.1039\n",
      "Epoch 392/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 5.5064e-05 - val_loss: 0.1040\n",
      "Epoch 393/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 5.4683e-05 - val_loss: 0.1041\n",
      "Epoch 394/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 5.4432e-05 - val_loss: 0.1042\n",
      "Epoch 395/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 5.3577e-05 - val_loss: 0.1044\n",
      "Epoch 396/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 5.3002e-05 - val_loss: 0.1045\n",
      "Epoch 397/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 5.2457e-05 - val_loss: 0.1047\n",
      "Epoch 398/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 5.2297e-05 - val_loss: 0.1048\n",
      "Epoch 399/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 5.1957e-05 - val_loss: 0.1049\n",
      "Epoch 400/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 5.1182e-05 - val_loss: 0.1051\n",
      "Epoch 401/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 5.0546e-05 - val_loss: 0.1052\n",
      "Epoch 402/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 5.0517e-05 - val_loss: 0.1054\n",
      "Epoch 403/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 4.9681e-05 - val_loss: 0.1055\n",
      "Epoch 404/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 4.9250e-05 - val_loss: 0.1057\n",
      "Epoch 405/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 4.8854e-05 - val_loss: 0.1058\n",
      "Epoch 406/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 4.8337e-05 - val_loss: 0.1059\n",
      "Epoch 407/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 4.7935e-05 - val_loss: 0.1060\n",
      "Epoch 408/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 4.7364e-05 - val_loss: 0.1061\n",
      "Epoch 409/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 4.6978e-05 - val_loss: 0.1063\n",
      "Epoch 410/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 4.7019e-05 - val_loss: 0.1065\n",
      "Epoch 411/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 4.6591e-05 - val_loss: 0.1065\n",
      "Epoch 412/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 4.5341e-05 - val_loss: 0.1067\n",
      "Epoch 413/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 4.5206e-05 - val_loss: 0.1068\n",
      "Epoch 414/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 4.5058e-05 - val_loss: 0.1070\n",
      "Epoch 415/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 4.4121e-05 - val_loss: 0.1071\n",
      "Epoch 416/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 4.3898e-05 - val_loss: 0.1072\n",
      "Epoch 417/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 4.3761e-05 - val_loss: 0.1074\n",
      "Epoch 418/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 4.3080e-05 - val_loss: 0.1075\n",
      "Epoch 419/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 4.2702e-05 - val_loss: 0.1077\n",
      "Epoch 420/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 4.3117e-05 - val_loss: 0.1078\n",
      "Epoch 421/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 4.1486e-05 - val_loss: 0.1079\n",
      "Epoch 422/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 4.1365e-05 - val_loss: 0.1081\n",
      "Epoch 423/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 4.1134e-05 - val_loss: 0.1082\n",
      "Epoch 424/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 4.0676e-05 - val_loss: 0.1084\n",
      "Epoch 425/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 4.0323e-05 - val_loss: 0.1085\n",
      "Epoch 426/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 3.9779e-05 - val_loss: 0.1086\n",
      "Epoch 427/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 3.9402e-05 - val_loss: 0.1087\n",
      "Epoch 428/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 3.9176e-05 - val_loss: 0.1089\n",
      "Epoch 429/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 3.8687e-05 - val_loss: 0.1089\n",
      "Epoch 430/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 3.8373e-05 - val_loss: 0.1091\n",
      "Epoch 431/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 3.7797e-05 - val_loss: 0.1092\n",
      "Epoch 432/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 3.7595e-05 - val_loss: 0.1094\n",
      "Epoch 433/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 3.7509e-05 - val_loss: 0.1095\n",
      "Epoch 434/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 3.6975e-05 - val_loss: 0.1096\n",
      "Epoch 435/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 3.6935e-05 - val_loss: 0.1097\n",
      "Epoch 436/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 3.6224e-05 - val_loss: 0.1099\n",
      "Epoch 437/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 3.6312e-05 - val_loss: 0.1099\n",
      "Epoch 438/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 3.5535e-05 - val_loss: 0.1101\n",
      "Epoch 439/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 3.5541e-05 - val_loss: 0.1103\n",
      "Epoch 440/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 3.6529e-05 - val_loss: 0.1105\n",
      "Epoch 441/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 3.5087e-05 - val_loss: 0.1107\n",
      "Epoch 442/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 3.4510e-05 - val_loss: 0.1108\n",
      "Epoch 443/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 3.3906e-05 - val_loss: 0.1109\n",
      "Epoch 444/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 3.3837e-05 - val_loss: 0.1110\n",
      "Epoch 445/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 3.3223e-05 - val_loss: 0.1111\n",
      "Epoch 446/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 3.2963e-05 - val_loss: 0.1113\n",
      "Epoch 447/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 3.2584e-05 - val_loss: 0.1114\n",
      "Epoch 448/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 3.2461e-05 - val_loss: 0.1115\n",
      "Epoch 449/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 3.2114e-05 - val_loss: 0.1116\n",
      "Epoch 450/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 3.1811e-05 - val_loss: 0.1117\n",
      "Epoch 451/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 3.1516e-05 - val_loss: 0.1118\n",
      "Epoch 452/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 3.1281e-05 - val_loss: 0.1120\n",
      "Epoch 453/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 3.0868e-05 - val_loss: 0.1121\n",
      "Epoch 454/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 3.0583e-05 - val_loss: 0.1122\n",
      "Epoch 455/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 3.0389e-05 - val_loss: 0.1123\n",
      "Epoch 456/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 3.0146e-05 - val_loss: 0.1125\n",
      "Epoch 457/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 2.9913e-05 - val_loss: 0.1126\n",
      "Epoch 458/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 2.9691e-05 - val_loss: 0.1127\n",
      "Epoch 459/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 3.0391e-05 - val_loss: 0.1128\n",
      "Epoch 460/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 2.9413e-05 - val_loss: 0.1130\n",
      "Epoch 461/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 2.8896e-05 - val_loss: 0.1131\n",
      "Epoch 462/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 2.8604e-05 - val_loss: 0.1133\n",
      "Epoch 463/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 2.8403e-05 - val_loss: 0.1133\n",
      "Epoch 464/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 2.8033e-05 - val_loss: 0.1135\n",
      "Epoch 465/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 2.7704e-05 - val_loss: 0.1136\n",
      "Epoch 466/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 2.7373e-05 - val_loss: 0.1137\n",
      "Epoch 467/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 2.7025e-05 - val_loss: 0.1138\n",
      "Epoch 468/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 2.6949e-05 - val_loss: 0.1139\n",
      "Epoch 469/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 2.6664e-05 - val_loss: 0.1140\n",
      "Epoch 470/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 2.6228e-05 - val_loss: 0.1142\n",
      "Epoch 471/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 2.6245e-05 - val_loss: 0.1144\n",
      "Epoch 472/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 2.6020e-05 - val_loss: 0.1145\n",
      "Epoch 473/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 2.5629e-05 - val_loss: 0.1146\n",
      "Epoch 474/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 2.5455e-05 - val_loss: 0.1147\n",
      "Epoch 475/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 2.5248e-05 - val_loss: 0.1148\n",
      "Epoch 476/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 2.5188e-05 - val_loss: 0.1150\n",
      "Epoch 477/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 2.5073e-05 - val_loss: 0.1151\n",
      "Epoch 478/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 2.4400e-05 - val_loss: 0.1152\n",
      "Epoch 479/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 2.4335e-05 - val_loss: 0.1153\n",
      "Epoch 480/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 2.4120e-05 - val_loss: 0.1154\n",
      "Epoch 481/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 2.3866e-05 - val_loss: 0.1155\n",
      "Epoch 482/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 2.3750e-05 - val_loss: 0.1157\n",
      "Epoch 483/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 2.3431e-05 - val_loss: 0.1158\n",
      "Epoch 484/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 2.3224e-05 - val_loss: 0.1159\n",
      "Epoch 485/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 2.3115e-05 - val_loss: 0.1161\n",
      "Epoch 486/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 2.3018e-05 - val_loss: 0.1162\n",
      "Epoch 487/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 2.2705e-05 - val_loss: 0.1163\n",
      "Epoch 488/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 2.2472e-05 - val_loss: 0.1164\n",
      "Epoch 489/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 2.2255e-05 - val_loss: 0.1166\n",
      "Epoch 490/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 2.2854e-05 - val_loss: 0.1167\n",
      "Epoch 491/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 2.2099e-05 - val_loss: 0.1168\n",
      "Epoch 492/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 2.1721e-05 - val_loss: 0.1170\n",
      "Epoch 493/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 2.1540e-05 - val_loss: 0.1172\n",
      "Epoch 494/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 2.1305e-05 - val_loss: 0.1173\n",
      "Epoch 495/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 2.1355e-05 - val_loss: 0.1174\n",
      "Epoch 496/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 2.1017e-05 - val_loss: 0.1175\n",
      "Epoch 497/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 2.0722e-05 - val_loss: 0.1176\n",
      "Epoch 498/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 2.0444e-05 - val_loss: 0.1177\n",
      "Epoch 499/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 2.0295e-05 - val_loss: 0.1179\n",
      "Epoch 500/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 2.0270e-05 - val_loss: 0.1180\n",
      "Epoch 501/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.9942e-05 - val_loss: 0.1181\n",
      "Epoch 502/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.9879e-05 - val_loss: 0.1182\n",
      "Epoch 503/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.9670e-05 - val_loss: 0.1183\n",
      "Epoch 504/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.9585e-05 - val_loss: 0.1185\n",
      "Epoch 505/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.9236e-05 - val_loss: 0.1186\n",
      "Epoch 506/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.9100e-05 - val_loss: 0.1187\n",
      "Epoch 507/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.8913e-05 - val_loss: 0.1188\n",
      "Epoch 508/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.8818e-05 - val_loss: 0.1190\n",
      "Epoch 509/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.8599e-05 - val_loss: 0.1191\n",
      "Epoch 510/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.8516e-05 - val_loss: 0.1192\n",
      "Epoch 511/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.8405e-05 - val_loss: 0.1193\n",
      "Epoch 512/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.8150e-05 - val_loss: 0.1195\n",
      "Epoch 513/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.7952e-05 - val_loss: 0.1196\n",
      "Epoch 514/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.7806e-05 - val_loss: 0.1197\n",
      "Epoch 515/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.7824e-05 - val_loss: 0.1198\n",
      "Epoch 516/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.7551e-05 - val_loss: 0.1199\n",
      "Epoch 517/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.7525e-05 - val_loss: 0.1201\n",
      "Epoch 518/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.7358e-05 - val_loss: 0.1202\n",
      "Epoch 519/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.7115e-05 - val_loss: 0.1203\n",
      "Epoch 520/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.7179e-05 - val_loss: 0.1204\n",
      "Epoch 521/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.6875e-05 - val_loss: 0.1205\n",
      "Epoch 522/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.6667e-05 - val_loss: 0.1206\n",
      "Epoch 523/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.6618e-05 - val_loss: 0.1207\n",
      "Epoch 524/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.6318e-05 - val_loss: 0.1208\n",
      "Epoch 525/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.6234e-05 - val_loss: 0.1210\n",
      "Epoch 526/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.6164e-05 - val_loss: 0.1211\n",
      "Epoch 527/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.5953e-05 - val_loss: 0.1212\n",
      "Epoch 528/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.5893e-05 - val_loss: 0.1214\n",
      "Epoch 529/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.5688e-05 - val_loss: 0.1214\n",
      "Epoch 530/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.5573e-05 - val_loss: 0.1216\n",
      "Epoch 531/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.5407e-05 - val_loss: 0.1218\n",
      "Epoch 532/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.5297e-05 - val_loss: 0.1219\n",
      "Epoch 533/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.5108e-05 - val_loss: 0.1220\n",
      "Epoch 534/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.5033e-05 - val_loss: 0.1221\n",
      "Epoch 535/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.4828e-05 - val_loss: 0.1222\n",
      "Epoch 536/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.4676e-05 - val_loss: 0.1223\n",
      "Epoch 537/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.4668e-05 - val_loss: 0.1224\n",
      "Epoch 538/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.4766e-05 - val_loss: 0.1226\n",
      "Epoch 539/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.4534e-05 - val_loss: 0.1227\n",
      "Epoch 540/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.4342e-05 - val_loss: 0.1228\n",
      "Epoch 541/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.4385e-05 - val_loss: 0.1230\n",
      "Epoch 542/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.3978e-05 - val_loss: 0.1231\n",
      "Epoch 543/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.3857e-05 - val_loss: 0.1232\n",
      "Epoch 544/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.3718e-05 - val_loss: 0.1233\n",
      "Epoch 545/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.3555e-05 - val_loss: 0.1235\n",
      "Epoch 546/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.3450e-05 - val_loss: 0.1236\n",
      "Epoch 547/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.3423e-05 - val_loss: 0.1237\n",
      "Epoch 548/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.3439e-05 - val_loss: 0.1239\n",
      "Epoch 549/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.3243e-05 - val_loss: 0.1240\n",
      "Epoch 550/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.3102e-05 - val_loss: 0.1240\n",
      "Epoch 551/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.2853e-05 - val_loss: 0.1242\n",
      "Epoch 552/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.2803e-05 - val_loss: 0.1243\n",
      "Epoch 553/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.2701e-05 - val_loss: 0.1244\n",
      "Epoch 554/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.2682e-05 - val_loss: 0.1245\n",
      "Epoch 555/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.2469e-05 - val_loss: 0.1247\n",
      "Epoch 556/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.2381e-05 - val_loss: 0.1248\n",
      "Epoch 557/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.2250e-05 - val_loss: 0.1249\n",
      "Epoch 558/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.2086e-05 - val_loss: 0.1250\n",
      "Epoch 559/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.2036e-05 - val_loss: 0.1251\n",
      "Epoch 560/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.1939e-05 - val_loss: 0.1252\n",
      "Epoch 561/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.1856e-05 - val_loss: 0.1254\n",
      "Epoch 562/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.1758e-05 - val_loss: 0.1255\n",
      "Epoch 563/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.1631e-05 - val_loss: 0.1256\n",
      "Epoch 564/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.1540e-05 - val_loss: 0.1257\n",
      "Epoch 565/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.1445e-05 - val_loss: 0.1259\n",
      "Epoch 566/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.1302e-05 - val_loss: 0.1259\n",
      "Epoch 567/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.1261e-05 - val_loss: 0.1261\n",
      "Epoch 568/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.1299e-05 - val_loss: 0.1262\n",
      "Epoch 569/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.0968e-05 - val_loss: 0.1263\n",
      "Epoch 570/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.0954e-05 - val_loss: 0.1264\n",
      "Epoch 571/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.0789e-05 - val_loss: 0.1267\n",
      "Epoch 572/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.0774e-05 - val_loss: 0.1267\n",
      "Epoch 573/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.0700e-05 - val_loss: 0.1268\n",
      "Epoch 574/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.0584e-05 - val_loss: 0.1270\n",
      "Epoch 575/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.0502e-05 - val_loss: 0.1271\n",
      "Epoch 576/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.0385e-05 - val_loss: 0.1272\n",
      "Epoch 577/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.0288e-05 - val_loss: 0.1273\n",
      "Epoch 578/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.0188e-05 - val_loss: 0.1274\n",
      "Epoch 579/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.0156e-05 - val_loss: 0.1276\n",
      "Epoch 580/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.0042e-05 - val_loss: 0.1277\n",
      "Epoch 581/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 9.9228e-06 - val_loss: 0.1279\n",
      "Epoch 582/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 9.8861e-06 - val_loss: 0.1280\n",
      "Epoch 583/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 9.7785e-06 - val_loss: 0.1281\n",
      "Epoch 584/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 9.6665e-06 - val_loss: 0.1282\n",
      "Epoch 585/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 9.6247e-06 - val_loss: 0.1283\n",
      "Epoch 586/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 9.5143e-06 - val_loss: 0.1284\n",
      "Epoch 587/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 9.4706e-06 - val_loss: 0.1285\n",
      "Epoch 588/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 9.3459e-06 - val_loss: 0.1287\n",
      "Epoch 589/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 9.3730e-06 - val_loss: 0.1287\n",
      "Epoch 590/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 9.2425e-06 - val_loss: 0.1289\n",
      "Epoch 591/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 9.1819e-06 - val_loss: 0.1290\n",
      "Epoch 592/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 9.0719e-06 - val_loss: 0.1291\n",
      "Epoch 593/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 9.0342e-06 - val_loss: 0.1292\n",
      "Epoch 594/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 8.9677e-06 - val_loss: 0.1294\n",
      "Epoch 595/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 8.8622e-06 - val_loss: 0.1295\n",
      "Epoch 596/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 8.8275e-06 - val_loss: 0.1296\n",
      "Epoch 597/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 8.7307e-06 - val_loss: 0.1297\n",
      "Epoch 598/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 8.6116e-06 - val_loss: 0.1298\n",
      "Epoch 599/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 8.5467e-06 - val_loss: 0.1300\n",
      "Epoch 600/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 8.5675e-06 - val_loss: 0.1301\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5ac875fc40>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train, epochs=600, validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.847443</td>\n",
       "      <td>0.647770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.580443</td>\n",
       "      <td>0.484444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.445931</td>\n",
       "      <td>0.381853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.354246</td>\n",
       "      <td>0.304810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.286004</td>\n",
       "      <td>0.247484</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       loss  val_loss\n",
       "0  0.847443  0.647770\n",
       "1  0.580443  0.484444\n",
       "2  0.445931  0.381853\n",
       "3  0.354246  0.304810\n",
       "4  0.286004  0.247484"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = pd.DataFrame(model.history.history)\n",
    "loss[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss.plot()     # this is an example for overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98        63\n",
      "           1       0.98      1.00      0.99       108\n",
      "\n",
      "    accuracy                           0.99       171\n",
      "   macro avg       0.99      0.98      0.99       171\n",
      "weighted avg       0.99      0.99      0.99       171\n",
      "\n",
      "[[ 61   2]\n",
      " [  0 108]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "print(classification_report(y_test,pred.round()))\n",
    "print(confusion_matrix(y_test,pred.round()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Intially, both the training loss and validation loss decreases\n",
    "- But at certain point of time, we notice that our training loss is still going on down, but our validation loss starts to increase\n",
    "- Which means, we are overfitting to our training dataset\n",
    "- Which means, we are training for way too many epochs\n",
    "- So, we try to prevent overfitting by using early stopping and dropout layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Creating a TensorBoard Callback</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss',mode='min',verbose=1,patience=25)\n",
    "\n",
    "# If our metric is accuracy, then mode='max', because we need to max the accuracy\n",
    "# If our metric is loss, then mode='min', because we need to reduce the loss\n",
    "# patience = 25 means that we will wait for 25 epochs more, even after detecting a stopping point because of noise that could occur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/studio-lab-user/sagemaker-studiolab-notebooks/Deep-Learning/Notebook/TensorBoard'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2022-03-16--1902'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "datetime.now().strftime(\"%Y-%m-%d--%H%M\")    # this will make sure we will have a unique log for each time you run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_directory = 'logs\\fit'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-16 19:06:48.571569: I tensorflow/core/profiler/lib/profiler_session.cc:110] Profiler session initializing.\n",
      "2022-03-16 19:06:48.571598: I tensorflow/core/profiler/lib/profiler_session.cc:125] Profiler session started.\n",
      "2022-03-16 19:06:48.575239: I tensorflow/core/profiler/lib/profiler_session.cc:143] Profiler session tear down.\n"
     ]
    }
   ],
   "source": [
    "board = TensorBoard(log_dir=log_directory, histogram_freq=1,\n",
    "                   write_graph=True,\n",
    "                   write_images=True,\n",
    "                   update_freq='epoch',\n",
    "                   profile_batch=2,embeddings_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(30, activation='relu'))     # hidden layer 1\n",
    "model.add(Dense(15, activation='relu'))     # hidden layer 2\n",
    "model.add(Dense(1,activation = 'sigmoid'))  # output layer, sigmoidal because it's an binary classifcation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class EarlyStopping in module keras.callbacks:\n",
      "\n",
      "class EarlyStopping(Callback)\n",
      " |  EarlyStopping(monitor='val_loss', min_delta=0, patience=0, verbose=0, mode='auto', baseline=None, restore_best_weights=False)\n",
      " |  \n",
      " |  Stop training when a monitored metric has stopped improving.\n",
      " |  \n",
      " |  Assuming the goal of a training is to minimize the loss. With this, the\n",
      " |  metric to be monitored would be `'loss'`, and mode would be `'min'`. A\n",
      " |  `model.fit()` training loop will check at end of every epoch whether\n",
      " |  the loss is no longer decreasing, considering the `min_delta` and\n",
      " |  `patience` if applicable. Once it's found no longer decreasing,\n",
      " |  `model.stop_training` is marked True and the training terminates.\n",
      " |  \n",
      " |  The quantity to be monitored needs to be available in `logs` dict.\n",
      " |  To make it so, pass the loss or metrics at `model.compile()`.\n",
      " |  \n",
      " |  Args:\n",
      " |    monitor: Quantity to be monitored.\n",
      " |    min_delta: Minimum change in the monitored quantity\n",
      " |        to qualify as an improvement, i.e. an absolute\n",
      " |        change of less than min_delta, will count as no\n",
      " |        improvement.\n",
      " |    patience: Number of epochs with no improvement\n",
      " |        after which training will be stopped.\n",
      " |    verbose: verbosity mode.\n",
      " |    mode: One of `{\"auto\", \"min\", \"max\"}`. In `min` mode,\n",
      " |        training will stop when the quantity\n",
      " |        monitored has stopped decreasing; in `\"max\"`\n",
      " |        mode it will stop when the quantity\n",
      " |        monitored has stopped increasing; in `\"auto\"`\n",
      " |        mode, the direction is automatically inferred\n",
      " |        from the name of the monitored quantity.\n",
      " |    baseline: Baseline value for the monitored quantity.\n",
      " |        Training will stop if the model doesn't show improvement over the\n",
      " |        baseline.\n",
      " |    restore_best_weights: Whether to restore model weights from\n",
      " |        the epoch with the best value of the monitored quantity.\n",
      " |        If False, the model weights obtained at the last step of\n",
      " |        training are used. An epoch will be restored regardless\n",
      " |        of the performance relative to the `baseline`. If no epoch\n",
      " |        improves on `baseline`, training will run for `patience`\n",
      " |        epochs and restore weights from the best epoch in that set.\n",
      " |  \n",
      " |  Example:\n",
      " |  \n",
      " |  >>> callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
      " |  >>> # This callback will stop the training when there is no improvement in\n",
      " |  >>> # the loss for three consecutive epochs.\n",
      " |  >>> model = tf.keras.models.Sequential([tf.keras.layers.Dense(10)])\n",
      " |  >>> model.compile(tf.keras.optimizers.SGD(), loss='mse')\n",
      " |  >>> history = model.fit(np.arange(100).reshape(5, 20), np.zeros(5),\n",
      " |  ...                     epochs=10, batch_size=1, callbacks=[callback],\n",
      " |  ...                     verbose=0)\n",
      " |  >>> len(history.history['loss'])  # Only 4 epochs are run.\n",
      " |  4\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      EarlyStopping\n",
      " |      Callback\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, monitor='val_loss', min_delta=0, patience=0, verbose=0, mode='auto', baseline=None, restore_best_weights=False)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  get_monitor_value(self, logs)\n",
      " |  \n",
      " |  on_epoch_end(self, epoch, logs=None)\n",
      " |      Called at the end of an epoch.\n",
      " |      \n",
      " |      Subclasses should override for any actions to run. This function should only\n",
      " |      be called during TRAIN mode.\n",
      " |      \n",
      " |      Args:\n",
      " |          epoch: Integer, index of epoch.\n",
      " |          logs: Dict, metric results for this training epoch, and for the\n",
      " |            validation epoch if validation is performed. Validation result keys\n",
      " |            are prefixed with `val_`. For training epoch, the values of the\n",
      " |           `Model`'s metrics are returned. Example : `{'loss': 0.2, 'accuracy':\n",
      " |             0.7}`.\n",
      " |  \n",
      " |  on_train_begin(self, logs=None)\n",
      " |      Called at the beginning of training.\n",
      " |      \n",
      " |      Subclasses should override for any actions to run.\n",
      " |      \n",
      " |      Args:\n",
      " |          logs: Dict. Currently no data is passed to this argument for this method\n",
      " |            but that may change in the future.\n",
      " |  \n",
      " |  on_train_end(self, logs=None)\n",
      " |      Called at the end of training.\n",
      " |      \n",
      " |      Subclasses should override for any actions to run.\n",
      " |      \n",
      " |      Args:\n",
      " |          logs: Dict. Currently the output of the last call to `on_epoch_end()`\n",
      " |            is passed to this argument for this method but that may change in\n",
      " |            the future.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from Callback:\n",
      " |  \n",
      " |  on_batch_begin(self, batch, logs=None)\n",
      " |      A backwards compatibility alias for `on_train_batch_begin`.\n",
      " |  \n",
      " |  on_batch_end(self, batch, logs=None)\n",
      " |      A backwards compatibility alias for `on_train_batch_end`.\n",
      " |  \n",
      " |  on_epoch_begin(self, epoch, logs=None)\n",
      " |      Called at the start of an epoch.\n",
      " |      \n",
      " |      Subclasses should override for any actions to run. This function should only\n",
      " |      be called during TRAIN mode.\n",
      " |      \n",
      " |      Args:\n",
      " |          epoch: Integer, index of epoch.\n",
      " |          logs: Dict. Currently no data is passed to this argument for this method\n",
      " |            but that may change in the future.\n",
      " |  \n",
      " |  on_predict_batch_begin(self, batch, logs=None)\n",
      " |      Called at the beginning of a batch in `predict` methods.\n",
      " |      \n",
      " |      Subclasses should override for any actions to run.\n",
      " |      \n",
      " |      Note that if the `steps_per_execution` argument to `compile` in\n",
      " |      `tf.keras.Model` is set to `N`, this method will only be called every `N`\n",
      " |      batches.\n",
      " |      \n",
      " |      Args:\n",
      " |          batch: Integer, index of batch within the current epoch.\n",
      " |          logs: Dict. Currently no data is passed to this argument for this method\n",
      " |            but that may change in the future.\n",
      " |  \n",
      " |  on_predict_batch_end(self, batch, logs=None)\n",
      " |      Called at the end of a batch in `predict` methods.\n",
      " |      \n",
      " |      Subclasses should override for any actions to run.\n",
      " |      \n",
      " |      Note that if the `steps_per_execution` argument to `compile` in\n",
      " |      `tf.keras.Model` is set to `N`, this method will only be called every `N`\n",
      " |      batches.\n",
      " |      \n",
      " |      Args:\n",
      " |          batch: Integer, index of batch within the current epoch.\n",
      " |          logs: Dict. Aggregated metric results up until this batch.\n",
      " |  \n",
      " |  on_predict_begin(self, logs=None)\n",
      " |      Called at the beginning of prediction.\n",
      " |      \n",
      " |      Subclasses should override for any actions to run.\n",
      " |      \n",
      " |      Args:\n",
      " |          logs: Dict. Currently no data is passed to this argument for this method\n",
      " |            but that may change in the future.\n",
      " |  \n",
      " |  on_predict_end(self, logs=None)\n",
      " |      Called at the end of prediction.\n",
      " |      \n",
      " |      Subclasses should override for any actions to run.\n",
      " |      \n",
      " |      Args:\n",
      " |          logs: Dict. Currently no data is passed to this argument for this method\n",
      " |            but that may change in the future.\n",
      " |  \n",
      " |  on_test_batch_begin(self, batch, logs=None)\n",
      " |      Called at the beginning of a batch in `evaluate` methods.\n",
      " |      \n",
      " |      Also called at the beginning of a validation batch in the `fit`\n",
      " |      methods, if validation data is provided.\n",
      " |      \n",
      " |      Subclasses should override for any actions to run.\n",
      " |      \n",
      " |      Note that if the `steps_per_execution` argument to `compile` in\n",
      " |      `tf.keras.Model` is set to `N`, this method will only be called every `N`\n",
      " |      batches.\n",
      " |      \n",
      " |      Args:\n",
      " |          batch: Integer, index of batch within the current epoch.\n",
      " |          logs: Dict. Currently no data is passed to this argument for this method\n",
      " |            but that may change in the future.\n",
      " |  \n",
      " |  on_test_batch_end(self, batch, logs=None)\n",
      " |      Called at the end of a batch in `evaluate` methods.\n",
      " |      \n",
      " |      Also called at the end of a validation batch in the `fit`\n",
      " |      methods, if validation data is provided.\n",
      " |      \n",
      " |      Subclasses should override for any actions to run.\n",
      " |      \n",
      " |      Note that if the `steps_per_execution` argument to `compile` in\n",
      " |      `tf.keras.Model` is set to `N`, this method will only be called every `N`\n",
      " |      batches.\n",
      " |      \n",
      " |      Args:\n",
      " |          batch: Integer, index of batch within the current epoch.\n",
      " |          logs: Dict. Aggregated metric results up until this batch.\n",
      " |  \n",
      " |  on_test_begin(self, logs=None)\n",
      " |      Called at the beginning of evaluation or validation.\n",
      " |      \n",
      " |      Subclasses should override for any actions to run.\n",
      " |      \n",
      " |      Args:\n",
      " |          logs: Dict. Currently no data is passed to this argument for this method\n",
      " |            but that may change in the future.\n",
      " |  \n",
      " |  on_test_end(self, logs=None)\n",
      " |      Called at the end of evaluation or validation.\n",
      " |      \n",
      " |      Subclasses should override for any actions to run.\n",
      " |      \n",
      " |      Args:\n",
      " |          logs: Dict. Currently the output of the last call to\n",
      " |            `on_test_batch_end()` is passed to this argument for this method\n",
      " |            but that may change in the future.\n",
      " |  \n",
      " |  on_train_batch_begin(self, batch, logs=None)\n",
      " |      Called at the beginning of a training batch in `fit` methods.\n",
      " |      \n",
      " |      Subclasses should override for any actions to run.\n",
      " |      \n",
      " |      Note that if the `steps_per_execution` argument to `compile` in\n",
      " |      `tf.keras.Model` is set to `N`, this method will only be called every `N`\n",
      " |      batches.\n",
      " |      \n",
      " |      Args:\n",
      " |          batch: Integer, index of batch within the current epoch.\n",
      " |          logs: Dict. Currently no data is passed to this argument for this method\n",
      " |            but that may change in the future.\n",
      " |  \n",
      " |  on_train_batch_end(self, batch, logs=None)\n",
      " |      Called at the end of a training batch in `fit` methods.\n",
      " |      \n",
      " |      Subclasses should override for any actions to run.\n",
      " |      \n",
      " |      Note that if the `steps_per_execution` argument to `compile` in\n",
      " |      `tf.keras.Model` is set to `N`, this method will only be called every `N`\n",
      " |      batches.\n",
      " |      \n",
      " |      Args:\n",
      " |          batch: Integer, index of batch within the current epoch.\n",
      " |          logs: Dict. Aggregated metric results up until this batch.\n",
      " |  \n",
      " |  set_model(self, model)\n",
      " |  \n",
      " |  set_params(self, params)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from Callback:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(EarlyStopping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      " 4/13 [========>.....................] - ETA: 0s - loss: 0.6011"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-16 19:07:18.989459: I tensorflow/core/profiler/lib/profiler_session.cc:110] Profiler session initializing.\n",
      "2022-03-16 19:07:18.989504: I tensorflow/core/profiler/lib/profiler_session.cc:125] Profiler session started.\n",
      "2022-03-16 19:07:18.992490: I tensorflow/core/profiler/lib/profiler_session.cc:67] Profiler session collecting data.\n",
      "2022-03-16 19:07:18.999049: I tensorflow/core/profiler/lib/profiler_session.cc:143] Profiler session tear down.\n",
      "2022-03-16 19:07:19.010155: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: logs\f",
      "it/plugins/profile/2022_03_16_19_07_19\n",
      "\n",
      "2022-03-16 19:07:19.014364: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for trace.json.gz to logs\f",
      "it/plugins/profile/2022_03_16_19_07_19/default.trace.json.gz\n",
      "2022-03-16 19:07:19.033695: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: logs\f",
      "it/plugins/profile/2022_03_16_19_07_19\n",
      "\n",
      "2022-03-16 19:07:19.033850: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for memory_profile.json.gz to logs\f",
      "it/plugins/profile/2022_03_16_19_07_19/default.memory_profile.json.gz\n",
      "2022-03-16 19:07:19.034154: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: logs\f",
      "it/plugins/profile/2022_03_16_19_07_19\n",
      "Dumped tool data for xplane.pb to logs\f",
      "it/plugins/profile/2022_03_16_19_07_19/default.xplane.pb\n",
      "Dumped tool data for overview_page.pb to logs\f",
      "it/plugins/profile/2022_03_16_19_07_19/default.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to logs\f",
      "it/plugins/profile/2022_03_16_19_07_19/default.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to logs\f",
      "it/plugins/profile/2022_03_16_19_07_19/default.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to logs\f",
      "it/plugins/profile/2022_03_16_19_07_19/default.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 1s 30ms/step - loss: 0.5481 - val_loss: 0.3973\n",
      "Epoch 2/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3658 - val_loss: 0.2698\n",
      "Epoch 3/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2700 - val_loss: 0.2064\n",
      "Epoch 4/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2172 - val_loss: 0.1662\n",
      "Epoch 5/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.1835 - val_loss: 0.1404\n",
      "Epoch 6/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.1603 - val_loss: 0.1229\n",
      "Epoch 7/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.1437 - val_loss: 0.1086\n",
      "Epoch 8/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.1290 - val_loss: 0.0982\n",
      "Epoch 9/600\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.1179 - val_loss: 0.0906\n",
      "Epoch 10/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.1088 - val_loss: 0.0835\n",
      "Epoch 11/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.1011 - val_loss: 0.0777\n",
      "Epoch 12/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0939 - val_loss: 0.0731\n",
      "Epoch 13/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0888 - val_loss: 0.0689\n",
      "Epoch 14/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0839 - val_loss: 0.0664\n",
      "Epoch 15/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0797 - val_loss: 0.0641\n",
      "Epoch 16/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0753 - val_loss: 0.0612\n",
      "Epoch 17/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0717 - val_loss: 0.0592\n",
      "Epoch 18/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0686 - val_loss: 0.0577\n",
      "Epoch 19/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0654 - val_loss: 0.0561\n",
      "Epoch 20/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0626 - val_loss: 0.0545\n",
      "Epoch 21/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0600 - val_loss: 0.0534\n",
      "Epoch 22/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0574 - val_loss: 0.0528\n",
      "Epoch 23/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0554 - val_loss: 0.0517\n",
      "Epoch 24/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0532 - val_loss: 0.0513\n",
      "Epoch 25/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0510 - val_loss: 0.0505\n",
      "Epoch 26/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0492 - val_loss: 0.0498\n",
      "Epoch 27/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0474 - val_loss: 0.0493\n",
      "Epoch 28/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0462 - val_loss: 0.0498\n",
      "Epoch 29/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0442 - val_loss: 0.0495\n",
      "Epoch 30/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0424 - val_loss: 0.0486\n",
      "Epoch 31/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0406 - val_loss: 0.0473\n",
      "Epoch 32/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0394 - val_loss: 0.0470\n",
      "Epoch 33/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0381 - val_loss: 0.0483\n",
      "Epoch 34/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0365 - val_loss: 0.0480\n",
      "Epoch 35/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0353 - val_loss: 0.0477\n",
      "Epoch 36/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0342 - val_loss: 0.0472\n",
      "Epoch 37/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0337 - val_loss: 0.0476\n",
      "Epoch 38/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0320 - val_loss: 0.0462\n",
      "Epoch 39/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0310 - val_loss: 0.0462\n",
      "Epoch 40/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0301 - val_loss: 0.0462\n",
      "Epoch 41/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0292 - val_loss: 0.0461\n",
      "Epoch 42/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0287 - val_loss: 0.0470\n",
      "Epoch 43/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0274 - val_loss: 0.0467\n",
      "Epoch 44/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0267 - val_loss: 0.0463\n",
      "Epoch 45/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0258 - val_loss: 0.0469\n",
      "Epoch 46/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0251 - val_loss: 0.0468\n",
      "Epoch 47/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0252 - val_loss: 0.0493\n",
      "Epoch 48/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0237 - val_loss: 0.0479\n",
      "Epoch 49/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0232 - val_loss: 0.0468\n",
      "Epoch 50/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0222 - val_loss: 0.0468\n",
      "Epoch 51/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0217 - val_loss: 0.0470\n",
      "Epoch 52/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0218 - val_loss: 0.0481\n",
      "Epoch 53/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0202 - val_loss: 0.0475\n",
      "Epoch 54/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0198 - val_loss: 0.0466\n",
      "Epoch 55/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0194 - val_loss: 0.0475\n",
      "Epoch 56/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0186 - val_loss: 0.0473\n",
      "Epoch 57/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0183 - val_loss: 0.0468\n",
      "Epoch 58/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0176 - val_loss: 0.0472\n",
      "Epoch 59/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0170 - val_loss: 0.0481\n",
      "Epoch 60/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0165 - val_loss: 0.0482\n",
      "Epoch 61/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0161 - val_loss: 0.0475\n",
      "Epoch 62/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0158 - val_loss: 0.0478\n",
      "Epoch 63/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0151 - val_loss: 0.0490\n",
      "Epoch 64/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0147 - val_loss: 0.0488\n",
      "Epoch 65/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0143 - val_loss: 0.0488\n",
      "Epoch 66/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0141 - val_loss: 0.0485\n",
      "Epoch 66: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5ab0cfdd00>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,epochs=600,validation_data=(X_test,y_test),callbacks=[early_stop, board])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs\f",
      "it\n"
     ]
    }
   ],
   "source": [
    "print(log_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/studio-lab-user/sagemaker-studiolab-notebooks/Deep-Learning/Notebook/TensorBoard'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.548076</td>\n",
       "      <td>0.397313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.365809</td>\n",
       "      <td>0.269762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.270040</td>\n",
       "      <td>0.206366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.217158</td>\n",
       "      <td>0.166179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.183471</td>\n",
       "      <td>0.140361</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       loss  val_loss\n",
       "0  0.548076  0.397313\n",
       "1  0.365809  0.269762\n",
       "2  0.270040  0.206366\n",
       "3  0.217158  0.166179\n",
       "4  0.183471  0.140361"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_loss = pd.DataFrame(model.history.history)\n",
    "model_loss[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_loss.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98        63\n",
      "           1       0.99      0.99      0.99       108\n",
      "\n",
      "    accuracy                           0.99       171\n",
      "   macro avg       0.99      0.99      0.99       171\n",
      "weighted avg       0.99      0.99      0.99       171\n",
      "\n",
      "[[ 62   1]\n",
      " [  1 107]]\n"
     ]
    }
   ],
   "source": [
    "pred_2 = model.predict(X_test)\n",
    "print(classification_report(y_test,pred_2.round()))\n",
    "print(confusion_matrix(y_test,pred_2.round()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Next, we can prevent overfitting by using dropout layers\n",
    "- Dropout layers will essentially turn off a percentage of neurons randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(30, activation='relu'))     # hidden layer 1\n",
    "model.add(Dropout(rate=0.5))\n",
    "model.add(Dense(15, activation='relu'))     # hidden layer 2\n",
    "model.add(Dropout(rate=0.5))\n",
    "model.add(Dense(1,activation = 'sigmoid'))  # output layer, sigmoidal because it's an binary classifcation\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam')\n",
    "\n",
    "# rate=0.5 means that 50% of neurons are going to be turned off randomly, which also means that each neuron has 50% chance of getting turned off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "13/13 [==============================] - 1s 12ms/step - loss: 0.8398 - val_loss: 0.5359\n",
      "Epoch 2/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.6649 - val_loss: 0.4106\n",
      "Epoch 3/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.5530 - val_loss: 0.3253\n",
      "Epoch 4/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4771 - val_loss: 0.2663\n",
      "Epoch 5/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.4654 - val_loss: 0.2270\n",
      "Epoch 6/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4258 - val_loss: 0.2003\n",
      "Epoch 7/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.3495 - val_loss: 0.1817\n",
      "Epoch 8/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.3656 - val_loss: 0.1664\n",
      "Epoch 9/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.3266 - val_loss: 0.1531\n",
      "Epoch 10/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.3564 - val_loss: 0.1427\n",
      "Epoch 11/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.3097 - val_loss: 0.1338\n",
      "Epoch 12/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.3265 - val_loss: 0.1249\n",
      "Epoch 13/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.3163 - val_loss: 0.1171\n",
      "Epoch 14/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.2588 - val_loss: 0.1106\n",
      "Epoch 15/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.2501 - val_loss: 0.1053\n",
      "Epoch 16/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.2374 - val_loss: 0.1003\n",
      "Epoch 17/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.2364 - val_loss: 0.0960\n",
      "Epoch 18/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1935 - val_loss: 0.0921\n",
      "Epoch 19/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.2033 - val_loss: 0.0879\n",
      "Epoch 20/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1995 - val_loss: 0.0831\n",
      "Epoch 21/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1977 - val_loss: 0.0789\n",
      "Epoch 22/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1831 - val_loss: 0.0752\n",
      "Epoch 23/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1873 - val_loss: 0.0724\n",
      "Epoch 24/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1538 - val_loss: 0.0705\n",
      "Epoch 25/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1861 - val_loss: 0.0689\n",
      "Epoch 26/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1725 - val_loss: 0.0669\n",
      "Epoch 27/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1843 - val_loss: 0.0646\n",
      "Epoch 28/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1496 - val_loss: 0.0628\n",
      "Epoch 29/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1667 - val_loss: 0.0612\n",
      "Epoch 30/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1505 - val_loss: 0.0590\n",
      "Epoch 31/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1382 - val_loss: 0.0569\n",
      "Epoch 32/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1402 - val_loss: 0.0556\n",
      "Epoch 33/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1286 - val_loss: 0.0549\n",
      "Epoch 34/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1477 - val_loss: 0.0544\n",
      "Epoch 35/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1469 - val_loss: 0.0532\n",
      "Epoch 36/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1213 - val_loss: 0.0520\n",
      "Epoch 37/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1056 - val_loss: 0.0507\n",
      "Epoch 38/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1210 - val_loss: 0.0506\n",
      "Epoch 39/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1619 - val_loss: 0.0515\n",
      "Epoch 40/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1014 - val_loss: 0.0524\n",
      "Epoch 41/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1258 - val_loss: 0.0516\n",
      "Epoch 42/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1275 - val_loss: 0.0506\n",
      "Epoch 43/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1050 - val_loss: 0.0505\n",
      "Epoch 44/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1039 - val_loss: 0.0510\n",
      "Epoch 45/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0921 - val_loss: 0.0508\n",
      "Epoch 46/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1219 - val_loss: 0.0509\n",
      "Epoch 47/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1010 - val_loss: 0.0501\n",
      "Epoch 48/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1286 - val_loss: 0.0487\n",
      "Epoch 49/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1293 - val_loss: 0.0474\n",
      "Epoch 50/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1178 - val_loss: 0.0457\n",
      "Epoch 51/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1179 - val_loss: 0.0445\n",
      "Epoch 52/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1182 - val_loss: 0.0446\n",
      "Epoch 53/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1207 - val_loss: 0.0449\n",
      "Epoch 54/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1331 - val_loss: 0.0456\n",
      "Epoch 55/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1301 - val_loss: 0.0446\n",
      "Epoch 56/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0827 - val_loss: 0.0438\n",
      "Epoch 57/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0977 - val_loss: 0.0440\n",
      "Epoch 58/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1074 - val_loss: 0.0446\n",
      "Epoch 59/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1051 - val_loss: 0.0452\n",
      "Epoch 60/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0895 - val_loss: 0.0446\n",
      "Epoch 61/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0986 - val_loss: 0.0441\n",
      "Epoch 62/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1165 - val_loss: 0.0436\n",
      "Epoch 63/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0828 - val_loss: 0.0442\n",
      "Epoch 64/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0998 - val_loss: 0.0441\n",
      "Epoch 65/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0705 - val_loss: 0.0444\n",
      "Epoch 66/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0855 - val_loss: 0.0443\n",
      "Epoch 67/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1088 - val_loss: 0.0450\n",
      "Epoch 68/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0869 - val_loss: 0.0449\n",
      "Epoch 69/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0828 - val_loss: 0.0440\n",
      "Epoch 70/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0788 - val_loss: 0.0430\n",
      "Epoch 71/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0761 - val_loss: 0.0423\n",
      "Epoch 72/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0930 - val_loss: 0.0425\n",
      "Epoch 73/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0734 - val_loss: 0.0428\n",
      "Epoch 74/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0988 - val_loss: 0.0424\n",
      "Epoch 75/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0770 - val_loss: 0.0417\n",
      "Epoch 76/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0731 - val_loss: 0.0415\n",
      "Epoch 77/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0789 - val_loss: 0.0416\n",
      "Epoch 78/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1002 - val_loss: 0.0421\n",
      "Epoch 79/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0788 - val_loss: 0.0426\n",
      "Epoch 80/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0906 - val_loss: 0.0423\n",
      "Epoch 81/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0950 - val_loss: 0.0415\n",
      "Epoch 82/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0759 - val_loss: 0.0409\n",
      "Epoch 83/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0785 - val_loss: 0.0411\n",
      "Epoch 84/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0802 - val_loss: 0.0409\n",
      "Epoch 85/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0772 - val_loss: 0.0403\n",
      "Epoch 86/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0935 - val_loss: 0.0410\n",
      "Epoch 87/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0642 - val_loss: 0.0414\n",
      "Epoch 88/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0653 - val_loss: 0.0418\n",
      "Epoch 89/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0689 - val_loss: 0.0418\n",
      "Epoch 90/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0781 - val_loss: 0.0424\n",
      "Epoch 91/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0720 - val_loss: 0.0427\n",
      "Epoch 92/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0635 - val_loss: 0.0422\n",
      "Epoch 93/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0618 - val_loss: 0.0428\n",
      "Epoch 94/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0637 - val_loss: 0.0425\n",
      "Epoch 95/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0699 - val_loss: 0.0419\n",
      "Epoch 96/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0716 - val_loss: 0.0429\n",
      "Epoch 97/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0700 - val_loss: 0.0451\n",
      "Epoch 98/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0762 - val_loss: 0.0482\n",
      "Epoch 99/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0701 - val_loss: 0.0490\n",
      "Epoch 100/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0741 - val_loss: 0.0487\n",
      "Epoch 101/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0628 - val_loss: 0.0485\n",
      "Epoch 102/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0793 - val_loss: 0.0473\n",
      "Epoch 103/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0763 - val_loss: 0.0473\n",
      "Epoch 104/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0579 - val_loss: 0.0471\n",
      "Epoch 105/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0768 - val_loss: 0.0466\n",
      "Epoch 106/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0838 - val_loss: 0.0458\n",
      "Epoch 107/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0650 - val_loss: 0.0454\n",
      "Epoch 108/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0640 - val_loss: 0.0459\n",
      "Epoch 109/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0578 - val_loss: 0.0461\n",
      "Epoch 110/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0534 - val_loss: 0.0463\n",
      "Epoch 110: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5ab0919bb0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,epochs=600,validation_data=[X_test,y_test],callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAA6XElEQVR4nO3deXhU1fnA8e87M9n3HUiAJOw7aIi4gbjiBi5VxKXu1H2rVmtba7Wtra1ry0/FpXVXXFqpoqiIgsoWMCxhCRC2hBCSAEnInpnz++NOIIGEDJBkmMn7eZ55krlz5t735sJ7zz33nHPFGINSSinfZ/N2AEoppdqHJnSllPITmtCVUspPaEJXSik/oQldKaX8hMNbG46Pjzepqane2rxSSvmkpUuXlhhjElr6zGsJPTU1laysLG9tXimlfJKIbGntM21yUUopP6EJXSml/IQmdKWU8hNea0NXSnVN9fX15OfnU1NT4+1QjmnBwcGkpKQQEBDg8Xc0oSulOlV+fj4RERGkpqYiIt4O55hkjKG0tJT8/HzS0tI8/p42uSilOlVNTQ1xcXGazA9BRIiLizvsqxhN6EqpTqfJvG1H8jfyuYS+ZPMunvxiLS6XTvurlFJN+VxCX75tD//37Ub21jV4OxSllI8KDw/3dggdwucSemSIdce3rKrey5EopdSxxfcSerCV0MtrNKErpY6OMYYHHniAoUOHMmzYMN5//30ACgsLGTt2LCNHjmTo0KHMnz8fp9PJddddt6/sM8884+XoD+Zz3RajGmvo1ZrQlfJ1f/hfDqu3l7frOgf3iOT3Fw7xqOzHH39MdnY2y5cvp6SkhNGjRzN27FjeeecdzjnnHH7zm9/gdDqpqqoiOzubgoICVq1aBcCePXvaNe724Hs19BDrHFRerW3oSqmj8/333zNlyhTsdjtJSUmMGzeOJUuWMHr0aP71r3/x6KOPsnLlSiIiIkhPTycvL48777yTL774gsjISG+HfxCfraGXaw1dKZ/naU26s40dO5Z58+bx2Wefcd1113Hffffx85//nOXLlzN79mxefPFFZsyYwWuvvebtUJvxwRq6tqErpdrHqaeeyvvvv4/T6aS4uJh58+aRmZnJli1bSEpK4uabb+amm25i2bJllJSU4HK5uPTSS/njH//IsmXLvB3+QTyqoYvIBOA5wA68Yoz5ywGf9wJeB6LdZR4yxsxq31At4YEObKJt6Eqpo3fxxRezYMECRowYgYjw5JNP0q1bN15//XX+9re/ERAQQHh4OG+88QYFBQVcf/31uFwuAJ544gkvR38wMebQA3RExA7kAmcB+cASYIoxZnWTMtOBn4wxL4jIYGCWMSb1UOvNyMgwR/qAixF/+JKLRvbgD5OGHtH3lVLes2bNGgYNGuTtMHxCS38rEVlqjMloqbwnTS6ZwAZjTJ4xpg54D5h0QBkDNN4hiAK2H1bUhykqJEBr6EopdQBPEnoysK3J+3z3sqYeBa4WkXxgFnBnSysSkakikiUiWcXFxUcQrkUTulJKHay9bopOAf5tjEkBzgPeFJGD1m2MmW6MyTDGZCQktPiMU49Ehjgor9Fui0op1ZQnCb0A6NnkfYp7WVM3AjMAjDELgGAgvj0CbInW0JVS6mCeJPQlQD8RSRORQOAKYOYBZbYCZwCIyCCshH7kbSptiAwO0H7oSil1gDYTujGmAbgDmA2sAWYYY3JE5DERmegu9kvgZhFZDrwLXGfa6j5zFLSGrpRSB/OoH7q7T/msA5Y90uT31cDJ7Rta6yJDAqhtcFFT7yQ4wN5Zm1VKqWOaz40UBR0tqpTqPIeaO33z5s0MHXrsjIfxzYQerBN0KaXUgXxuci7QKXSV8hufPwQ7VrbvOrsNg3P/0urHDz30ED179uT2228H4NFHH8XhcDB37lx2795NfX09f/zjH5k06cDxk4dWU1PDrbfeSlZWFg6Hg6effprx48eTk5PD9ddfT11dHS6Xi48++ogePXpw+eWXk5+fj9Pp5He/+x2TJ08+qt0GH03o2uSilDpSkydP5p577tmX0GfMmMHs2bO56667iIyMpKSkhDFjxjBx4sTDelDztGnTEBFWrlzJ2rVrOfvss8nNzeXFF1/k7rvv5qqrrqKurg6n08msWbPo0aMHn332GQBlZWXtsm8+mdB1Cl2l/MQhatIdZdSoUezcuZPt27dTXFxMTEwM3bp1495772XevHnYbDYKCgooKiqiW7duHq/3+++/5847rUHyAwcOpHfv3uTm5nLiiSfypz/9ifz8fC655BL69evHsGHD+OUvf8mDDz7IBRdcwKmnntou++aTbeia0JVSR+Oyyy7jww8/5P3332fy5Mm8/fbbFBcXs3TpUrKzs0lKSqKmpqZdtnXllVcyc+ZMQkJCOO+88/jmm2/o378/y5YtY9iwYfz2t7/lsccea5dt+WQNvfG5otqGrpQ6EpMnT+bmm2+mpKSE7777jhkzZpCYmEhAQABz585ly5Yth73OU089lbfffpvTTz+d3Nxctm7dyoABA8jLyyM9PZ277rqLrVu3smLFCgYOHEhsbCxXX3010dHRvPLKK+2yXz6Z0AMdNkIC7Dqfi1LqiAwZMoSKigqSk5Pp3r07V111FRdeeCHDhg0jIyODgQMHHvY6b7vtNm699VaGDRuGw+Hg3//+N0FBQcyYMYM333yTgIAAunXrxsMPP8ySJUt44IEHsNlsBAQE8MILL7TLfrU5H3pHOZr50AFO+PPXnNY/kb/+bHg7RqWU6mg6H7rnOmI+9GOSDv9XSqnmfLLJBdwTdGm3RaVUJ1i5ciXXXHNNs2VBQUEsWrTISxG1zGcTelRIADvK2+cutFKqcxljDquPt7cNGzaM7OzsTt3mkTSH+2yTS2SI1tCV8kXBwcGUlpYeUcLqKowxlJaWEhwcfFjf8+kaelmVJnSlfE1KSgr5+fkczWMou4Lg4GBSUlIO6zs+m9Ajgx1U1DbgchlsNt+5dFOqqwsICCAtLc3bYfgln25yMQYqarUvulJKgYcJXUQmiMg6EdkgIg+18PkzIpLtfuWKyJ52j/QAOvxfKaWaa7PJRUTswDTgLCAfWCIiM91PKQLAGHNvk/J3AqM6INZmIptModuzjbJKKdUVeFJDzwQ2GGPyjDF1wHvAoSYKnoL1XNEOFaVT6CqlVDOeJPRkYFuT9/nuZQcRkd5AGvBNK59PFZEsEck62jvcjRN0aZOLUkpZ2vum6BXAh8YYZ0sfGmOmG2MyjDEZCQkJR7WhqNDGhK43RZVSCjxL6AXQrJk6xb2sJVfQCc0tsP+5ojqfi1JKWTxJ6EuAfiKSJiKBWEl75oGFRGQgEAMsaN8QWxYe5MAm2oaulFKN2kzoxpgG4A5gNrAGmGGMyRGRx0RkYpOiVwDvmU4azysiROqMi0optY9HI0WNMbOAWQcse+SA94+2X1ie0Sl0lVJqP58dKQruKXQ1oSulFODjCV1r6EoptZ9vJ/TQAPZoQldKKcDHE3pCeBDF5bXeDkMppY4JPp3QkyKDqahtoKpOBxcppZSPJ/QgAHZqLV0ppXw9oVuPZyrSZ4sqpZRvJ/TECKuGXlShNXSllPLthO6uoe/UGrpSSvl2Qo8MdhAcYNMmF6WUwscTuoiQFBnMTm1yUUop307oAEkRwVpDV0op/CChJ0QGabdFpZTCDxK61tCVUsri+wk9MojKOid7a3W0qFKqa/MooYvIBBFZJyIbROShVspcLiKrRSRHRN5p3zBbp4OLlFLK0uYDLkTEDkwDzgLygSUiMtMYs7pJmX7Ar4GTjTG7RSSxowI+UGKT4f99EsI7a7NKKXXM8aSGnglsMMbkGWPqgPeASQeUuRmYZozZDWCM2dm+YbausYa+s0Jr6Eqprs2ThJ4MbGvyPt+9rKn+QH8R+UFEForIhPYKsC37hv9rk4tSqovz6JmiHq6nH3AakALME5Fhxpg9TQuJyFRgKkCvXr3aZcPhQQ5CA+0UaddFpVQX50kNvQDo2eR9intZU/nATGNMvTFmE5CLleCbMcZMN8ZkGGMyEhISjjTmZhpHi2oNXSnV1XmS0JcA/UQkTUQCgSuAmQeU+S9W7RwRicdqgslrvzAPLTFCBxcppVSbCd0Y0wDcAcwG1gAzjDE5IvKYiEx0F5sNlIrIamAu8IAxprSjgj6QNZ+L1tCVUl2bR23oxphZwKwDlj3S5HcD3Od+dbrEiCCKymsxxiAi3ghBKaW8zudHioJVQ6+ud1Kho0WVUl2YXyT0/YOLtNlFKdV1+UVC3z/8X2+MKqW6Lj9L6FpDV0p1XX6R0PePFtUaulKq6/KLhB4W5CA8yKFdF5VSXZpfJHSAHtHBbNtV7e0wlFLKa/wmoafFh7G5tNLbYSillNf4UUIPZ0tpJU6X8XYoSinlFb6X0ItWw5JXwTRP3OnxYdQ7DQW7tdlFKdU1+V5C3zgHPrsPasubLU5LCAMgr2SvN6JSSimv872EHuZ+ut3e4maL0+KthL6pRNvRlVJdk+8l9HD3POqVzZ9yFxcWSESwQxO6UqrL8r2Evq+G3jyhiwjp8WGa0JVSXZbvJfRwd0KvLD7oo7T4MPKKNaErpbom30vooXEgtoNq6GB1XdxeVk1NvdMLgSmllHd5lNBFZIKIrBORDSLyUAufXycixSKS7X7d1P6hutnsVlKvbCGhJ4RhDGwpreqwzSul1LGqzYQuInZgGnAuMBiYIiKDWyj6vjFmpPv1SjvH2VxY4kG9XMDqiw6wSbsuKqW6IE9q6JnABmNMnjGmDngPmNSxYbUhPKHFGnpqfGNfdG1HV0p1PZ4k9GRgW5P3+e5lB7pURFaIyIci0rOlFYnIVBHJEpGs4uKDa9geC0uEvUUHLQ4PcpAUGcQmvTGqlOqC2uum6P+AVGPMcOAr4PWWChljphtjMowxGQkJCUe+tXB3k4s5eN6WNO26qJTqojxJ6AVA0xp3invZPsaYUmNM49MlXgGOb5/wWhGWAA3VUHdwW3lafLgmdKVUl+RJQl8C9BORNBEJBK4AZjYtICLdm7ydCKxpvxBbEN7y4CKwboyWVtZRVlXfoSEopdSxps2EboxpAO4AZmMl6hnGmBwReUxEJrqL3SUiOSKyHLgLuK6jAgb2jxZtZXAR6CRdSqmux+FJIWPMLGDWAcseafL7r4Fft29oh3CIGnrjrIvLtu5hVK+YTgtJKaW8zfdGikKT4f8tdF2MCyOjdwx/+XwN36w9uCeMUkr5K99M6KHxgLQ4uMhuE167fjSDukdyy1vLmJd7FN0jlVLKh/hmQrc7IDS2xRo6QGRwAG/ckEmfhHCmvpnFtl06FYBSyv/5ZkIH9+CilhM6QHRoIC9efRw19S5m5+zoxMCUUso7fDehhye02Mulqd5xYfRJCOM7bXZRSnUBvpvQ26ihNzptQCKL8nZRVdfQCUEppZT3+G5CD09ss4YOcNqABOqcLhZsLO2EoJRSynt8N6GHJVhD/+sOPcw/My2WkAC7Nrsopfye7yb0QwwuairIYeekPnF8u64Y08JkXkop5S98N6EfYvj/gU4bkMDWXVU6aZdSyq/5bkIPd0+/6+GNUYBv12mzi1LKf/luQg9rffj/gXrGhpKeEMa32o6ulPJjPpzQG2voniXpcf0TWJhXSr3T1YFBKaWU9/huQncEQnC0RzV0gMHdI6lrcJG/u7pj41JKKS/x3YQO7kfReZbQ093T6m7SedKVUn7KtxN6mGeDi8B6NB3AphKdqEsp5Z88SugiMkFE1onIBhF56BDlLhURIyIZ7RfiIUQkQUWhR0VjQgOICgnQGrpSym+1mdBFxA5MA84FBgNTRGRwC+UigLuBRe0dZKuie0NZPjjbnqdFREiLD9O+6Eopv+VJDT0T2GCMyTPG1AHvAZNaKPc48Fegph3jO7SYVHA1QHmBR8XT48PYVKwJXSnlnzxJ6MnAtibv893L9hGR44CexpjPDrUiEZkqIlkiklVc3A59wmNSrZ+7N3tUPC0+jO1lNVTXOY9+20opdYw56puiImIDngZ+2VZZY8x0Y0yGMSYjISHhaDd9+And3dNlc6nW0pVS/seThF4A9GzyPsW9rFEEMBT4VkQ2A2OAmZ1yYzQyGWwOjxN6alxj10VN6Eop/+NJQl8C9BORNBEJBK4AZjZ+aIwpM8bEG2NSjTGpwEJgojEmq0MibsrugKiesGeLR8XT4jWhK6X8V5sJ3RjTANwBzAbWADOMMTki8piITOzoANsUk+pxDT0syEFSZJAmdKWUX3J4UsgYMwuYdcCyR1ope9rRh3UYYlJhzcw2izXSrotKKX/l2yNFAWJ6Q1Up1JR7VDwtPlwTulLKL/lBQk+1fnrYjp4eH8auyjr2VNUBkL+7ir21+gBppZTv85+Efhh90cG6MbqltJJznpnHHz9d3TGxKaVUJ/KoDf2YdoR90dfv3Mu7i7dSWefk6zVFuFwGm006JkallOoEvl9DD4mB4CjY7VmTS8+YUOw24akv1/HT1j2cPTiJkr11rNpetq/Mks27GPPnOewo67xZDJRS6mj5fkKHw+q6GOiwkRITQlF5LReN7METlwxDBOau3T8Vwb9/2MyO8hrmr9dH1imlfEeXS+hgPb0oOTqEP0waSlx4ECNSopm7znpQxp6qOr5aXQTA4k27OiBYpZTqGL7fhg5WQl/3ObhcYGv7HPW3y0bQ4HQRFRIAwPgBiTw7J5fSvbV8uqKQOqeL9IQwFm/WhK6U8h3+UUOP7g3OOo8fdhEe5CA6NHDf+/EDEzAGvsst5oOl2xjSI5IrM3uxpbRK29GVUj7DPxL6YfZ0OdDQHlHEhwfx8vxNrCoo57LjUzghLQ5Aa+lKKZ+hCR2w2YTTBiSwprCcQLuNSSOTGdQ9grBAO4s3lbZbmEop1ZH8I6FH9QSxeTxatCXjByQCcObgRGLCAnHYbRyfGtvsxuicNUV8umL7UYerlFIdwT9uijoCISoFSjcc8SrGDUhgTHosN5+avm/ZCWmx/G32OnZX1lGyt5Zb315GXYOL3B0V3HtWf0R0IJJS6tjhHwkdIGko7Fh5xF8PD3Lw3tQTmy3LTIsFYGFeKS9+t5GwQDvnD+vO899soHhvLY9PGorD7h8XOUop3+c/Cb3bcKvrYl0lBIa1yyqHp0QR6LDx+5k57Kyo5Z9XjuL8Yd1Jjg7hn3M3kBITyu3j+7bLtpRS6mj5T/Wy+3DAQFFOu60yyGFnVM9odlbUcv7w7lwwvAciwv3nDGBw90gW5ukNU6XUscOjhC4iE0RknYhsEJGHWvj8FhFZKSLZIvK9iAxu/1Db0G249bNwebuu9uwh3UiODuHxSUObLR+WHEXO9nKMMe26PaWUOlJtJnQRsQPTgHOBwcCUFhL2O8aYYcaYkcCTwNPtHWibolKsibp2rGjX1d54ShrzfzWe2LDAZsuHpkSxq7KO7TrwSCl1jPCkhp4JbDDG5Blj6oD3gElNCxhjmj4uKAzo/GqriFVLL2zfhA60OK3u0B6RAKwqKDvoM6WU8gZPEnoysK3J+3z3smZE5HYR2YhVQ7+rpRWJyFQRyRKRrOLiDpjJsPtw2LkanPXtv+4DDOoeid0mmtCVUseMdrspaoyZZozpAzwI/LaVMtONMRnGmIyEhIT22vR+3UZYc7oUr2v/dR8gOMBOv8RwTehKqWOGJwm9AOjZ5H2Ke1lr3gMuOoqYjlx3943Rdm5Hb82QHlGs2u7Zw6mVUqqjeZLQlwD9RCRNRAKBK4CZTQuISL8mb88H1rdfiIchri8EhHZIO3pLhiVHUlxRS1G53hhVSnlfmwOLjDENInIHMBuwA68ZY3JE5DEgyxgzE7hDRM4E6oHdwLUdGXSrbHZIGtJpNfShyVGAdWM0KTK4U7aplFKt8WikqDFmFjDrgGWPNPn97naO68h1Gw4rP/D4YRdHY1D3SERgVUE5ZwxK6tBtKaVUW/xnpGij7sOhthz2bO7wTYUFOeiTEM5KvTGqlDoG+F9C3zditJOaXXpEkrNdE7pSyvv8L6EnDbFujG7+vlM2NzQ5isKyGkr21nbK9pRSqjX+l9AdQZA2DtbPhk6YZ6Xxxuh/fzpUT06llOp4/pfQAfqdBXu2QknH9548vncMJ/eN44+freHh/6yktsHZ4dtUSqmW+G9CB9jwVYdvKsBu4/XrM7llXB/eWbSVy19cwJ6qug7frlJKHcg/E3p0L0gYBOu/7JTNOew2Hjp3IC9efTxrCiu46fUsauq1pq6U6lz+mdAB+p0Jm3+A2r2dtskJQ7vx9OQRLN26m7vf+wmnS+dKV0p1Hj9O6GeDqx42fdepm71geA9+d/5gZucUcctbS5k+byP/+Smf7XuqOzUOpVTX4z/PFD1QzzEQGGE1uww8v1M3fcMpaeyprmf6vI18tboIgBPSYnn/Fye28U2llDpy/pvQHYGQPg7Wf211X5SDH1LRke47qz/3ntmPvbUNPPVlLm8t3EJlbQNhQf77J1dKeZf/NrmA1exSnt9pk3UdSESICA7gzEFJNLgMizft8kocSqmuwb8T+qALwREMWa95NYyM1BgCHTZ+2FDi1TiUUv7NvxN6aCwMuwxWzIDq3V4LIzjATkbvGH7YWOq1GJRS/s+/EzpA5s1QXwXZ73g1jJP7xrOmsFznfFFKdRiPErqITBCRdSKyQUQeauHz+0RktYisEJE5ItK7/UM9Qt1HWD1eFr9szZHuJSf3jQdggdbSlVIdpM2ELiJ2YBpwLjAYmCIigw8o9hOQYYwZDnwIPNnegR6VzJth9ybY8LXXQhiWHEVEsKNZO3p1nRPTCROIKaW6Bk9q6JnABmNMnjGmDush0JOaFjDGzDXGVLnfLsR6kPSxY9BECE+CxdO9FoLdJpyYHscPG0swxvDCtxsZ/PsvGPe3b/nL52tZtnU31XU6XYBS6sh50ik6GdjW5H0+cMIhyt8IfN7SByIyFZgK0KtXLw9DbAeOQBh9E8z9E2xZAL29M8Dn5L7xfLm6iNveXsbnq3ZwxsBE6l2GV+bn8eJ3GxGBlJgQzhyUxO/OH4zN1rl955VSvq1dR7mIyNVABjCupc+NMdOB6QAZGRmd29Zw4u2w9HWYdT9M/Q7snT/Ap7Ed/fNVO7jttD7cf/YAbDZhd2UdC/JKWV+0l5UFe/jXD5uJDw/i9vF9Oz1GpZTv8iSrFQA9m7xPcS9rRkTOBH4DjDPGHHtdOQLDYMITMOMaq+nlxNs6PYQ+CWFcM6Y3w1OiuCxj/580JiyQ84Z1h2FgjOHu97J56st1jEiJ5pR+1kmguKKW2LBA7FprV0q1wpM29CVAPxFJE5FA4ApgZtMCIjIKeAmYaIzZ2f5htpNBF0LfM2Hun6FiR6dvXkR4/KKhzZJ5S2X+cukw+iaGc9d7P/HK/DwumvYDo//0NS/Pz2tWdsHGUq58eSE7y2uaLc/avIttu6pQSnUtbSZ0Y0wDcAcwG1gDzDDG5IjIYyIy0V3sb0A48IGIZIvIzFZW510icO6T4KyDLx7qlEfUHYnQQAcvXn08dQ0u/vjZGmrqnfSOC+XjZfnNyr00byM/bizl5jeX7pt//ZPsAi57aQEPfLjcG6ErpbzIo4ZkY8wsYNYByx5p8vuZ7RxXx4nrA+N+Bd88Dn3PglFXeTuiFqUnhPPf20+i3mkY1D2SNxZs5pFPcsgtqqB/UgSle2uZv76EjN4xZG3ZzYMfreC8Yd25b8ZyQgLsLN60i5K9tcSHB3l7V5RSncT/R4q25JR7IfVU6wZp8TpvR9OqvokRDOoeCVgPz7AJfLqiEIBZq3bgdBkev2go95/dn0+yt3PLW0sZlhzFGzdk4jLwZU6RN8NXSnWyrpnQbXa45GUICIUPb4D6Y//hE4kRwZyQFsenK7ZjjGFmdgH9k8IZ2C2C28f3ZUpmLzJ6x/D69Zkc3zuG1LhQPl9V2GwdDU7vjZRVSnW8rpnQASK7w8UvQdEq+Oz+Y7Y9vanzh3cnr7iSb9buZMnm3Uwc0QMRQUR44pJhfHDLSUSFBiAiTBjanQUbS/c9sPrLnB2Meuwrvl137N6zVkodna6b0MF67ui4ByH7LfjhOW9H06Zz3c0uD328EoCJI5IPWbbBZfhqdRG7K+t4+D8rqaht4IEPV7Crsq7DY11VUMakaT9QVlXf4dtSSlm6dkIHOO3XMPRn8PXvYfUn3o7mkOLCgzipTzzFFbWM7BlNr7jQVssOT4kiOTqEL1bt4A//y2FPVT1PXTaCPVV1PPzxyg6fQ+ajZfks37aHZVu9N22xUl2NJnQRmDQNUjLh46mw5UdvR3RI5w/vDsDEET0OWc5qdunG3HU7+W/2dm4f35dLj0/hl2cP4IucHXy07KCxYe1q/nprErLVheUduh2l1H6a0AECgmHKuxDVE968GHJnezuiVl00Mpn7zurP5aNbH5zU6Nyh3XAZ9t04Bbj51HQy02L5/SerWFVQ1uY6auqdfLwsn1krC/lxY4lH87lv31PNhp17AU3oSnUmTeiNwuLhhi8gYSC8OwWWv+ftiFoUEmjnrjP6Ee7Bw6aP6xXD3Wf0459XHkegwzrUdpvw/BWjiA4N5NrXFpNXvPeQ63huznrum7Gc295expUvL+LMp7/bd6O1NfNyiwFITwhjzXZN6Ep1Fk3oTYXFw3WfQurJ8J9fwJzHweW7U9rabMK9Z/Wnb2J4s+XdooJ588ZMAK55dTE/bd3NF6sK+ec361mRv2dfuU0llbwyP4+JI3rw+d2n8o8po9hTVc+7i7dxKPPXl9AtMpiJI3qwqbSSqrqGdt83pdTBNKEfKCgCrvwARl0D8/8Ob/8MqnZ5O6p2l54Qzus3ZFJWXc/F//cjt7y1jL9/mcvklxayZLO1v4/9L4cgh53fXjCIQd0juXBED07uG8frP26mvpU+7U6X4fsNJZzaL54hPaIwBtbuqOjMXVOqy9KE3pKAYJj0T7jwOdj8Pbw0Dgr9b26UoclR/Pf2k/j7ZSOYecfJzP/VeLpHB3P9v5bw3NfrmbuumLvP6EdiRPC+79xwcho7ymuYtbKwxXUuz99DWXU9Y/snMKh7BACrj+Fmlzlrirj2tcU8P2c9S7fsavVEpZQv6PxJwX3J8ddBt2Hw/jXw6tlw4fMwYrK3o2pXfRMj6JsYse/9OzeNYfL0BTzzdS59EsK49qTUZuXHD0gkPT6M177ftG9gU1PzcosRgVP6xhMdGkBksOOgG6NlVfXklexl664qTuoTT0LEkc03U1Zdz6Mzcygqr6Gsup6IYAdPXT6S5OgQj76/YGMpt769jNBAO/PWF/P0V3BiehzvTh1zRPEo5W1aQ29L8vHWAzGSM+A/U61RpXX+OzVtt6hg3rl5DGcMTOTJnw3fdzO1kc0mXH9yKsvzy1rsYz5/fQnDk6OICQtERBjcI7JZDf2+GdmMeOxLLv6/H7n7vWx+7R4kdSTeX7KV//xUQG2Di26RweRsL+fKlxeyo6ymze+uKijj5jey6BUbytxfnsay357F5IyeLNpUSkWNDoZSvkkTuifCE+Dn/4UT74AlL8NLp0J+lrej6jDJ0SG8et1oju8d2+Lnlx6fQlRIANPmbmw2QGlnRQ3Z2/Ywtn/CvmWDu0exbkcFTpchZ3sZHy8r4OJRybzy8wxuOiWNr9cUedR9cuobWTz44Yp9710uw9uLtjI6NYaPbj2JV68bzRs3ZFK6t27fHPEul8HpMtTUOymrrmdHWQ1z1hTx5Bdrufa1xUQGO3jzxkxiwgKJCQvkghHdcRlYtnXPkf/xlPIibXLxlD0AzvkT9DsbPrkdXj0LxtxmTcUbHOXt6DpVaKCD207rwxOfr+WDpflcntETl8tw/wcrcNiESSP3T0kwuEck1fVONpdWMn1eHmGBdh69cAhRoQFkpscyI2sbz369nleuzWh1e3nFe/lytTVz5JQTejGyZzTfbyhhS2kV953Vf1+5Ub1i+Pf1o/n5a4vJ/POcVtfnsAnDU6J48mcj6B61v3nmuF4x2G3Ckk27GNfkpHQkquucPDl7LTecnEbP2NZH9CrVnjShH670cXDrD/Dl72DBNFjxPpzxCIy8yprFsYu46dR0vl1XzKMzc8joHcPXa4qYl1vM4xcNbdZNsvHG6Jc5RXy6opAbTk4lKjQAgMjgAG4+NZ2nvsplZX4Zw1JaPjF+uDQfm0BUSABPzFrDe1PH8NbCLcSFBTJhaLdmZTNSY/nglhP5anURgiACDrsQaLcRFGCnf2I4w1OiCQk8+FiFBTkY0iOSxZuPvlfTc3PW868fNiMIj1w4+KjXp5QnPGpyEZEJIrJORDaIyEMtfD5WRJaJSIOI/Kz9wzzGBEfBxOdh6lyITYeZd8I/joes16C+7fZbf2C3Cc9MHkmgw8ZNb2Tx5BfrOGdIElef0KtZuX6JEQTYhefm5GITuOGUtGafX3dyKlEhATw3J7fF7Thdho+XFTCufwL3ntWfRZt28e7ibXy9pojLMnoS5Dg4MQ/pEcU9Z/bn7jP7cdcZ/bjttL7cdGo614zpzQnpcS0m80ajU2PJ3raH2oaDxx9U1jbwSXYBSzbvorK29b71q7eX8/L8POw24fNVhbhcns+bU1ZVz61vLWXDTu3qqQ5fmwldROzANOBcYDAwRUQOrHJsBa4D3mnvAI9pPUbBDbPh8jchJBo+vReeHQbfPQl7i70dXYfrFhXMXy8dTl5xJYkRQfz10uEH9XoJdNjomxhBTb2LSSOTmzVxAEQEB3DzqWl8vWYnk19awB3vLOOZr3L3PVLv+w0l7Civ4bKMnkzJ7EVqXCi/+e9KDHBlZvOTR3sYnRpLXYOLlfnN2/WLymu4/KUF3P1eNpe9uIChj87miukLDkrsTpfh1x+vICY0gN+dP4jCshp+2ub5BGWv/rCJz1ft4IlZa9tlf1TX4kkNPRPYYIzJM8bUAe8Bk5oWMMZsNsasALpeJ14RGDwRbp4LP58J3YfD3D/BM0Pgv7fB1oU+Mdf6kTpnSDemXXkcb9yYSXRoYItlBrufunTLuPQWP7/+5DSmZPbCZQw528t5bs567nz3J+qdLj7I2kZ0aABnDEokwG7jgXMGYgyM7ZdwyNkmj9To1BiAZs0uawrLuWjaD2wqqeSfV47i1WszuO20PizetItHZ+Y0+/4bCzazPL+MRy4cwqXHpxDosO17yhTAuh0VzFjS8kjbipp6/v3DJiKCHMxZu7NdZqosq6r3+IHhuUUVPPnFWpyHcUWhji2etKEnA03/BeYDJxzJxkRkKjAVoFev9q9deZWI1b6ePs56rN3CF2DFDMh+G+L6wcgpMOQSiE1re10+pnEGyNbcelofxvaPb9bfvamwIAdPXDJs3/vG56fe+c5PfLNuJ1dm9trXtHLesG7cc2Y/zhqc1H470ERceBB9EsLI2mwl0w0793L5iwsIDbLzwS0nMqSH1c5/xqAkbCL845sNjO2fwIUjevDOoq38edYaThuQwIXDuyMijOufwKyVhfzu/MHUNriY+mYWW0qrOCE9lt5xYc22/ebCLZTXNPD+1DHc9vYynvpyHW/fdHR94u+dkU3W5l3M/9Xp++5dtMQYw8MfryRry276JoZzyXEpB5WpqXeyaNMuRqfGEBqot9+ORZ3abdEYM90Yk2GMyUhIOLpeBMe0hAFw4bNwf641NW9oHMx5DJ4fCdPHw8IXobLU21F2mr6J4c16vrTl5yem8uCEgXyRs4O6BheXZexPLiLCPWf235dYO0JmWixZ7nby299eRoDDxke3nnTQNu8+ox/H9Yrm4Y9Xct+MbB7+z0pO6hPPc1eM2tf0dMHw7hSV17Js627+NnsdW0qrEIEPsvKbrauqroFX5m9iXP8ETkiP49bT+vDDhlJ+3FjiUcybSyqZMn0hOdv3NxVt2FnBN2t3Ul7TwMvz8w75/bnrdpK1ZTchAXae+TqXuob9F9sbi/fy6MwcTvjzHK59bfFBVyWexHbKX79hrj4tq8N5ktALgKZztaa4l6m2BIXDqKvhxtlwz0o46zFwNcAXD8JTA+C9q2DjN37dJHOkbj2tD78+dyCTM3p2aPJuyejUWMprGrjh30vI3VnBM5NHkhJzcPOOw27juStGAfDxsgJuGdeH164bTVTI/prwGYOSCHTYePKLdfzrx038/MTenNY/gQ+X5jdr2nh38TZ2VdZx5+nWNMdXj+lNt8hg/j57HXsPcQMWrHb7+z9YzoK8Uh75JGff2IBXv99MkMPG2P4JvPbDplanPna5DE9+sY7ecaE8P2UU23ZV8/6SrQAs3bKLC//xPe8s2srY/glMHNGDGVn5ZG/b49HfssHp4r4Z2eTvrua17zd59B115DxJ6EuAfiKSJiKBwBXAzI4Nyw9F94KT74Zb5sOtP8IJv7Da19+8GKadAItfhmp9uk9TvxjXh7/+bHinb3d0qjWgatGmXdx+Wt9D9knvGRvKGzdm8voNmTx07kDstuY3hcODHIwfkMDizbtIjg7hwQkDuTyjJzvKa/ZNM7yrso4Xv9vImPRYMtzbDg6wc+9Z/Vi2dQ8Zf/yKe977ie9yi1t80Pe/f9xM1pbdnDkokaVbdjNz+XZK99by8bJ8LjkuhUcuGExNvZMXv93Y4j78b8V21u6o4L6z+nPmoEQyU2N5/psNLNm8i+v+tYTEiCDm/Wo8/5gyij9fMozEiCB+/8kqj3rvvDQvj2Vb9zCqlzV2IH+3/42y3lRSyXNfr2/zxNsZ2kzoxpgG4A5gNrAGmGGMyRGRx0RkIoCIjBaRfOAy4CURObxrsq4maYg1SOneHLjoRQgIgVn3w98HwIxrYe2sLtP98ViUEhNCWnwYJ6bHcc+Z/dosP6pXzCGT/sWjUrAJ/PXS4YQFOThjUBKxYYHMyNqGy2W4b0Y2ZVX1/Pb85p3HJo/uxUe3nsQlx6XwzdqdXPvaYsY8MYdHZ+bw44YSquucbCqp5G+z13LGwEReuiaDIT0i+cvna3l5/iZqG1zceErqvjbxNxZuOWhahMraBp7+KteaTXO4NTfPAxMGUFxRy+SXFhAZHMDbN4+hW5Q1QVt4kIOHzxvE8vwyPli6DWMMW0or+d/y7Tw/Zz33vp/Nrz5czifZBXy/voRnvsrlguHd+ccU60rmwKamlpTsrd3Xy8lbiitqeXPBZlYVlLV64qptcPLs17mc8+w8nvk6l6e+XNfJUR5MOvrZkq3JyMgwWVn+O3z+sBgDhdnWQzVWfgBVpRAYAQMmQP8J0PskiDz0I+dU+yqrqic40NZiP/fDZYxhT1U9MWH7ewE9/ulq3liwmWtPTOWV7zfx+EVDuWZM71bXUVPv5Nt1O5m5fDtfr9lJXYOLALsQERxAg9PFV/eNIykymMWbdnH5SwsAGD8ggX9db817v21XFac/9S39kyK48oRenD4wkVkrd/DCtxso2VvH6zdkNjsp3fLmUn7atpv3p55Ianzzm7fGGC5/aQFrCisICbRTXLG/KSc5OoS9tQ2UVVvz4SRFBjH7nrFEhwZyzauLyCuuZN6vxh90JdPok+wCfvXhCmLDArn3rP5celxKq2UPR029kzcWbKawrIYbT0lr1oS2o6yGhIigfdtxuQxXvrKQhXlWT6eY0ACuOqE3958zYN93KmrqufSFH8kt2suFI3pgF5i5fDuf3nkqg3tEHnW8hyIiS40xLQ6t1oR+rHHWQ953sPq/sPbT/c0wMWnQYyQkDraeqhTXF2JSIVCHlfuidTsqOOfZeQD7arAH9uFvzd7aBpZs2sWiTbv4aeturj85lQlD9/c0uv2dZXy2opC3bjyBU/rF71v+0dJ8pn27gbziyn3LTu4bx31nDeD43jHNtlHvdOF0GYIDWj6hrdtRwf0fLKdvYjgZqTGM7BlNenw4IYF2nC7DqoIyFuSVclKfOIanRAPwv+XbufPdn3jjhsxm8/2AdR/g71+u44VvN3J87xgaXIbl2/bQPymcv1w6nON6xbQQRXM7y2vIKSwnr7iSgt3VJEUGkRofRll1Pc9+lcv2shocNsEmwrUn9SYpMphPsrezsqCM0wcm8sLVxxHksPPq95t4/NPV/Pb8QcSFB/Lp8kLmrN3Ja9dlcPpAq3fVnz5bzSvfb2L6NRmcNTiJPVV1jP/7t/RNDGfGL070+FgeCU3ovsrZAEUrrQdXb/kRinJg92agyTGLTIbEQdYraSj0OM5K9jadd+1Yd8X0BRRX1PLJHad49EhBT+2qrOPbdTu5eFTyQYnFGMPqwnK+XVfMqF7RnNQnvpW1tL/aBicn/HkOp/SN559XHgdY7c+fryrkf8sLWVNYzpTMXvxh4hAC7MIXq3bwp1lr2FFWw0PnDuTGU9JaTJS7Kut4fs563lq4hQZ380hwgI2a+v33G4YlR/HweYPoHRfK01/l8tGyfIyB4SlRDEuO4u1FWxk/IIH7zxnAJf/3I6f0jeeVazMQEeoaXJz3/Hxq6p18de84tu2u4tzn5nPZ8Sn85dL993jeX7KVBz9aydOXj2ix22d70YTuT+oqoSQXSjfCrjwoWQ/Fa6A4F5zuS9+gSKsmH98P4vtbPxtr9PbW+yKrzlVd58Rmo12adXzFozNzeGvhFlJiQthZUUtVndVWPiIlimtOTOVnxzdPhGXV9fzqw+XMziliXP8EzhiUSJ+EcEID7WzYuZc1hRV8sHQblbUNTMnsxUWjkkmPDyM2LJDymgY2l1RSXe8kMzUWW5Omm62lVbiM2dec9M6irTz8n5UE2IXwIAez7x3b7MEuC/NKuWL6Qm4f34elW3azprCCufefRmyTZjSXy3DJCz+yurCc3rGhxIcHMbxnFL8Y26dZuaOlCb0rcDZYiX77MihYBsVrrfeVTaYgsDkgYZA1mrXbcOg21LpBG9L25axS7WFraRW/n7mK8OAAEsKDSI0P5YxBSYd8KIkxhtd+2MyzX+dSUdO8J0mgw8bYfvE8OGEg/ZJaHrjmqfcWb+XR/+Xw7OSRzZqwGt03I5uPl1k9tlu757FtVxWvzM+jqLyW4r21/LR1N2GBDn4xLp0bTklrlwFZmtC7sqpd7tr8RmsE644VsD0bqpoMWAlLhKhkq/kmLMGafCw4ynq+amA4BEdCeDeI6AbhSWDXUYKq8xlj2FlRy8ade6msc9I3MZxesaHtctO0Ub3TRYC95ebKkr21nPHUd/SMDeGT20/xaLvriyp4cvY6vlpdRESQg0mjejAls9dRja3QhK6aMwYqdkDRKtix0mq6KS+AsgKo3gXVe8DV2lN7BMITreQemQxRKdbPoHDrM4CaMms9VbutHjtVJdBQA8HR1iRmoXHWiSMsweqyKXYQGzRUW01K9TXWPQBbgLW88Z6BI9i6mgiNhYjuENXTvV2lOsf2PdWEBzuIDD68pstlW3fz1oItfLaykNoGF7+7YDA3nnJk04BoQleHxxior4a6vVBbAbXlUFEEFYX7X+WFUL4dyvKhtoUnDtmD3Ik7DkLjwRHkTvSNSb4UTDvM5RYSY51Uonpar9j0/fcLIrtDYFjr362vsWJy1kJIrFXW094JzgbrewGhnn/HUy6Xtc4O7CnRpVTssEZkb/gadq6xKiw1e8DltO4p2QOs5kibw/o9PMnqJhyW6K5QYP202a2XI9i6cg0Ms65kQ6IhOMaqnAQEW+upq4L6Smios0aHu1+V1TUs2lDEgJEnkZx+ZPPkHyqh67WzOpiI1R0yMNSqjbelptyqgRuXdTIIjmw70bmcVnJvqHH/Y3da3wkMs/5juJzWcuNkX82/oWb/CaF8O+zZCmXbrCuL3Vtg0zzrJNRUUJS1H8YAxuoW6qy3krGzrnlZR7B18gmNtU5G9gBoqLXK11daVw+1e60TXL17xKPYraapoEhrO4370Lgf9dXWSaNurzspuP/LOeut7Tee1Iyx1tlYtnHd9kB3PO6YwhKtK5vQGGvfgiOtcq4G66qqodZ6uRrcCcZ9HIMam9BCrXXaA6xtGpd7/6rd+1i1/6dxussGWgksNNY68QVFuPcv1PqbNh53m6P13lUup7WNhpomP6ushNf4b85Z565AVFhlnLXWiTPAnUAdwfsrGQ01+/cjINT6PCjcOkaVJfuvQAuXw54t1jbCEiFlNCTHWFeLNsf+49CYdBtqYW8RFK2Gqnn7p+Uwrv3/Jp0tT6HgiTDgdICeT8MRJvRD0YSujl5wJHCYgylsdgg7RJe5FnvjRB76BGOMdRO4dKP1n7h8u3U1UV/tPrmIu0bmTlLBkVYNyx5o3WuoKrEmTaveZSWFpgktvNv+RN14j8EeYCWXmnJ3EmpMiFXWtuurraQaHAWRKe7E57TibExGTZ9yFRC2/94F7E8ejU1XlcVWt9W9xda2jlWO4P33X5z17pOUFx7YEZsOycfB6BshfbzVrbc9uvO6XNbfv3bv/qvOmjL3CcpdQWk8sTuCrKbDxtq/zW79Hun5ZHWHQxO68h/ibt8PT4TeJ3o7mo7VUGddKdSUuWvH7kThCHYnEbvVpFRftb9WW+O+snDWWYlWxF2rtlsJqPHVeKVhc7hr/XVWQq7aZZ1Yaius9dRXW1cdjVdiLpe7llvtvpKpsE5cIdH7r2AcIVZ8jVcw9ibd+WwOq1xQuPuzICsJNjb/NdS4a+KR1joaa9QN1ftr9oFh1lVWWLy1jo5gs7mvyiKsZr1jiCZ0pXyRIxAc8Ye+ygkMA+I6LSTlfTqcUCml/IQmdKWU8hOa0JVSyk9oQldKKT+hCV0ppfyEJnSllPITmtCVUspPaEJXSik/4bXJuUSkGNhyhF+PB0raLOW7dP98m+6fbzvW96+3MabFp5J7LaEfDRHJam22MX+g++fbdP98my/vnza5KKWUn9CErpRSfsJXE/p0bwfQwXT/fJvun2/z2f3zyTZ0pZRSB/PVGrpSSqkDaEJXSik/4XMJXUQmiMg6EdkgIg95O56jJSI9RWSuiKwWkRwRudu9PFZEvhKR9e6fMd6O9UiJiF1EfhKRT93v00RkkfsYvi8igW2t41glItEi8qGIrBWRNSJyop8du3vd/y5Xici7IhLsy8dPRF4TkZ0isqrJshaPl1ied+/nChE5znuRe8anErqI2IFpwLnAYGCKiLT/k1Y7VwPwS2PMYGAMcLt7nx4C5hhj+gFz3O991d3Amibv/wo8Y4zpC+wGbvRKVO3jOeALY8xAYATWfvrFsRORZOAuIMMYMxSwA1fg28fv38CEA5a1drzOBfq5X1OBFzopxiPmUwkdyAQ2GGPyjDF1wHvAJC/HdFSMMYXGmGXu3yuwEkIy1n697i72OnCRVwI8SiKSApwPvOJ+L1gPPv/QXcSX9y0KGAu8CmCMqTPG7MFPjp2bAwgREQcQChTiw8fPGDMP2HXA4taO1yTgDWNZCESLyLH1ENED+FpCTwa2NXmf717mF0QkFRgFLAKSjDGF7o92AEneiusoPQv8CnC538cBe4wxDe73vnwM04Bi4F/uJqVXRCQMPzl2xpgC4O/AVqxEXgYsxX+OX6PWjpfP5RtfS+h+S0TCgY+Ae4wx5U0/M1bfUp/rXyoiFwA7jTFLvR1LB3EAxwEvGGNGAZUc0Lziq8cOwN2WPAnrxNUDCOPg5gq/4svHC3wvoRcAPZu8T3Ev82kiEoCVzN82xnzsXlzUeHnn/rnTW/EdhZOBiSKyGat57HSsNudo9yU8+PYxzAfyjTGL3O8/xErw/nDsAM4ENhljio0x9cDHWMfUX45fo9aOl8/lG19L6EuAfu677IFYN2hmejmmo+JuU34VWGOMebrJRzOBa92/Xwt80tmxHS1jzK+NMSnGmFSsY/WNMeYqYC7wM3cxn9w3AGPMDmCbiAxwLzoDWI0fHDu3rcAYEQl1/ztt3D+/OH5NtHa8ZgI/d/d2GQOUNWmaOTYZY3zqBZwH5AIbgd94O5522J9TsC7xVgDZ7td5WG3Nc4D1wNdArLdjPcr9PA341P17OrAY2AB8AAR5O76j2K+RQJb7+P0XiPGnYwf8AVgLrALeBIJ8+fgB72LdD6jHusK6sbXjBQhWr7qNwEqs3j5e34dDvXTov1JK+Qlfa3JRSinVCk3oSinlJzShK6WUn9CErpRSfkITulJK+QlN6Eop5Sc0oSullJ/4f99cj/T6HPAwAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = pd.DataFrame(model.history.history)\n",
    "loss.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98        63\n",
      "           1       0.99      0.99      0.99       108\n",
      "\n",
      "    accuracy                           0.99       171\n",
      "   macro avg       0.99      0.99      0.99       171\n",
      "weighted avg       0.99      0.99      0.99       171\n",
      "\n",
      "[[ 62   1]\n",
      " [  1 107]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,pred.round()))\n",
    "print(confusion_matrix(y_test,pred.round()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('ANN_clasification.h5')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "69eb92836b941e979072a76c7fcfffe5419cca933cedd02cfafbdfca1a93358c"
  },
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
