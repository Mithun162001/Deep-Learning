{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>benign_0__mal_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                 0.07871  ...          17.33           184.60      2019.0   \n",
       "1                 0.05667  ...          23.41           158.80      1956.0   \n",
       "2                 0.05999  ...          25.53           152.50      1709.0   \n",
       "3                 0.09744  ...          26.50            98.87       567.7   \n",
       "4                 0.05883  ...          16.67           152.20      1575.0   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  benign_0__mal_1  \n",
       "0          0.4601                  0.11890                0  \n",
       "1          0.2750                  0.08902                0  \n",
       "2          0.3613                  0.08758                0  \n",
       "3          0.6638                  0.17300                0  \n",
       "4          0.2364                  0.07678                0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('cancer_classification.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Basic EDA</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 31 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   mean radius              569 non-null    float64\n",
      " 1   mean texture             569 non-null    float64\n",
      " 2   mean perimeter           569 non-null    float64\n",
      " 3   mean area                569 non-null    float64\n",
      " 4   mean smoothness          569 non-null    float64\n",
      " 5   mean compactness         569 non-null    float64\n",
      " 6   mean concavity           569 non-null    float64\n",
      " 7   mean concave points      569 non-null    float64\n",
      " 8   mean symmetry            569 non-null    float64\n",
      " 9   mean fractal dimension   569 non-null    float64\n",
      " 10  radius error             569 non-null    float64\n",
      " 11  texture error            569 non-null    float64\n",
      " 12  perimeter error          569 non-null    float64\n",
      " 13  area error               569 non-null    float64\n",
      " 14  smoothness error         569 non-null    float64\n",
      " 15  compactness error        569 non-null    float64\n",
      " 16  concavity error          569 non-null    float64\n",
      " 17  concave points error     569 non-null    float64\n",
      " 18  symmetry error           569 non-null    float64\n",
      " 19  fractal dimension error  569 non-null    float64\n",
      " 20  worst radius             569 non-null    float64\n",
      " 21  worst texture            569 non-null    float64\n",
      " 22  worst perimeter          569 non-null    float64\n",
      " 23  worst area               569 non-null    float64\n",
      " 24  worst smoothness         569 non-null    float64\n",
      " 25  worst compactness        569 non-null    float64\n",
      " 26  worst concavity          569 non-null    float64\n",
      " 27  worst concave points     569 non-null    float64\n",
      " 28  worst symmetry           569 non-null    float64\n",
      " 29  worst fractal dimension  569 non-null    float64\n",
      " 30  benign_0__mal_1          569 non-null    int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 137.9 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean radius</th>\n",
       "      <td>569.0</td>\n",
       "      <td>14.127292</td>\n",
       "      <td>3.524049</td>\n",
       "      <td>6.981000</td>\n",
       "      <td>11.700000</td>\n",
       "      <td>13.370000</td>\n",
       "      <td>15.780000</td>\n",
       "      <td>28.11000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean texture</th>\n",
       "      <td>569.0</td>\n",
       "      <td>19.289649</td>\n",
       "      <td>4.301036</td>\n",
       "      <td>9.710000</td>\n",
       "      <td>16.170000</td>\n",
       "      <td>18.840000</td>\n",
       "      <td>21.800000</td>\n",
       "      <td>39.28000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean perimeter</th>\n",
       "      <td>569.0</td>\n",
       "      <td>91.969033</td>\n",
       "      <td>24.298981</td>\n",
       "      <td>43.790000</td>\n",
       "      <td>75.170000</td>\n",
       "      <td>86.240000</td>\n",
       "      <td>104.100000</td>\n",
       "      <td>188.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean area</th>\n",
       "      <td>569.0</td>\n",
       "      <td>654.889104</td>\n",
       "      <td>351.914129</td>\n",
       "      <td>143.500000</td>\n",
       "      <td>420.300000</td>\n",
       "      <td>551.100000</td>\n",
       "      <td>782.700000</td>\n",
       "      <td>2501.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean smoothness</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.096360</td>\n",
       "      <td>0.014064</td>\n",
       "      <td>0.052630</td>\n",
       "      <td>0.086370</td>\n",
       "      <td>0.095870</td>\n",
       "      <td>0.105300</td>\n",
       "      <td>0.16340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean compactness</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.104341</td>\n",
       "      <td>0.052813</td>\n",
       "      <td>0.019380</td>\n",
       "      <td>0.064920</td>\n",
       "      <td>0.092630</td>\n",
       "      <td>0.130400</td>\n",
       "      <td>0.34540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean concavity</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.088799</td>\n",
       "      <td>0.079720</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029560</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>0.130700</td>\n",
       "      <td>0.42680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean concave points</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.048919</td>\n",
       "      <td>0.038803</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020310</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>0.20120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean symmetry</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.181162</td>\n",
       "      <td>0.027414</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>0.161900</td>\n",
       "      <td>0.179200</td>\n",
       "      <td>0.195700</td>\n",
       "      <td>0.30400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.062798</td>\n",
       "      <td>0.007060</td>\n",
       "      <td>0.049960</td>\n",
       "      <td>0.057700</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>0.066120</td>\n",
       "      <td>0.09744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>radius error</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.405172</td>\n",
       "      <td>0.277313</td>\n",
       "      <td>0.111500</td>\n",
       "      <td>0.232400</td>\n",
       "      <td>0.324200</td>\n",
       "      <td>0.478900</td>\n",
       "      <td>2.87300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>texture error</th>\n",
       "      <td>569.0</td>\n",
       "      <td>1.216853</td>\n",
       "      <td>0.551648</td>\n",
       "      <td>0.360200</td>\n",
       "      <td>0.833900</td>\n",
       "      <td>1.108000</td>\n",
       "      <td>1.474000</td>\n",
       "      <td>4.88500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perimeter error</th>\n",
       "      <td>569.0</td>\n",
       "      <td>2.866059</td>\n",
       "      <td>2.021855</td>\n",
       "      <td>0.757000</td>\n",
       "      <td>1.606000</td>\n",
       "      <td>2.287000</td>\n",
       "      <td>3.357000</td>\n",
       "      <td>21.98000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>area error</th>\n",
       "      <td>569.0</td>\n",
       "      <td>40.337079</td>\n",
       "      <td>45.491006</td>\n",
       "      <td>6.802000</td>\n",
       "      <td>17.850000</td>\n",
       "      <td>24.530000</td>\n",
       "      <td>45.190000</td>\n",
       "      <td>542.20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smoothness error</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.007041</td>\n",
       "      <td>0.003003</td>\n",
       "      <td>0.001713</td>\n",
       "      <td>0.005169</td>\n",
       "      <td>0.006380</td>\n",
       "      <td>0.008146</td>\n",
       "      <td>0.03113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compactness error</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.025478</td>\n",
       "      <td>0.017908</td>\n",
       "      <td>0.002252</td>\n",
       "      <td>0.013080</td>\n",
       "      <td>0.020450</td>\n",
       "      <td>0.032450</td>\n",
       "      <td>0.13540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concavity error</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.031894</td>\n",
       "      <td>0.030186</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015090</td>\n",
       "      <td>0.025890</td>\n",
       "      <td>0.042050</td>\n",
       "      <td>0.39600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concave points error</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.011796</td>\n",
       "      <td>0.006170</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007638</td>\n",
       "      <td>0.010930</td>\n",
       "      <td>0.014710</td>\n",
       "      <td>0.05279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>symmetry error</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.020542</td>\n",
       "      <td>0.008266</td>\n",
       "      <td>0.007882</td>\n",
       "      <td>0.015160</td>\n",
       "      <td>0.018730</td>\n",
       "      <td>0.023480</td>\n",
       "      <td>0.07895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fractal dimension error</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.003795</td>\n",
       "      <td>0.002646</td>\n",
       "      <td>0.000895</td>\n",
       "      <td>0.002248</td>\n",
       "      <td>0.003187</td>\n",
       "      <td>0.004558</td>\n",
       "      <td>0.02984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worst radius</th>\n",
       "      <td>569.0</td>\n",
       "      <td>16.269190</td>\n",
       "      <td>4.833242</td>\n",
       "      <td>7.930000</td>\n",
       "      <td>13.010000</td>\n",
       "      <td>14.970000</td>\n",
       "      <td>18.790000</td>\n",
       "      <td>36.04000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worst texture</th>\n",
       "      <td>569.0</td>\n",
       "      <td>25.677223</td>\n",
       "      <td>6.146258</td>\n",
       "      <td>12.020000</td>\n",
       "      <td>21.080000</td>\n",
       "      <td>25.410000</td>\n",
       "      <td>29.720000</td>\n",
       "      <td>49.54000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worst perimeter</th>\n",
       "      <td>569.0</td>\n",
       "      <td>107.261213</td>\n",
       "      <td>33.602542</td>\n",
       "      <td>50.410000</td>\n",
       "      <td>84.110000</td>\n",
       "      <td>97.660000</td>\n",
       "      <td>125.400000</td>\n",
       "      <td>251.20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worst area</th>\n",
       "      <td>569.0</td>\n",
       "      <td>880.583128</td>\n",
       "      <td>569.356993</td>\n",
       "      <td>185.200000</td>\n",
       "      <td>515.300000</td>\n",
       "      <td>686.500000</td>\n",
       "      <td>1084.000000</td>\n",
       "      <td>4254.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worst smoothness</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.132369</td>\n",
       "      <td>0.022832</td>\n",
       "      <td>0.071170</td>\n",
       "      <td>0.116600</td>\n",
       "      <td>0.131300</td>\n",
       "      <td>0.146000</td>\n",
       "      <td>0.22260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worst compactness</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.254265</td>\n",
       "      <td>0.157336</td>\n",
       "      <td>0.027290</td>\n",
       "      <td>0.147200</td>\n",
       "      <td>0.211900</td>\n",
       "      <td>0.339100</td>\n",
       "      <td>1.05800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worst concavity</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.272188</td>\n",
       "      <td>0.208624</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.114500</td>\n",
       "      <td>0.226700</td>\n",
       "      <td>0.382900</td>\n",
       "      <td>1.25200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worst concave points</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.114606</td>\n",
       "      <td>0.065732</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.064930</td>\n",
       "      <td>0.099930</td>\n",
       "      <td>0.161400</td>\n",
       "      <td>0.29100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worst symmetry</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.290076</td>\n",
       "      <td>0.061867</td>\n",
       "      <td>0.156500</td>\n",
       "      <td>0.250400</td>\n",
       "      <td>0.282200</td>\n",
       "      <td>0.317900</td>\n",
       "      <td>0.66380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.083946</td>\n",
       "      <td>0.018061</td>\n",
       "      <td>0.055040</td>\n",
       "      <td>0.071460</td>\n",
       "      <td>0.080040</td>\n",
       "      <td>0.092080</td>\n",
       "      <td>0.20750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>benign_0__mal_1</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.627417</td>\n",
       "      <td>0.483918</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         count        mean         std         min  \\\n",
       "mean radius              569.0   14.127292    3.524049    6.981000   \n",
       "mean texture             569.0   19.289649    4.301036    9.710000   \n",
       "mean perimeter           569.0   91.969033   24.298981   43.790000   \n",
       "mean area                569.0  654.889104  351.914129  143.500000   \n",
       "mean smoothness          569.0    0.096360    0.014064    0.052630   \n",
       "mean compactness         569.0    0.104341    0.052813    0.019380   \n",
       "mean concavity           569.0    0.088799    0.079720    0.000000   \n",
       "mean concave points      569.0    0.048919    0.038803    0.000000   \n",
       "mean symmetry            569.0    0.181162    0.027414    0.106000   \n",
       "mean fractal dimension   569.0    0.062798    0.007060    0.049960   \n",
       "radius error             569.0    0.405172    0.277313    0.111500   \n",
       "texture error            569.0    1.216853    0.551648    0.360200   \n",
       "perimeter error          569.0    2.866059    2.021855    0.757000   \n",
       "area error               569.0   40.337079   45.491006    6.802000   \n",
       "smoothness error         569.0    0.007041    0.003003    0.001713   \n",
       "compactness error        569.0    0.025478    0.017908    0.002252   \n",
       "concavity error          569.0    0.031894    0.030186    0.000000   \n",
       "concave points error     569.0    0.011796    0.006170    0.000000   \n",
       "symmetry error           569.0    0.020542    0.008266    0.007882   \n",
       "fractal dimension error  569.0    0.003795    0.002646    0.000895   \n",
       "worst radius             569.0   16.269190    4.833242    7.930000   \n",
       "worst texture            569.0   25.677223    6.146258   12.020000   \n",
       "worst perimeter          569.0  107.261213   33.602542   50.410000   \n",
       "worst area               569.0  880.583128  569.356993  185.200000   \n",
       "worst smoothness         569.0    0.132369    0.022832    0.071170   \n",
       "worst compactness        569.0    0.254265    0.157336    0.027290   \n",
       "worst concavity          569.0    0.272188    0.208624    0.000000   \n",
       "worst concave points     569.0    0.114606    0.065732    0.000000   \n",
       "worst symmetry           569.0    0.290076    0.061867    0.156500   \n",
       "worst fractal dimension  569.0    0.083946    0.018061    0.055040   \n",
       "benign_0__mal_1          569.0    0.627417    0.483918    0.000000   \n",
       "\n",
       "                                25%         50%          75%         max  \n",
       "mean radius               11.700000   13.370000    15.780000    28.11000  \n",
       "mean texture              16.170000   18.840000    21.800000    39.28000  \n",
       "mean perimeter            75.170000   86.240000   104.100000   188.50000  \n",
       "mean area                420.300000  551.100000   782.700000  2501.00000  \n",
       "mean smoothness            0.086370    0.095870     0.105300     0.16340  \n",
       "mean compactness           0.064920    0.092630     0.130400     0.34540  \n",
       "mean concavity             0.029560    0.061540     0.130700     0.42680  \n",
       "mean concave points        0.020310    0.033500     0.074000     0.20120  \n",
       "mean symmetry              0.161900    0.179200     0.195700     0.30400  \n",
       "mean fractal dimension     0.057700    0.061540     0.066120     0.09744  \n",
       "radius error               0.232400    0.324200     0.478900     2.87300  \n",
       "texture error              0.833900    1.108000     1.474000     4.88500  \n",
       "perimeter error            1.606000    2.287000     3.357000    21.98000  \n",
       "area error                17.850000   24.530000    45.190000   542.20000  \n",
       "smoothness error           0.005169    0.006380     0.008146     0.03113  \n",
       "compactness error          0.013080    0.020450     0.032450     0.13540  \n",
       "concavity error            0.015090    0.025890     0.042050     0.39600  \n",
       "concave points error       0.007638    0.010930     0.014710     0.05279  \n",
       "symmetry error             0.015160    0.018730     0.023480     0.07895  \n",
       "fractal dimension error    0.002248    0.003187     0.004558     0.02984  \n",
       "worst radius              13.010000   14.970000    18.790000    36.04000  \n",
       "worst texture             21.080000   25.410000    29.720000    49.54000  \n",
       "worst perimeter           84.110000   97.660000   125.400000   251.20000  \n",
       "worst area               515.300000  686.500000  1084.000000  4254.00000  \n",
       "worst smoothness           0.116600    0.131300     0.146000     0.22260  \n",
       "worst compactness          0.147200    0.211900     0.339100     1.05800  \n",
       "worst concavity            0.114500    0.226700     0.382900     1.25200  \n",
       "worst concave points       0.064930    0.099930     0.161400     0.29100  \n",
       "worst symmetry             0.250400    0.282200     0.317900     0.66380  \n",
       "worst fractal dimension    0.071460    0.080040     0.092080     0.20750  \n",
       "benign_0__mal_1            0.000000    1.000000     1.000000     1.00000  "
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='benign_0__mal_1', ylabel='count'>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='benign_0__mal_1',data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "df.corr()['benign_0__mal_1'][:-1].sort_values().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('benign_0__mal_1',axis=1).values\n",
    "y = df['benign_0__mal_1'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(398, 30)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(30, activation='relu'))     # hidden layer 1\n",
    "model.add(Dense(15, activation='relu'))     # hidden layer 2\n",
    "model.add(Dense(1,activation = 'sigmoid'))  # output layer, sigmoidal because it's an binary classifcation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "13/13 [==============================] - 1s 22ms/step - loss: 0.7916 - val_loss: 0.6575\n",
      "Epoch 2/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5747 - val_loss: 0.4856\n",
      "Epoch 3/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4357 - val_loss: 0.3669\n",
      "Epoch 4/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3382 - val_loss: 0.2796\n",
      "Epoch 5/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.2665 - val_loss: 0.2197\n",
      "Epoch 6/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.2192 - val_loss: 0.1797\n",
      "Epoch 7/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1873 - val_loss: 0.1511\n",
      "Epoch 8/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.1637 - val_loss: 0.1317\n",
      "Epoch 9/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1460 - val_loss: 0.1167\n",
      "Epoch 10/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1319 - val_loss: 0.1052\n",
      "Epoch 11/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1206 - val_loss: 0.0954\n",
      "Epoch 12/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.1115 - val_loss: 0.0876\n",
      "Epoch 13/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1033 - val_loss: 0.0814\n",
      "Epoch 14/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0967 - val_loss: 0.0761\n",
      "Epoch 15/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0906 - val_loss: 0.0722\n",
      "Epoch 16/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0850 - val_loss: 0.0686\n",
      "Epoch 17/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0802 - val_loss: 0.0652\n",
      "Epoch 18/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0761 - val_loss: 0.0624\n",
      "Epoch 19/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0723 - val_loss: 0.0594\n",
      "Epoch 20/600\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0688 - val_loss: 0.0578\n",
      "Epoch 21/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0658 - val_loss: 0.0559\n",
      "Epoch 22/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0630 - val_loss: 0.0550\n",
      "Epoch 23/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0596 - val_loss: 0.0535\n",
      "Epoch 24/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0571 - val_loss: 0.0520\n",
      "Epoch 25/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0554 - val_loss: 0.0499\n",
      "Epoch 26/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0532 - val_loss: 0.0513\n",
      "Epoch 27/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0507 - val_loss: 0.0511\n",
      "Epoch 28/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0488 - val_loss: 0.0523\n",
      "Epoch 29/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0475 - val_loss: 0.0508\n",
      "Epoch 30/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0456 - val_loss: 0.0520\n",
      "Epoch 31/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0439 - val_loss: 0.0509\n",
      "Epoch 32/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0423 - val_loss: 0.0506\n",
      "Epoch 33/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0411 - val_loss: 0.0514\n",
      "Epoch 34/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0396 - val_loss: 0.0510\n",
      "Epoch 35/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0388 - val_loss: 0.0526\n",
      "Epoch 36/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0370 - val_loss: 0.0515\n",
      "Epoch 37/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0359 - val_loss: 0.0509\n",
      "Epoch 38/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0347 - val_loss: 0.0504\n",
      "Epoch 39/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0337 - val_loss: 0.0517\n",
      "Epoch 40/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0323 - val_loss: 0.0516\n",
      "Epoch 41/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0313 - val_loss: 0.0515\n",
      "Epoch 42/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0303 - val_loss: 0.0522\n",
      "Epoch 43/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0295 - val_loss: 0.0520\n",
      "Epoch 44/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0286 - val_loss: 0.0516\n",
      "Epoch 45/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0279 - val_loss: 0.0509\n",
      "Epoch 46/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0268 - val_loss: 0.0518\n",
      "Epoch 47/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0262 - val_loss: 0.0533\n",
      "Epoch 48/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0254 - val_loss: 0.0518\n",
      "Epoch 49/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0244 - val_loss: 0.0517\n",
      "Epoch 50/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0236 - val_loss: 0.0531\n",
      "Epoch 51/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0232 - val_loss: 0.0548\n",
      "Epoch 52/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0225 - val_loss: 0.0534\n",
      "Epoch 53/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0211 - val_loss: 0.0553\n",
      "Epoch 54/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0207 - val_loss: 0.0560\n",
      "Epoch 55/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0200 - val_loss: 0.0549\n",
      "Epoch 56/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0193 - val_loss: 0.0535\n",
      "Epoch 57/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0188 - val_loss: 0.0539\n",
      "Epoch 58/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0181 - val_loss: 0.0546\n",
      "Epoch 59/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0176 - val_loss: 0.0552\n",
      "Epoch 60/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0173 - val_loss: 0.0541\n",
      "Epoch 61/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0166 - val_loss: 0.0554\n",
      "Epoch 62/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0160 - val_loss: 0.0558\n",
      "Epoch 63/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0158 - val_loss: 0.0551\n",
      "Epoch 64/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0149 - val_loss: 0.0561\n",
      "Epoch 65/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0146 - val_loss: 0.0570\n",
      "Epoch 66/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0144 - val_loss: 0.0558\n",
      "Epoch 67/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0136 - val_loss: 0.0573\n",
      "Epoch 68/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0132 - val_loss: 0.0564\n",
      "Epoch 69/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0129 - val_loss: 0.0571\n",
      "Epoch 70/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0122 - val_loss: 0.0592\n",
      "Epoch 71/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0119 - val_loss: 0.0588\n",
      "Epoch 72/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0115 - val_loss: 0.0591\n",
      "Epoch 73/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0111 - val_loss: 0.0578\n",
      "Epoch 74/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0106 - val_loss: 0.0588\n",
      "Epoch 75/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0105 - val_loss: 0.0585\n",
      "Epoch 76/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0098 - val_loss: 0.0624\n",
      "Epoch 77/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0097 - val_loss: 0.0615\n",
      "Epoch 78/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0093 - val_loss: 0.0597\n",
      "Epoch 79/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0089 - val_loss: 0.0604\n",
      "Epoch 80/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0086 - val_loss: 0.0618\n",
      "Epoch 81/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0082 - val_loss: 0.0618\n",
      "Epoch 82/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0081 - val_loss: 0.0618\n",
      "Epoch 83/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0077 - val_loss: 0.0623\n",
      "Epoch 84/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0075 - val_loss: 0.0621\n",
      "Epoch 85/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0072 - val_loss: 0.0622\n",
      "Epoch 86/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0072 - val_loss: 0.0616\n",
      "Epoch 87/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0070 - val_loss: 0.0636\n",
      "Epoch 88/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0067 - val_loss: 0.0631\n",
      "Epoch 89/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0064 - val_loss: 0.0640\n",
      "Epoch 90/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0062 - val_loss: 0.0638\n",
      "Epoch 91/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0060 - val_loss: 0.0638\n",
      "Epoch 92/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0058 - val_loss: 0.0642\n",
      "Epoch 93/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0058 - val_loss: 0.0650\n",
      "Epoch 94/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0054 - val_loss: 0.0639\n",
      "Epoch 95/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0054 - val_loss: 0.0649\n",
      "Epoch 96/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0052 - val_loss: 0.0647\n",
      "Epoch 97/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0049 - val_loss: 0.0664\n",
      "Epoch 98/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0050 - val_loss: 0.0666\n",
      "Epoch 99/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0049 - val_loss: 0.0662\n",
      "Epoch 100/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0046 - val_loss: 0.0663\n",
      "Epoch 101/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0044 - val_loss: 0.0671\n",
      "Epoch 102/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0043 - val_loss: 0.0674\n",
      "Epoch 103/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0042 - val_loss: 0.0684\n",
      "Epoch 104/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0041 - val_loss: 0.0686\n",
      "Epoch 105/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0041 - val_loss: 0.0678\n",
      "Epoch 106/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0039 - val_loss: 0.0687\n",
      "Epoch 107/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0038 - val_loss: 0.0692\n",
      "Epoch 108/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0037 - val_loss: 0.0705\n",
      "Epoch 109/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0037 - val_loss: 0.0708\n",
      "Epoch 110/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0036 - val_loss: 0.0708\n",
      "Epoch 111/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0036 - val_loss: 0.0720\n",
      "Epoch 112/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0034 - val_loss: 0.0720\n",
      "Epoch 113/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0033 - val_loss: 0.0724\n",
      "Epoch 114/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0032 - val_loss: 0.0726\n",
      "Epoch 115/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0032 - val_loss: 0.0737\n",
      "Epoch 116/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0031 - val_loss: 0.0739\n",
      "Epoch 117/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0029 - val_loss: 0.0751\n",
      "Epoch 118/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0029 - val_loss: 0.0752\n",
      "Epoch 119/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0028 - val_loss: 0.0755\n",
      "Epoch 120/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0028 - val_loss: 0.0765\n",
      "Epoch 121/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0026 - val_loss: 0.0768\n",
      "Epoch 122/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0026 - val_loss: 0.0780\n",
      "Epoch 123/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0026 - val_loss: 0.0772\n",
      "Epoch 124/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0024 - val_loss: 0.0784\n",
      "Epoch 125/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0024 - val_loss: 0.0800\n",
      "Epoch 126/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0023 - val_loss: 0.0815\n",
      "Epoch 127/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0022 - val_loss: 0.0812\n",
      "Epoch 128/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0022 - val_loss: 0.0822\n",
      "Epoch 129/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0021 - val_loss: 0.0832\n",
      "Epoch 130/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0020 - val_loss: 0.0848\n",
      "Epoch 131/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0020 - val_loss: 0.0843\n",
      "Epoch 132/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0020 - val_loss: 0.0846\n",
      "Epoch 133/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0019 - val_loss: 0.0851\n",
      "Epoch 134/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0019 - val_loss: 0.0857\n",
      "Epoch 135/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0018 - val_loss: 0.0867\n",
      "Epoch 136/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0018 - val_loss: 0.0878\n",
      "Epoch 137/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0017 - val_loss: 0.0893\n",
      "Epoch 138/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0017 - val_loss: 0.0896\n",
      "Epoch 139/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 0.0899\n",
      "Epoch 140/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 0.0913\n",
      "Epoch 141/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 0.0917\n",
      "Epoch 142/600\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 0.0929\n",
      "Epoch 143/600\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 0.0943\n",
      "Epoch 144/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 0.0954\n",
      "Epoch 145/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 0.0955\n",
      "Epoch 146/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0947\n",
      "Epoch 147/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 0.0961\n",
      "Epoch 148/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0976\n",
      "Epoch 149/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 0.0986\n",
      "Epoch 150/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0998\n",
      "Epoch 151/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 0.0996\n",
      "Epoch 152/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.1007\n",
      "Epoch 153/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 0.1019\n",
      "Epoch 154/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 0.1028\n",
      "Epoch 155/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 0.1029\n",
      "Epoch 156/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 0.1045\n",
      "Epoch 157/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 0.1057\n",
      "Epoch 158/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.1052\n",
      "Epoch 159/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 0.1058\n",
      "Epoch 160/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 0.1060\n",
      "Epoch 161/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 0.1068\n",
      "Epoch 162/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 9.8654e-04 - val_loss: 0.1082\n",
      "Epoch 163/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 9.7146e-04 - val_loss: 0.1089\n",
      "Epoch 164/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 9.5735e-04 - val_loss: 0.1090\n",
      "Epoch 165/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 9.4033e-04 - val_loss: 0.1101\n",
      "Epoch 166/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 9.1826e-04 - val_loss: 0.1103\n",
      "Epoch 167/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 8.9426e-04 - val_loss: 0.1112\n",
      "Epoch 168/600\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 8.8034e-04 - val_loss: 0.1123\n",
      "Epoch 169/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 8.7798e-04 - val_loss: 0.1124\n",
      "Epoch 170/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 8.4943e-04 - val_loss: 0.1125\n",
      "Epoch 171/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 8.2496e-04 - val_loss: 0.1136\n",
      "Epoch 172/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 8.2574e-04 - val_loss: 0.1146\n",
      "Epoch 173/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 8.4129e-04 - val_loss: 0.1151\n",
      "Epoch 174/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 7.9801e-04 - val_loss: 0.1164\n",
      "Epoch 175/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 7.7070e-04 - val_loss: 0.1170\n",
      "Epoch 176/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 7.6696e-04 - val_loss: 0.1163\n",
      "Epoch 177/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 7.5193e-04 - val_loss: 0.1166\n",
      "Epoch 178/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 7.3475e-04 - val_loss: 0.1174\n",
      "Epoch 179/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 7.2004e-04 - val_loss: 0.1196\n",
      "Epoch 180/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 6.9632e-04 - val_loss: 0.1208\n",
      "Epoch 181/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 6.7984e-04 - val_loss: 0.1215\n",
      "Epoch 182/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 6.6786e-04 - val_loss: 0.1220\n",
      "Epoch 183/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 6.6590e-04 - val_loss: 0.1218\n",
      "Epoch 184/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 6.4629e-04 - val_loss: 0.1222\n",
      "Epoch 185/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 6.3699e-04 - val_loss: 0.1228\n",
      "Epoch 186/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 6.4083e-04 - val_loss: 0.1230\n",
      "Epoch 187/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 6.1251e-04 - val_loss: 0.1238\n",
      "Epoch 188/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 6.0382e-04 - val_loss: 0.1250\n",
      "Epoch 189/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 5.9296e-04 - val_loss: 0.1262\n",
      "Epoch 190/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 5.9090e-04 - val_loss: 0.1266\n",
      "Epoch 191/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 5.7398e-04 - val_loss: 0.1268\n",
      "Epoch 192/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 5.6652e-04 - val_loss: 0.1267\n",
      "Epoch 193/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 5.5833e-04 - val_loss: 0.1272\n",
      "Epoch 194/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 5.4772e-04 - val_loss: 0.1282\n",
      "Epoch 195/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 5.4331e-04 - val_loss: 0.1282\n",
      "Epoch 196/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 5.2555e-04 - val_loss: 0.1294\n",
      "Epoch 197/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 5.1963e-04 - val_loss: 0.1303\n",
      "Epoch 198/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 5.1412e-04 - val_loss: 0.1317\n",
      "Epoch 199/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 4.9675e-04 - val_loss: 0.1326\n",
      "Epoch 200/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 4.9123e-04 - val_loss: 0.1334\n",
      "Epoch 201/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 4.7334e-04 - val_loss: 0.1337\n",
      "Epoch 202/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 4.7408e-04 - val_loss: 0.1337\n",
      "Epoch 203/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 4.6523e-04 - val_loss: 0.1342\n",
      "Epoch 204/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 4.5531e-04 - val_loss: 0.1345\n",
      "Epoch 205/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5144e-04 - val_loss: 0.1344\n",
      "Epoch 206/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 4.3609e-04 - val_loss: 0.1348\n",
      "Epoch 207/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3420e-04 - val_loss: 0.1362\n",
      "Epoch 208/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 4.3107e-04 - val_loss: 0.1365\n",
      "Epoch 209/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 4.2084e-04 - val_loss: 0.1370\n",
      "Epoch 210/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 4.1568e-04 - val_loss: 0.1372\n",
      "Epoch 211/600\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 4.0776e-04 - val_loss: 0.1382\n",
      "Epoch 212/600\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3.9709e-04 - val_loss: 0.1392\n",
      "Epoch 213/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 3.9876e-04 - val_loss: 0.1400\n",
      "Epoch 214/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 3.8494e-04 - val_loss: 0.1396\n",
      "Epoch 215/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 3.8264e-04 - val_loss: 0.1400\n",
      "Epoch 216/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 3.7273e-04 - val_loss: 0.1406\n",
      "Epoch 217/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 3.7903e-04 - val_loss: 0.1403\n",
      "Epoch 218/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 3.7338e-04 - val_loss: 0.1416\n",
      "Epoch 219/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 3.6609e-04 - val_loss: 0.1429\n",
      "Epoch 220/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 3.5300e-04 - val_loss: 0.1436\n",
      "Epoch 221/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 3.5112e-04 - val_loss: 0.1446\n",
      "Epoch 222/600\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 3.3937e-04 - val_loss: 0.1443\n",
      "Epoch 223/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 3.4105e-04 - val_loss: 0.1449\n",
      "Epoch 224/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 3.2789e-04 - val_loss: 0.1455\n",
      "Epoch 225/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 3.2988e-04 - val_loss: 0.1457\n",
      "Epoch 226/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 3.2019e-04 - val_loss: 0.1469\n",
      "Epoch 227/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 3.2057e-04 - val_loss: 0.1466\n",
      "Epoch 228/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 3.1018e-04 - val_loss: 0.1479\n",
      "Epoch 229/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 3.0945e-04 - val_loss: 0.1492\n",
      "Epoch 230/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 3.0814e-04 - val_loss: 0.1498\n",
      "Epoch 231/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 2.9910e-04 - val_loss: 0.1499\n",
      "Epoch 232/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 2.9753e-04 - val_loss: 0.1506\n",
      "Epoch 233/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 2.9039e-04 - val_loss: 0.1513\n",
      "Epoch 234/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 2.8609e-04 - val_loss: 0.1516\n",
      "Epoch 235/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 2.8240e-04 - val_loss: 0.1517\n",
      "Epoch 236/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 2.7977e-04 - val_loss: 0.1524\n",
      "Epoch 237/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 2.7310e-04 - val_loss: 0.1534\n",
      "Epoch 238/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 2.7375e-04 - val_loss: 0.1534\n",
      "Epoch 239/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 2.6734e-04 - val_loss: 0.1541\n",
      "Epoch 240/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 2.6556e-04 - val_loss: 0.1545\n",
      "Epoch 241/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 2.6086e-04 - val_loss: 0.1546\n",
      "Epoch 242/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 2.5776e-04 - val_loss: 0.1548\n",
      "Epoch 243/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 2.5456e-04 - val_loss: 0.1555\n",
      "Epoch 244/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.4914e-04 - val_loss: 0.1565\n",
      "Epoch 245/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 2.4988e-04 - val_loss: 0.1562\n",
      "Epoch 246/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 2.4392e-04 - val_loss: 0.1569\n",
      "Epoch 247/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 2.4133e-04 - val_loss: 0.1570\n",
      "Epoch 248/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.3737e-04 - val_loss: 0.1574\n",
      "Epoch 249/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 2.3583e-04 - val_loss: 0.1580\n",
      "Epoch 250/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 2.3635e-04 - val_loss: 0.1576\n",
      "Epoch 251/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 2.3565e-04 - val_loss: 0.1577\n",
      "Epoch 252/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 2.2934e-04 - val_loss: 0.1589\n",
      "Epoch 253/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 2.2452e-04 - val_loss: 0.1597\n",
      "Epoch 254/600\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.4085e-0 - 0s 7ms/step - loss: 2.1962e-04 - val_loss: 0.1608\n",
      "Epoch 255/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 2.1615e-04 - val_loss: 0.1609\n",
      "Epoch 256/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 2.1337e-04 - val_loss: 0.1620\n",
      "Epoch 257/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 2.1319e-04 - val_loss: 0.1627\n",
      "Epoch 258/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 2.1319e-04 - val_loss: 0.1621\n",
      "Epoch 259/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 2.1062e-04 - val_loss: 0.1633\n",
      "Epoch 260/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 2.0695e-04 - val_loss: 0.1645\n",
      "Epoch 261/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 2.0218e-04 - val_loss: 0.1648\n",
      "Epoch 262/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.9682e-04 - val_loss: 0.1656\n",
      "Epoch 263/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 1.9433e-04 - val_loss: 0.1660\n",
      "Epoch 264/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.9180e-04 - val_loss: 0.1666\n",
      "Epoch 265/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.8869e-04 - val_loss: 0.1672\n",
      "Epoch 266/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.8647e-04 - val_loss: 0.1675\n",
      "Epoch 267/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.8519e-04 - val_loss: 0.1685\n",
      "Epoch 268/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.8350e-04 - val_loss: 0.1688\n",
      "Epoch 269/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.8170e-04 - val_loss: 0.1698\n",
      "Epoch 270/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.7766e-04 - val_loss: 0.1701\n",
      "Epoch 271/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 1.7743e-04 - val_loss: 0.1715\n",
      "Epoch 272/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 1.7526e-04 - val_loss: 0.1719\n",
      "Epoch 273/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.7317e-04 - val_loss: 0.1721\n",
      "Epoch 274/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.7338e-04 - val_loss: 0.1723\n",
      "Epoch 275/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.6760e-04 - val_loss: 0.1729\n",
      "Epoch 276/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.6617e-04 - val_loss: 0.1741\n",
      "Epoch 277/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.6412e-04 - val_loss: 0.1744\n",
      "Epoch 278/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.6098e-04 - val_loss: 0.1746\n",
      "Epoch 279/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.6060e-04 - val_loss: 0.1745\n",
      "Epoch 280/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.5829e-04 - val_loss: 0.1751\n",
      "Epoch 281/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.5527e-04 - val_loss: 0.1757\n",
      "Epoch 282/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.5295e-04 - val_loss: 0.1757\n",
      "Epoch 283/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.5066e-04 - val_loss: 0.1767\n",
      "Epoch 284/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.5003e-04 - val_loss: 0.1769\n",
      "Epoch 285/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.4737e-04 - val_loss: 0.1777\n",
      "Epoch 286/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.4577e-04 - val_loss: 0.1779\n",
      "Epoch 287/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.4392e-04 - val_loss: 0.1785\n",
      "Epoch 288/600\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.9074e-0 - 0s 7ms/step - loss: 1.4264e-04 - val_loss: 0.1793\n",
      "Epoch 289/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.4162e-04 - val_loss: 0.1792\n",
      "Epoch 290/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.3986e-04 - val_loss: 0.1799\n",
      "Epoch 291/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.3781e-04 - val_loss: 0.1813\n",
      "Epoch 292/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.3752e-04 - val_loss: 0.1815\n",
      "Epoch 293/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.3362e-04 - val_loss: 0.1824\n",
      "Epoch 294/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.3200e-04 - val_loss: 0.1830\n",
      "Epoch 295/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.3103e-04 - val_loss: 0.1836\n",
      "Epoch 296/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.3085e-04 - val_loss: 0.1842\n",
      "Epoch 297/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 1.2854e-04 - val_loss: 0.1846\n",
      "Epoch 298/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.2778e-04 - val_loss: 0.1849\n",
      "Epoch 299/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.2554e-04 - val_loss: 0.1856\n",
      "Epoch 300/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.2463e-04 - val_loss: 0.1860\n",
      "Epoch 301/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.2279e-04 - val_loss: 0.1866\n",
      "Epoch 302/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.2089e-04 - val_loss: 0.1869\n",
      "Epoch 303/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.2020e-04 - val_loss: 0.1873\n",
      "Epoch 304/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.2016e-04 - val_loss: 0.1881\n",
      "Epoch 305/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.1785e-04 - val_loss: 0.1884\n",
      "Epoch 306/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.1717e-04 - val_loss: 0.1885\n",
      "Epoch 307/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.1365e-04 - val_loss: 0.1887\n",
      "Epoch 308/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.1278e-04 - val_loss: 0.1897\n",
      "Epoch 309/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.1221e-04 - val_loss: 0.1900\n",
      "Epoch 310/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.1071e-04 - val_loss: 0.1907\n",
      "Epoch 311/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.1054e-04 - val_loss: 0.1913\n",
      "Epoch 312/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.0752e-04 - val_loss: 0.1918\n",
      "Epoch 313/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.0630e-04 - val_loss: 0.1926\n",
      "Epoch 314/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.0906e-04 - val_loss: 0.1927\n",
      "Epoch 315/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.0466e-04 - val_loss: 0.1919\n",
      "Epoch 316/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.0510e-04 - val_loss: 0.1922\n",
      "Epoch 317/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.0286e-04 - val_loss: 0.1928\n",
      "Epoch 318/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.0184e-04 - val_loss: 0.1934\n",
      "Epoch 319/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 9.9409e-05 - val_loss: 0.1940\n",
      "Epoch 320/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 9.8444e-05 - val_loss: 0.1951\n",
      "Epoch 321/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 9.7774e-05 - val_loss: 0.1956\n",
      "Epoch 322/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 9.5945e-05 - val_loss: 0.1961\n",
      "Epoch 323/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 9.5199e-05 - val_loss: 0.1966\n",
      "Epoch 324/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 9.3969e-05 - val_loss: 0.1972\n",
      "Epoch 325/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 9.4394e-05 - val_loss: 0.1975\n",
      "Epoch 326/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 9.1873e-05 - val_loss: 0.1974\n",
      "Epoch 327/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 9.1407e-05 - val_loss: 0.1979\n",
      "Epoch 328/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 8.9733e-05 - val_loss: 0.1990\n",
      "Epoch 329/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 9.0100e-05 - val_loss: 0.1990\n",
      "Epoch 330/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 8.8004e-05 - val_loss: 0.1995\n",
      "Epoch 331/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 8.8187e-05 - val_loss: 0.2003\n",
      "Epoch 332/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 8.6808e-05 - val_loss: 0.2007\n",
      "Epoch 333/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 8.5342e-05 - val_loss: 0.2012\n",
      "Epoch 334/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 8.5055e-05 - val_loss: 0.2019\n",
      "Epoch 335/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 8.3945e-05 - val_loss: 0.2020\n",
      "Epoch 336/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 8.2851e-05 - val_loss: 0.2024\n",
      "Epoch 337/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 8.2237e-05 - val_loss: 0.2030\n",
      "Epoch 338/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 8.1452e-05 - val_loss: 0.2038\n",
      "Epoch 339/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 8.0538e-05 - val_loss: 0.2041\n",
      "Epoch 340/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 7.9569e-05 - val_loss: 0.2046\n",
      "Epoch 341/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 7.8919e-05 - val_loss: 0.2047\n",
      "Epoch 342/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 7.8092e-05 - val_loss: 0.2053\n",
      "Epoch 343/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 7.6977e-05 - val_loss: 0.2056\n",
      "Epoch 344/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 7.6222e-05 - val_loss: 0.2061\n",
      "Epoch 345/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 7.5292e-05 - val_loss: 0.2065\n",
      "Epoch 346/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 7.4875e-05 - val_loss: 0.2064\n",
      "Epoch 347/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 7.4109e-05 - val_loss: 0.2072\n",
      "Epoch 348/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 7.3810e-05 - val_loss: 0.2075\n",
      "Epoch 349/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 7.2426e-05 - val_loss: 0.2078\n",
      "Epoch 350/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.1525e-05 - val_loss: 0.2078\n",
      "Epoch 351/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 7.1400e-05 - val_loss: 0.2090\n",
      "Epoch 352/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.0804e-05 - val_loss: 0.2087\n",
      "Epoch 353/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 7.0391e-05 - val_loss: 0.2098\n",
      "Epoch 354/600\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 6.9468e-05 - val_loss: 0.2103\n",
      "Epoch 355/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 6.8495e-05 - val_loss: 0.2112\n",
      "Epoch 356/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 6.7349e-05 - val_loss: 0.2116\n",
      "Epoch 357/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 6.7004e-05 - val_loss: 0.2118\n",
      "Epoch 358/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 6.6380e-05 - val_loss: 0.2118\n",
      "Epoch 359/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 6.5423e-05 - val_loss: 0.2123\n",
      "Epoch 360/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 6.4658e-05 - val_loss: 0.2130\n",
      "Epoch 361/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 6.4107e-05 - val_loss: 0.2131\n",
      "Epoch 362/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 6.4430e-05 - val_loss: 0.2134\n",
      "Epoch 363/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 6.2743e-05 - val_loss: 0.2135\n",
      "Epoch 364/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 6.2187e-05 - val_loss: 0.2141\n",
      "Epoch 365/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 6.1520e-05 - val_loss: 0.2144\n",
      "Epoch 366/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 6.1471e-05 - val_loss: 0.2155\n",
      "Epoch 367/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 6.0610e-05 - val_loss: 0.2163\n",
      "Epoch 368/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 5.9743e-05 - val_loss: 0.2168\n",
      "Epoch 369/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 5.8966e-05 - val_loss: 0.2170\n",
      "Epoch 370/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 5.8358e-05 - val_loss: 0.2175\n",
      "Epoch 371/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 5.8092e-05 - val_loss: 0.2181\n",
      "Epoch 372/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 5.7271e-05 - val_loss: 0.2183\n",
      "Epoch 373/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 5.6644e-05 - val_loss: 0.2186\n",
      "Epoch 374/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 5.6195e-05 - val_loss: 0.2188\n",
      "Epoch 375/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 5.5638e-05 - val_loss: 0.2195\n",
      "Epoch 376/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 5.5552e-05 - val_loss: 0.2190\n",
      "Epoch 377/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 5.6345e-05 - val_loss: 0.2197\n",
      "Epoch 378/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 5.4001e-05 - val_loss: 0.2206\n",
      "Epoch 379/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 5.3704e-05 - val_loss: 0.2211\n",
      "Epoch 380/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 5.2697e-05 - val_loss: 0.2207\n",
      "Epoch 381/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 5.3185e-05 - val_loss: 0.2209\n",
      "Epoch 382/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 5.1899e-05 - val_loss: 0.2218\n",
      "Epoch 383/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 5.1204e-05 - val_loss: 0.2222\n",
      "Epoch 384/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 5.0555e-05 - val_loss: 0.2227\n",
      "Epoch 385/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 5.0036e-05 - val_loss: 0.2235\n",
      "Epoch 386/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 4.9349e-05 - val_loss: 0.2241\n",
      "Epoch 387/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 4.9208e-05 - val_loss: 0.2244\n",
      "Epoch 388/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 4.8458e-05 - val_loss: 0.2258\n",
      "Epoch 389/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 4.8441e-05 - val_loss: 0.2264\n",
      "Epoch 390/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 4.7624e-05 - val_loss: 0.2272\n",
      "Epoch 391/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 4.7175e-05 - val_loss: 0.2272\n",
      "Epoch 392/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 4.6599e-05 - val_loss: 0.2275\n",
      "Epoch 393/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 4.6251e-05 - val_loss: 0.2277\n",
      "Epoch 394/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 4.5690e-05 - val_loss: 0.2277\n",
      "Epoch 395/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 4.5318e-05 - val_loss: 0.2280\n",
      "Epoch 396/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 4.4684e-05 - val_loss: 0.2290\n",
      "Epoch 397/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 4.4684e-05 - val_loss: 0.2292\n",
      "Epoch 398/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 4.3970e-05 - val_loss: 0.2294\n",
      "Epoch 399/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 4.3457e-05 - val_loss: 0.2294\n",
      "Epoch 400/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 4.3208e-05 - val_loss: 0.2297\n",
      "Epoch 401/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 4.2671e-05 - val_loss: 0.2302\n",
      "Epoch 402/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 4.2089e-05 - val_loss: 0.2301\n",
      "Epoch 403/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 4.1820e-05 - val_loss: 0.2309\n",
      "Epoch 404/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 4.1274e-05 - val_loss: 0.2316\n",
      "Epoch 405/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 4.1424e-05 - val_loss: 0.2317\n",
      "Epoch 406/600\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 4.0553e-05 - val_loss: 0.2317\n",
      "Epoch 407/600\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 4.0523e-05 - val_loss: 0.2321\n",
      "Epoch 408/600\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 3.9686e-05 - val_loss: 0.2326\n",
      "Epoch 409/600\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3.9740e-05 - val_loss: 0.2326\n",
      "Epoch 410/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 4.0213e-05 - val_loss: 0.2324\n",
      "Epoch 411/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 3.9071e-05 - val_loss: 0.2331\n",
      "Epoch 412/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 3.8672e-05 - val_loss: 0.2338\n",
      "Epoch 413/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 3.8583e-05 - val_loss: 0.2342\n",
      "Epoch 414/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 3.7760e-05 - val_loss: 0.2340\n",
      "Epoch 415/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 3.7691e-05 - val_loss: 0.2346\n",
      "Epoch 416/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 3.6998e-05 - val_loss: 0.2353\n",
      "Epoch 417/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 3.6484e-05 - val_loss: 0.2364\n",
      "Epoch 418/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 3.6367e-05 - val_loss: 0.2364\n",
      "Epoch 419/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 3.5982e-05 - val_loss: 0.2363\n",
      "Epoch 420/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 3.5804e-05 - val_loss: 0.2367\n",
      "Epoch 421/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 3.5635e-05 - val_loss: 0.2373\n",
      "Epoch 422/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 3.5577e-05 - val_loss: 0.2374\n",
      "Epoch 423/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 3.4557e-05 - val_loss: 0.2374\n",
      "Epoch 424/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 3.4724e-05 - val_loss: 0.2379\n",
      "Epoch 425/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 3.3930e-05 - val_loss: 0.2386\n",
      "Epoch 426/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 3.3547e-05 - val_loss: 0.2389\n",
      "Epoch 427/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 3.3215e-05 - val_loss: 0.2393\n",
      "Epoch 428/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 3.2961e-05 - val_loss: 0.2394\n",
      "Epoch 429/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 3.2771e-05 - val_loss: 0.2400\n",
      "Epoch 430/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 3.2452e-05 - val_loss: 0.2400\n",
      "Epoch 431/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 3.2089e-05 - val_loss: 0.2404\n",
      "Epoch 432/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 3.1806e-05 - val_loss: 0.2407\n",
      "Epoch 433/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 3.1382e-05 - val_loss: 0.2409\n",
      "Epoch 434/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 3.1110e-05 - val_loss: 0.2411\n",
      "Epoch 435/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 3.0862e-05 - val_loss: 0.2416\n",
      "Epoch 436/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 3.0672e-05 - val_loss: 0.2413\n",
      "Epoch 437/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 3.0251e-05 - val_loss: 0.2421\n",
      "Epoch 438/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 3.0131e-05 - val_loss: 0.2422\n",
      "Epoch 439/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.9782e-05 - val_loss: 0.2429\n",
      "Epoch 440/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 2.9737e-05 - val_loss: 0.2440\n",
      "Epoch 441/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 2.9466e-05 - val_loss: 0.2444\n",
      "Epoch 442/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.8985e-05 - val_loss: 0.2444\n",
      "Epoch 443/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.8736e-05 - val_loss: 0.2445\n",
      "Epoch 444/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.8337e-05 - val_loss: 0.2445\n",
      "Epoch 445/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.8389e-05 - val_loss: 0.2448\n",
      "Epoch 446/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.7839e-05 - val_loss: 0.2455\n",
      "Epoch 447/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.7872e-05 - val_loss: 0.2455\n",
      "Epoch 448/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.7411e-05 - val_loss: 0.2465\n",
      "Epoch 449/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 2.7236e-05 - val_loss: 0.2467\n",
      "Epoch 450/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 2.6986e-05 - val_loss: 0.2474\n",
      "Epoch 451/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 2.6827e-05 - val_loss: 0.2475\n",
      "Epoch 452/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 2.6423e-05 - val_loss: 0.2477\n",
      "Epoch 453/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.6461e-05 - val_loss: 0.2478\n",
      "Epoch 454/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.5925e-05 - val_loss: 0.2481\n",
      "Epoch 455/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.5761e-05 - val_loss: 0.2485\n",
      "Epoch 456/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.5680e-05 - val_loss: 0.2491\n",
      "Epoch 457/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.5616e-05 - val_loss: 0.2488\n",
      "Epoch 458/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.5393e-05 - val_loss: 0.2492\n",
      "Epoch 459/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 2.4849e-05 - val_loss: 0.2492\n",
      "Epoch 460/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 2.4682e-05 - val_loss: 0.2502\n",
      "Epoch 461/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.4613e-05 - val_loss: 0.2509\n",
      "Epoch 462/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.4099e-05 - val_loss: 0.2514\n",
      "Epoch 463/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.3952e-05 - val_loss: 0.2518\n",
      "Epoch 464/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 2.3643e-05 - val_loss: 0.2521\n",
      "Epoch 465/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 2.3478e-05 - val_loss: 0.2520\n",
      "Epoch 466/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.3133e-05 - val_loss: 0.2529\n",
      "Epoch 467/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.3077e-05 - val_loss: 0.2530\n",
      "Epoch 468/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 2.2757e-05 - val_loss: 0.2531\n",
      "Epoch 469/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.2534e-05 - val_loss: 0.2530\n",
      "Epoch 470/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 2.2574e-05 - val_loss: 0.2535\n",
      "Epoch 471/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.2304e-05 - val_loss: 0.2528\n",
      "Epoch 472/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 2.2073e-05 - val_loss: 0.2534\n",
      "Epoch 473/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.1847e-05 - val_loss: 0.2540\n",
      "Epoch 474/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.1490e-05 - val_loss: 0.2541\n",
      "Epoch 475/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 2.1494e-05 - val_loss: 0.2541\n",
      "Epoch 476/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.1237e-05 - val_loss: 0.2549\n",
      "Epoch 477/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.1035e-05 - val_loss: 0.2556\n",
      "Epoch 478/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.0782e-05 - val_loss: 0.2553\n",
      "Epoch 479/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.0605e-05 - val_loss: 0.2557\n",
      "Epoch 480/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.0555e-05 - val_loss: 0.2570\n",
      "Epoch 481/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.0328e-05 - val_loss: 0.2576\n",
      "Epoch 482/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.0039e-05 - val_loss: 0.2577\n",
      "Epoch 483/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.9802e-05 - val_loss: 0.2576\n",
      "Epoch 484/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.9747e-05 - val_loss: 0.2578\n",
      "Epoch 485/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.9535e-05 - val_loss: 0.2580\n",
      "Epoch 486/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.9306e-05 - val_loss: 0.2586\n",
      "Epoch 487/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.9146e-05 - val_loss: 0.2588\n",
      "Epoch 488/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.8997e-05 - val_loss: 0.2592\n",
      "Epoch 489/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.8896e-05 - val_loss: 0.2594\n",
      "Epoch 490/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.8654e-05 - val_loss: 0.2593\n",
      "Epoch 491/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.8618e-05 - val_loss: 0.2595\n",
      "Epoch 492/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.8315e-05 - val_loss: 0.2600\n",
      "Epoch 493/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.8373e-05 - val_loss: 0.2601\n",
      "Epoch 494/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.8329e-05 - val_loss: 0.2598\n",
      "Epoch 495/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.8057e-05 - val_loss: 0.2602\n",
      "Epoch 496/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.7935e-05 - val_loss: 0.2608\n",
      "Epoch 497/600\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 1.7643e-05 - val_loss: 0.2611\n",
      "Epoch 498/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 1.7491e-05 - val_loss: 0.2618\n",
      "Epoch 499/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 1.7204e-05 - val_loss: 0.2618\n",
      "Epoch 500/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.7197e-05 - val_loss: 0.2626\n",
      "Epoch 501/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.6938e-05 - val_loss: 0.2628\n",
      "Epoch 502/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.6860e-05 - val_loss: 0.2633\n",
      "Epoch 503/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.6669e-05 - val_loss: 0.2630\n",
      "Epoch 504/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.6585e-05 - val_loss: 0.2637\n",
      "Epoch 505/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.6363e-05 - val_loss: 0.2642\n",
      "Epoch 506/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.6247e-05 - val_loss: 0.2647\n",
      "Epoch 507/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.6088e-05 - val_loss: 0.2652\n",
      "Epoch 508/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.6097e-05 - val_loss: 0.2647\n",
      "Epoch 509/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.5773e-05 - val_loss: 0.2649\n",
      "Epoch 510/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.5828e-05 - val_loss: 0.2655\n",
      "Epoch 511/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.5533e-05 - val_loss: 0.2659\n",
      "Epoch 512/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.5394e-05 - val_loss: 0.2664\n",
      "Epoch 513/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.5384e-05 - val_loss: 0.2661\n",
      "Epoch 514/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.5235e-05 - val_loss: 0.2662\n",
      "Epoch 515/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.5090e-05 - val_loss: 0.2668\n",
      "Epoch 516/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.4944e-05 - val_loss: 0.2676\n",
      "Epoch 517/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.4734e-05 - val_loss: 0.2679\n",
      "Epoch 518/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.4550e-05 - val_loss: 0.2685\n",
      "Epoch 519/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.4428e-05 - val_loss: 0.2685\n",
      "Epoch 520/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.4329e-05 - val_loss: 0.2688\n",
      "Epoch 521/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.4302e-05 - val_loss: 0.2685\n",
      "Epoch 522/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.4157e-05 - val_loss: 0.2692\n",
      "Epoch 523/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.3921e-05 - val_loss: 0.2695\n",
      "Epoch 524/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.3871e-05 - val_loss: 0.2696\n",
      "Epoch 525/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.3651e-05 - val_loss: 0.2698\n",
      "Epoch 526/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.3627e-05 - val_loss: 0.2698\n",
      "Epoch 527/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.3527e-05 - val_loss: 0.2703\n",
      "Epoch 528/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.3365e-05 - val_loss: 0.2706\n",
      "Epoch 529/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.3294e-05 - val_loss: 0.2714\n",
      "Epoch 530/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.3159e-05 - val_loss: 0.2712\n",
      "Epoch 531/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.3029e-05 - val_loss: 0.2715\n",
      "Epoch 532/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.2880e-05 - val_loss: 0.2719\n",
      "Epoch 533/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.2837e-05 - val_loss: 0.2725\n",
      "Epoch 534/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.2811e-05 - val_loss: 0.2719\n",
      "Epoch 535/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.2691e-05 - val_loss: 0.2721\n",
      "Epoch 536/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.2541e-05 - val_loss: 0.2728\n",
      "Epoch 537/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.2395e-05 - val_loss: 0.2737\n",
      "Epoch 538/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 1.2254e-05 - val_loss: 0.2733\n",
      "Epoch 539/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.2187e-05 - val_loss: 0.2734\n",
      "Epoch 540/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.1999e-05 - val_loss: 0.2739\n",
      "Epoch 541/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.1995e-05 - val_loss: 0.2743\n",
      "Epoch 542/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.1867e-05 - val_loss: 0.2743\n",
      "Epoch 543/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.1691e-05 - val_loss: 0.2749\n",
      "Epoch 544/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.1628e-05 - val_loss: 0.2752\n",
      "Epoch 545/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.1599e-05 - val_loss: 0.2753\n",
      "Epoch 546/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.1417e-05 - val_loss: 0.2756\n",
      "Epoch 547/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.1361e-05 - val_loss: 0.2759\n",
      "Epoch 548/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.1374e-05 - val_loss: 0.2763\n",
      "Epoch 549/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.1143e-05 - val_loss: 0.2763\n",
      "Epoch 550/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.1117e-05 - val_loss: 0.2768\n",
      "Epoch 551/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.0935e-05 - val_loss: 0.2768\n",
      "Epoch 552/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.0896e-05 - val_loss: 0.2771\n",
      "Epoch 553/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.0814e-05 - val_loss: 0.2781\n",
      "Epoch 554/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.0689e-05 - val_loss: 0.2781\n",
      "Epoch 555/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.0620e-05 - val_loss: 0.2781\n",
      "Epoch 556/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.0490e-05 - val_loss: 0.2784\n",
      "Epoch 557/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.0451e-05 - val_loss: 0.2786\n",
      "Epoch 558/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.0323e-05 - val_loss: 0.2791\n",
      "Epoch 559/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 1.0299e-05 - val_loss: 0.2798\n",
      "Epoch 560/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.0256e-05 - val_loss: 0.2801\n",
      "Epoch 561/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.0114e-05 - val_loss: 0.2806\n",
      "Epoch 562/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.0052e-05 - val_loss: 0.2808\n",
      "Epoch 563/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 9.9320e-06 - val_loss: 0.2810\n",
      "Epoch 564/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 9.8549e-06 - val_loss: 0.2815\n",
      "Epoch 565/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 9.7729e-06 - val_loss: 0.2815\n",
      "Epoch 566/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 9.6900e-06 - val_loss: 0.2819\n",
      "Epoch 567/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 9.5721e-06 - val_loss: 0.2821\n",
      "Epoch 568/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 9.5369e-06 - val_loss: 0.2827\n",
      "Epoch 569/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 9.4453e-06 - val_loss: 0.2826\n",
      "Epoch 570/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 9.4087e-06 - val_loss: 0.2834\n",
      "Epoch 571/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 9.2660e-06 - val_loss: 0.2836\n",
      "Epoch 572/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 9.4097e-06 - val_loss: 0.2840\n",
      "Epoch 573/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 9.2078e-06 - val_loss: 0.2837\n",
      "Epoch 574/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 9.0761e-06 - val_loss: 0.2840\n",
      "Epoch 575/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 9.0657e-06 - val_loss: 0.2840\n",
      "Epoch 576/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 8.9146e-06 - val_loss: 0.2840\n",
      "Epoch 577/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 8.8542e-06 - val_loss: 0.2843\n",
      "Epoch 578/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 8.7559e-06 - val_loss: 0.2845\n",
      "Epoch 579/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 8.6824e-06 - val_loss: 0.2855\n",
      "Epoch 580/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 8.6259e-06 - val_loss: 0.2854\n",
      "Epoch 581/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 8.5750e-06 - val_loss: 0.2859\n",
      "Epoch 582/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 8.4637e-06 - val_loss: 0.2868\n",
      "Epoch 583/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 8.4387e-06 - val_loss: 0.2869\n",
      "Epoch 584/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 8.3765e-06 - val_loss: 0.2871\n",
      "Epoch 585/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 8.3508e-06 - val_loss: 0.2873\n",
      "Epoch 586/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 8.2164e-06 - val_loss: 0.2871\n",
      "Epoch 587/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 8.1421e-06 - val_loss: 0.2876\n",
      "Epoch 588/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 8.0952e-06 - val_loss: 0.2876\n",
      "Epoch 589/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 8.0098e-06 - val_loss: 0.2883\n",
      "Epoch 590/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 7.9315e-06 - val_loss: 0.2888\n",
      "Epoch 591/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 7.9979e-06 - val_loss: 0.2890\n",
      "Epoch 592/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 7.8637e-06 - val_loss: 0.2892\n",
      "Epoch 593/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 7.7821e-06 - val_loss: 0.2896\n",
      "Epoch 594/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 7.7490e-06 - val_loss: 0.2899\n",
      "Epoch 595/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 7.6932e-06 - val_loss: 0.2892\n",
      "Epoch 596/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 7.7023e-06 - val_loss: 0.2896\n",
      "Epoch 597/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 7.5816e-06 - val_loss: 0.2900\n",
      "Epoch 598/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 7.5911e-06 - val_loss: 0.2904\n",
      "Epoch 599/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 7.3291e-06 - val_loss: 0.2905\n",
      "Epoch 600/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 7.3378e-06 - val_loss: 0.2908\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b1d84c8190>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train, epochs=600, validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.791649</td>\n",
       "      <td>0.657511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.574652</td>\n",
       "      <td>0.485579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.435737</td>\n",
       "      <td>0.366918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.338176</td>\n",
       "      <td>0.279599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.266545</td>\n",
       "      <td>0.219665</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       loss  val_loss\n",
       "0  0.791649  0.657511\n",
       "1  0.574652  0.485579\n",
       "2  0.435737  0.366918\n",
       "3  0.338176  0.279599\n",
       "4  0.266545  0.219665"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = pd.DataFrame(model.history.history)\n",
    "loss[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss.plot()     # this is an example for overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.95        63\n",
      "           1       0.98      0.96      0.97       108\n",
      "\n",
      "    accuracy                           0.96       171\n",
      "   macro avg       0.96      0.97      0.96       171\n",
      "weighted avg       0.97      0.96      0.97       171\n",
      "\n",
      "[[ 61   2]\n",
      " [  4 104]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "print(classification_report(y_test,pred.round()))\n",
    "print(confusion_matrix(y_test,pred.round()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Intially, both the training loss and validation loss decreases\n",
    "- But at certain point of time, we notice that our training loss is still going on down, but our validation loss starts to increase\n",
    "- Which means, we are overfitting to our training dataset\n",
    "- Which means, we are training for way too many epochs\n",
    "- So, we try to prevent overfitting by using early stopping and dropout layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(30, activation='relu'))     # hidden layer 1\n",
    "model.add(Dense(15, activation='relu'))     # hidden layer 2\n",
    "model.add(Dense(1,activation = 'sigmoid'))  # output layer, sigmoidal because it's an binary classifcation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class EarlyStopping in module keras.callbacks:\n",
      "\n",
      "class EarlyStopping(Callback)\n",
      " |  EarlyStopping(monitor='val_loss', min_delta=0, patience=0, verbose=0, mode='auto', baseline=None, restore_best_weights=False)\n",
      " |  \n",
      " |  Stop training when a monitored metric has stopped improving.\n",
      " |  \n",
      " |  Assuming the goal of a training is to minimize the loss. With this, the\n",
      " |  metric to be monitored would be `'loss'`, and mode would be `'min'`. A\n",
      " |  `model.fit()` training loop will check at end of every epoch whether\n",
      " |  the loss is no longer decreasing, considering the `min_delta` and\n",
      " |  `patience` if applicable. Once it's found no longer decreasing,\n",
      " |  `model.stop_training` is marked True and the training terminates.\n",
      " |  \n",
      " |  The quantity to be monitored needs to be available in `logs` dict.\n",
      " |  To make it so, pass the loss or metrics at `model.compile()`.\n",
      " |  \n",
      " |  Args:\n",
      " |    monitor: Quantity to be monitored.\n",
      " |    min_delta: Minimum change in the monitored quantity\n",
      " |        to qualify as an improvement, i.e. an absolute\n",
      " |        change of less than min_delta, will count as no\n",
      " |        improvement.\n",
      " |    patience: Number of epochs with no improvement\n",
      " |        after which training will be stopped.\n",
      " |    verbose: verbosity mode.\n",
      " |    mode: One of `{\"auto\", \"min\", \"max\"}`. In `min` mode,\n",
      " |        training will stop when the quantity\n",
      " |        monitored has stopped decreasing; in `\"max\"`\n",
      " |        mode it will stop when the quantity\n",
      " |        monitored has stopped increasing; in `\"auto\"`\n",
      " |        mode, the direction is automatically inferred\n",
      " |        from the name of the monitored quantity.\n",
      " |    baseline: Baseline value for the monitored quantity.\n",
      " |        Training will stop if the model doesn't show improvement over the\n",
      " |        baseline.\n",
      " |    restore_best_weights: Whether to restore model weights from\n",
      " |        the epoch with the best value of the monitored quantity.\n",
      " |        If False, the model weights obtained at the last step of\n",
      " |        training are used. An epoch will be restored regardless\n",
      " |        of the performance relative to the `baseline`. If no epoch\n",
      " |        improves on `baseline`, training will run for `patience`\n",
      " |        epochs and restore weights from the best epoch in that set.\n",
      " |  \n",
      " |  Example:\n",
      " |  \n",
      " |  >>> callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
      " |  >>> # This callback will stop the training when there is no improvement in\n",
      " |  >>> # the loss for three consecutive epochs.\n",
      " |  >>> model = tf.keras.models.Sequential([tf.keras.layers.Dense(10)])\n",
      " |  >>> model.compile(tf.keras.optimizers.SGD(), loss='mse')\n",
      " |  >>> history = model.fit(np.arange(100).reshape(5, 20), np.zeros(5),\n",
      " |  ...                     epochs=10, batch_size=1, callbacks=[callback],\n",
      " |  ...                     verbose=0)\n",
      " |  >>> len(history.history['loss'])  # Only 4 epochs are run.\n",
      " |  4\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      EarlyStopping\n",
      " |      Callback\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, monitor='val_loss', min_delta=0, patience=0, verbose=0, mode='auto', baseline=None, restore_best_weights=False)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  get_monitor_value(self, logs)\n",
      " |  \n",
      " |  on_epoch_end(self, epoch, logs=None)\n",
      " |      Called at the end of an epoch.\n",
      " |      \n",
      " |      Subclasses should override for any actions to run. This function should only\n",
      " |      be called during TRAIN mode.\n",
      " |      \n",
      " |      Args:\n",
      " |          epoch: Integer, index of epoch.\n",
      " |          logs: Dict, metric results for this training epoch, and for the\n",
      " |            validation epoch if validation is performed. Validation result keys\n",
      " |            are prefixed with `val_`. For training epoch, the values of the\n",
      " |           `Model`'s metrics are returned. Example : `{'loss': 0.2, 'accuracy':\n",
      " |             0.7}`.\n",
      " |  \n",
      " |  on_train_begin(self, logs=None)\n",
      " |      Called at the beginning of training.\n",
      " |      \n",
      " |      Subclasses should override for any actions to run.\n",
      " |      \n",
      " |      Args:\n",
      " |          logs: Dict. Currently no data is passed to this argument for this method\n",
      " |            but that may change in the future.\n",
      " |  \n",
      " |  on_train_end(self, logs=None)\n",
      " |      Called at the end of training.\n",
      " |      \n",
      " |      Subclasses should override for any actions to run.\n",
      " |      \n",
      " |      Args:\n",
      " |          logs: Dict. Currently the output of the last call to `on_epoch_end()`\n",
      " |            is passed to this argument for this method but that may change in\n",
      " |            the future.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from Callback:\n",
      " |  \n",
      " |  on_batch_begin(self, batch, logs=None)\n",
      " |      A backwards compatibility alias for `on_train_batch_begin`.\n",
      " |  \n",
      " |  on_batch_end(self, batch, logs=None)\n",
      " |      A backwards compatibility alias for `on_train_batch_end`.\n",
      " |  \n",
      " |  on_epoch_begin(self, epoch, logs=None)\n",
      " |      Called at the start of an epoch.\n",
      " |      \n",
      " |      Subclasses should override for any actions to run. This function should only\n",
      " |      be called during TRAIN mode.\n",
      " |      \n",
      " |      Args:\n",
      " |          epoch: Integer, index of epoch.\n",
      " |          logs: Dict. Currently no data is passed to this argument for this method\n",
      " |            but that may change in the future.\n",
      " |  \n",
      " |  on_predict_batch_begin(self, batch, logs=None)\n",
      " |      Called at the beginning of a batch in `predict` methods.\n",
      " |      \n",
      " |      Subclasses should override for any actions to run.\n",
      " |      \n",
      " |      Note that if the `steps_per_execution` argument to `compile` in\n",
      " |      `tf.keras.Model` is set to `N`, this method will only be called every `N`\n",
      " |      batches.\n",
      " |      \n",
      " |      Args:\n",
      " |          batch: Integer, index of batch within the current epoch.\n",
      " |          logs: Dict. Currently no data is passed to this argument for this method\n",
      " |            but that may change in the future.\n",
      " |  \n",
      " |  on_predict_batch_end(self, batch, logs=None)\n",
      " |      Called at the end of a batch in `predict` methods.\n",
      " |      \n",
      " |      Subclasses should override for any actions to run.\n",
      " |      \n",
      " |      Note that if the `steps_per_execution` argument to `compile` in\n",
      " |      `tf.keras.Model` is set to `N`, this method will only be called every `N`\n",
      " |      batches.\n",
      " |      \n",
      " |      Args:\n",
      " |          batch: Integer, index of batch within the current epoch.\n",
      " |          logs: Dict. Aggregated metric results up until this batch.\n",
      " |  \n",
      " |  on_predict_begin(self, logs=None)\n",
      " |      Called at the beginning of prediction.\n",
      " |      \n",
      " |      Subclasses should override for any actions to run.\n",
      " |      \n",
      " |      Args:\n",
      " |          logs: Dict. Currently no data is passed to this argument for this method\n",
      " |            but that may change in the future.\n",
      " |  \n",
      " |  on_predict_end(self, logs=None)\n",
      " |      Called at the end of prediction.\n",
      " |      \n",
      " |      Subclasses should override for any actions to run.\n",
      " |      \n",
      " |      Args:\n",
      " |          logs: Dict. Currently no data is passed to this argument for this method\n",
      " |            but that may change in the future.\n",
      " |  \n",
      " |  on_test_batch_begin(self, batch, logs=None)\n",
      " |      Called at the beginning of a batch in `evaluate` methods.\n",
      " |      \n",
      " |      Also called at the beginning of a validation batch in the `fit`\n",
      " |      methods, if validation data is provided.\n",
      " |      \n",
      " |      Subclasses should override for any actions to run.\n",
      " |      \n",
      " |      Note that if the `steps_per_execution` argument to `compile` in\n",
      " |      `tf.keras.Model` is set to `N`, this method will only be called every `N`\n",
      " |      batches.\n",
      " |      \n",
      " |      Args:\n",
      " |          batch: Integer, index of batch within the current epoch.\n",
      " |          logs: Dict. Currently no data is passed to this argument for this method\n",
      " |            but that may change in the future.\n",
      " |  \n",
      " |  on_test_batch_end(self, batch, logs=None)\n",
      " |      Called at the end of a batch in `evaluate` methods.\n",
      " |      \n",
      " |      Also called at the end of a validation batch in the `fit`\n",
      " |      methods, if validation data is provided.\n",
      " |      \n",
      " |      Subclasses should override for any actions to run.\n",
      " |      \n",
      " |      Note that if the `steps_per_execution` argument to `compile` in\n",
      " |      `tf.keras.Model` is set to `N`, this method will only be called every `N`\n",
      " |      batches.\n",
      " |      \n",
      " |      Args:\n",
      " |          batch: Integer, index of batch within the current epoch.\n",
      " |          logs: Dict. Aggregated metric results up until this batch.\n",
      " |  \n",
      " |  on_test_begin(self, logs=None)\n",
      " |      Called at the beginning of evaluation or validation.\n",
      " |      \n",
      " |      Subclasses should override for any actions to run.\n",
      " |      \n",
      " |      Args:\n",
      " |          logs: Dict. Currently no data is passed to this argument for this method\n",
      " |            but that may change in the future.\n",
      " |  \n",
      " |  on_test_end(self, logs=None)\n",
      " |      Called at the end of evaluation or validation.\n",
      " |      \n",
      " |      Subclasses should override for any actions to run.\n",
      " |      \n",
      " |      Args:\n",
      " |          logs: Dict. Currently the output of the last call to\n",
      " |            `on_test_batch_end()` is passed to this argument for this method\n",
      " |            but that may change in the future.\n",
      " |  \n",
      " |  on_train_batch_begin(self, batch, logs=None)\n",
      " |      Called at the beginning of a training batch in `fit` methods.\n",
      " |      \n",
      " |      Subclasses should override for any actions to run.\n",
      " |      \n",
      " |      Note that if the `steps_per_execution` argument to `compile` in\n",
      " |      `tf.keras.Model` is set to `N`, this method will only be called every `N`\n",
      " |      batches.\n",
      " |      \n",
      " |      Args:\n",
      " |          batch: Integer, index of batch within the current epoch.\n",
      " |          logs: Dict. Currently no data is passed to this argument for this method\n",
      " |            but that may change in the future.\n",
      " |  \n",
      " |  on_train_batch_end(self, batch, logs=None)\n",
      " |      Called at the end of a training batch in `fit` methods.\n",
      " |      \n",
      " |      Subclasses should override for any actions to run.\n",
      " |      \n",
      " |      Note that if the `steps_per_execution` argument to `compile` in\n",
      " |      `tf.keras.Model` is set to `N`, this method will only be called every `N`\n",
      " |      batches.\n",
      " |      \n",
      " |      Args:\n",
      " |          batch: Integer, index of batch within the current epoch.\n",
      " |          logs: Dict. Aggregated metric results up until this batch.\n",
      " |  \n",
      " |  set_model(self, model)\n",
      " |  \n",
      " |  set_params(self, params)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from Callback:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(EarlyStopping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss',mode='min',verbose=1,patience=25)\n",
    "\n",
    "# If our metric is accuracy, then mode='max', because we need to max the accuracy\n",
    "# If our metric is loss, then mode='min', because we need to reduce the loss\n",
    "# patience = 25 means that we will wait for 25 epochs more, even after detecting a stopping point because of noise that could occur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "13/13 [==============================] - 1s 25ms/step - loss: 0.5904 - val_loss: 0.4717\n",
      "Epoch 2/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4361 - val_loss: 0.3531\n",
      "Epoch 3/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3375 - val_loss: 0.2755\n",
      "Epoch 4/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2729 - val_loss: 0.2230\n",
      "Epoch 5/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2310 - val_loss: 0.1873\n",
      "Epoch 6/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.1994 - val_loss: 0.1617\n",
      "Epoch 7/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.1776 - val_loss: 0.1413\n",
      "Epoch 8/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.1594 - val_loss: 0.1276\n",
      "Epoch 9/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.1457 - val_loss: 0.1156\n",
      "Epoch 10/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.1344 - val_loss: 0.1053\n",
      "Epoch 11/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1242 - val_loss: 0.0973\n",
      "Epoch 12/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.1154 - val_loss: 0.0915\n",
      "Epoch 13/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1080 - val_loss: 0.0861\n",
      "Epoch 14/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.1010 - val_loss: 0.0803\n",
      "Epoch 15/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0949 - val_loss: 0.0755\n",
      "Epoch 16/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0893 - val_loss: 0.0723\n",
      "Epoch 17/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0838 - val_loss: 0.0694\n",
      "Epoch 18/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0791 - val_loss: 0.0660\n",
      "Epoch 19/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0754 - val_loss: 0.0641\n",
      "Epoch 20/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0710 - val_loss: 0.0615\n",
      "Epoch 21/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0678 - val_loss: 0.0594\n",
      "Epoch 22/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0648 - val_loss: 0.0582\n",
      "Epoch 23/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0612 - val_loss: 0.0573\n",
      "Epoch 24/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0584 - val_loss: 0.0561\n",
      "Epoch 25/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0559 - val_loss: 0.0556\n",
      "Epoch 26/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0533 - val_loss: 0.0552\n",
      "Epoch 27/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0514 - val_loss: 0.0540\n",
      "Epoch 28/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0491 - val_loss: 0.0541\n",
      "Epoch 29/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0471 - val_loss: 0.0533\n",
      "Epoch 30/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0455 - val_loss: 0.0530\n",
      "Epoch 31/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0436 - val_loss: 0.0520\n",
      "Epoch 32/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0417 - val_loss: 0.0522\n",
      "Epoch 33/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0401 - val_loss: 0.0523\n",
      "Epoch 34/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0386 - val_loss: 0.0519\n",
      "Epoch 35/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0371 - val_loss: 0.0524\n",
      "Epoch 36/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0355 - val_loss: 0.0522\n",
      "Epoch 37/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0342 - val_loss: 0.0515\n",
      "Epoch 38/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0329 - val_loss: 0.0518\n",
      "Epoch 39/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0313 - val_loss: 0.0514\n",
      "Epoch 40/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0300 - val_loss: 0.0518\n",
      "Epoch 41/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0290 - val_loss: 0.0521\n",
      "Epoch 42/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0278 - val_loss: 0.0519\n",
      "Epoch 43/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0267 - val_loss: 0.0526\n",
      "Epoch 44/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0258 - val_loss: 0.0518\n",
      "Epoch 45/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0249 - val_loss: 0.0522\n",
      "Epoch 46/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0249 - val_loss: 0.0561\n",
      "Epoch 47/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0230 - val_loss: 0.0540\n",
      "Epoch 48/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0217 - val_loss: 0.0535\n",
      "Epoch 49/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0210 - val_loss: 0.0539\n",
      "Epoch 50/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0201 - val_loss: 0.0539\n",
      "Epoch 51/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0196 - val_loss: 0.0538\n",
      "Epoch 52/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0188 - val_loss: 0.0548\n",
      "Epoch 53/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0182 - val_loss: 0.0543\n",
      "Epoch 54/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0175 - val_loss: 0.0546\n",
      "Epoch 55/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0172 - val_loss: 0.0558\n",
      "Epoch 56/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0164 - val_loss: 0.0553\n",
      "Epoch 57/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0165 - val_loss: 0.0564\n",
      "Epoch 58/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0151 - val_loss: 0.0558\n",
      "Epoch 59/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0148 - val_loss: 0.0557\n",
      "Epoch 60/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0143 - val_loss: 0.0563\n",
      "Epoch 61/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0141 - val_loss: 0.0557\n",
      "Epoch 62/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0133 - val_loss: 0.0574\n",
      "Epoch 63/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0132 - val_loss: 0.0583\n",
      "Epoch 64/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0124 - val_loss: 0.0578\n",
      "Epoch 00064: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b1de646e20>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,epochs=600,validation_data=(X_test,y_test),callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.590413</td>\n",
       "      <td>0.471744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.436124</td>\n",
       "      <td>0.353081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.337528</td>\n",
       "      <td>0.275499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.272860</td>\n",
       "      <td>0.223028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.231000</td>\n",
       "      <td>0.187273</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       loss  val_loss\n",
       "0  0.590413  0.471744\n",
       "1  0.436124  0.353081\n",
       "2  0.337528  0.275499\n",
       "3  0.272860  0.223028\n",
       "4  0.231000  0.187273"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_loss = pd.DataFrame(model.history.history)\n",
    "model_loss[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_loss.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98        63\n",
      "           1       0.99      0.99      0.99       108\n",
      "\n",
      "    accuracy                           0.99       171\n",
      "   macro avg       0.99      0.99      0.99       171\n",
      "weighted avg       0.99      0.99      0.99       171\n",
      "\n",
      "[[ 62   1]\n",
      " [  1 107]]\n"
     ]
    }
   ],
   "source": [
    "pred_2 = model.predict(X_test)\n",
    "print(classification_report(y_test,pred_2.round()))\n",
    "print(confusion_matrix(y_test,pred_2.round()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Next, we can prevent overfitting by using dropout layers\n",
    "- Dropout layers will essentially turn off a percentage of neurons randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(30, activation='relu'))     # hidden layer 1\n",
    "model.add(Dropout(rate=0.5))\n",
    "model.add(Dense(15, activation='relu'))     # hidden layer 2\n",
    "model.add(Dropout(rate=0.5))\n",
    "model.add(Dense(1,activation = 'sigmoid'))  # output layer, sigmoidal because it's an binary classifcation\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam')\n",
    "\n",
    "# rate=0.5 means that 50% of neurons are going to be turned off randomly, which also means that each neuron has 50% chance of getting turned off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "13/13 [==============================] - 1s 24ms/step - loss: 0.7815 - val_loss: 0.6398\n",
      "Epoch 2/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6547 - val_loss: 0.5364\n",
      "Epoch 3/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5969 - val_loss: 0.4524\n",
      "Epoch 4/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5423 - val_loss: 0.3842\n",
      "Epoch 5/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4666 - val_loss: 0.3284\n",
      "Epoch 6/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4241 - val_loss: 0.2816\n",
      "Epoch 7/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4033 - val_loss: 0.2442\n",
      "Epoch 8/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3984 - val_loss: 0.2153\n",
      "Epoch 9/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3485 - val_loss: 0.1906\n",
      "Epoch 10/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3142 - val_loss: 0.1708\n",
      "Epoch 11/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3128 - val_loss: 0.1555\n",
      "Epoch 12/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.2878 - val_loss: 0.1407\n",
      "Epoch 13/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.2345 - val_loss: 0.1273\n",
      "Epoch 14/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.2553 - val_loss: 0.1179\n",
      "Epoch 15/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.2350 - val_loss: 0.1101\n",
      "Epoch 16/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.2186 - val_loss: 0.1026\n",
      "Epoch 17/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.2409 - val_loss: 0.0968\n",
      "Epoch 18/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.2219 - val_loss: 0.0915\n",
      "Epoch 19/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.2231 - val_loss: 0.0865\n",
      "Epoch 20/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1940 - val_loss: 0.0824\n",
      "Epoch 21/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.1659 - val_loss: 0.0777\n",
      "Epoch 22/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.1761 - val_loss: 0.0746\n",
      "Epoch 23/600\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.1824 - val_loss: 0.0726\n",
      "Epoch 24/600\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.1786 - val_loss: 0.0710\n",
      "Epoch 25/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.1571 - val_loss: 0.0697\n",
      "Epoch 26/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1735 - val_loss: 0.0687\n",
      "Epoch 27/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.1788 - val_loss: 0.0680\n",
      "Epoch 28/600\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.1633 - val_loss: 0.0670\n",
      "Epoch 29/600\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.1730 - val_loss: 0.0656\n",
      "Epoch 30/600\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.1291 - val_loss: 0.0640\n",
      "Epoch 31/600\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.1153 - val_loss: 0.0628\n",
      "Epoch 32/600\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.1334 - val_loss: 0.0613\n",
      "Epoch 33/600\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.1481 - val_loss: 0.0602\n",
      "Epoch 34/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.1376 - val_loss: 0.0593\n",
      "Epoch 35/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1198 - val_loss: 0.0589\n",
      "Epoch 36/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1344 - val_loss: 0.0582\n",
      "Epoch 37/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1303 - val_loss: 0.0572\n",
      "Epoch 38/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.1285 - val_loss: 0.0568\n",
      "Epoch 39/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1177 - val_loss: 0.0574\n",
      "Epoch 40/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0884 - val_loss: 0.0574\n",
      "Epoch 41/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1170 - val_loss: 0.0571\n",
      "Epoch 42/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0920 - val_loss: 0.0566\n",
      "Epoch 43/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1290 - val_loss: 0.0562\n",
      "Epoch 44/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1071 - val_loss: 0.0554\n",
      "Epoch 45/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1285 - val_loss: 0.0557\n",
      "Epoch 46/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.1149 - val_loss: 0.0561\n",
      "Epoch 47/600\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.1347 - val_loss: 0.0567\n",
      "Epoch 48/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1050 - val_loss: 0.0574\n",
      "Epoch 49/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.1118 - val_loss: 0.0572\n",
      "Epoch 50/600\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0770 - val_loss: 0.0569\n",
      "Epoch 51/600\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.1202 - val_loss: 0.0563\n",
      "Epoch 52/600\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.0764 - val_loss: 0.0558\n",
      "Epoch 53/600\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.0911 - val_loss: 0.0556\n",
      "Epoch 54/600\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.1212 - val_loss: 0.0558\n",
      "Epoch 55/600\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.0642 - val_loss: 0.0552\n",
      "Epoch 56/600\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0983 - val_loss: 0.0541\n",
      "Epoch 57/600\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0951 - val_loss: 0.0534\n",
      "Epoch 58/600\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.0994 - val_loss: 0.0555\n",
      "Epoch 59/600\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.1004 - val_loss: 0.0566\n",
      "Epoch 60/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0858 - val_loss: 0.0574\n",
      "Epoch 61/600\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.0811 - val_loss: 0.0582\n",
      "Epoch 62/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0823 - val_loss: 0.0581\n",
      "Epoch 63/600\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0663 - val_loss: 0.0582\n",
      "Epoch 64/600\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.0996 - val_loss: 0.0591\n",
      "Epoch 65/600\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.0742 - val_loss: 0.0592\n",
      "Epoch 66/600\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.0723 - val_loss: 0.0586\n",
      "Epoch 67/600\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.1008 - val_loss: 0.0581\n",
      "Epoch 68/600\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.0885 - val_loss: 0.0581\n",
      "Epoch 69/600\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.0852 - val_loss: 0.0572\n",
      "Epoch 70/600\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0712 - val_loss: 0.0566\n",
      "Epoch 71/600\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.0861 - val_loss: 0.0561\n",
      "Epoch 72/600\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0796 - val_loss: 0.0562\n",
      "Epoch 73/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0951 - val_loss: 0.0567\n",
      "Epoch 74/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0961 - val_loss: 0.0571\n",
      "Epoch 75/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0517 - val_loss: 0.0570\n",
      "Epoch 76/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0748 - val_loss: 0.0570\n",
      "Epoch 77/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0750 - val_loss: 0.0566\n",
      "Epoch 78/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0772 - val_loss: 0.0566\n",
      "Epoch 79/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0652 - val_loss: 0.0563\n",
      "Epoch 80/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0702 - val_loss: 0.0568\n",
      "Epoch 81/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0768 - val_loss: 0.0567\n",
      "Epoch 82/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0825 - val_loss: 0.0574\n",
      "Epoch 00082: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b1de7fc700>"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,epochs=600,validation_data=[X_test,y_test],callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = pd.DataFrame(model.history.history)\n",
    "loss.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.97        63\n",
      "           1       0.99      0.97      0.98       108\n",
      "\n",
      "    accuracy                           0.98       171\n",
      "   macro avg       0.97      0.98      0.98       171\n",
      "weighted avg       0.98      0.98      0.98       171\n",
      "\n",
      "[[ 62   1]\n",
      " [  3 105]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,pred.round()))\n",
    "print(confusion_matrix(y_test,pred.round()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('ANN_clasification.h5')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "69eb92836b941e979072a76c7fcfffe5419cca933cedd02cfafbdfca1a93358c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
